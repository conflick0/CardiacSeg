{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1672296241939,
     "user": {
      "displayName": "29",
      "userId": "05747767364965554341"
     },
     "user_tz": -480
    },
    "id": "u5rjQLvLovao",
    "outputId": "33a2b194-0378-4a67-9f81-52db80994c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  4 05:14:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    43W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61937,
     "status": "ok",
     "timestamp": 1672296310857,
     "user": {
      "displayName": "29",
      "userId": "05747767364965554341"
     },
     "user_tz": -480
    },
    "id": "zVeiUM_Ro7H-",
    "outputId": "5686ec6c-2965-4503-af63-a2227487fa54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/Workspace/CardiacSeg/UNet3D/CHGH\n"
     ]
    }
   ],
   "source": [
    "# mount driver\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#%cd /nfs/Workspace/CardiacSeg/UNETCNX/CHGH\n",
    "%cd /nfs/Workspace/CardiacSeg/UNet3D/CHGH\n",
    "\n",
    "# # install dependents\n",
    "# !pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n",
    "# !python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "# !pip install -q timm\n",
    "# !pip install -U -q openmim\n",
    "# !mim install -U -q mmcv-full\n",
    "# !pip install ml-collections\n",
    "# !pip install ray\n",
    "# %matplotlib inline\n",
    "\n",
    "# # sync python module\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1672298141211,
     "user": {
      "displayName": "29",
      "userId": "05747767364965554341"
     },
     "user_tz": -480
    },
    "id": "q2qqZpDfpLyN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "workspace_dir = '/nfs/Workspace/CardiacSeg'\n",
    "model_workspace_dir = 'UNet3D' #'UNet3D'\n",
    "data_workspace_dir = 'CHGH'\n",
    "exp_name = 'exp_2_2_t6'\n",
    "tune_mode = 'optim_lrschedule_early_stop_epoch'\n",
    "model_name = 'unet3d' #'unet3d'\n",
    "\n",
    "# '/nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results'\n",
    "root_dir = os.path.join(\n",
    "    workspace_dir, \n",
    "    model_workspace_dir,\n",
    "    data_workspace_dir,\n",
    "    'tune_results'\n",
    ")\n",
    "# '/nfs/Workspace/CardiacSeg/dataset/CHGH'\n",
    "root_data_dir = os.path.join(\n",
    "    workspace_dir, \n",
    "    'dataset',\n",
    "    data_workspace_dir,\n",
    ")\n",
    "\n",
    "data_dir = os.path.join(root_data_dir, 'dataset_2')\n",
    "model_dir = os.path.join('./', 'models')\n",
    "log_dir = os.path.join('./', 'logs')\n",
    "start_epoch = 0\n",
    "val_every = 20\n",
    "max_epoch = 2000\n",
    "pin_memory = True\n",
    "test_mode = False\n",
    "best_checkpoint = os.path.join(model_dir, 'best_model.pth')\n",
    "final_checkpoint = os.path.join(model_dir, 'final_model.pth')\n",
    "data_dicts_json = os.path.join(root_data_dir, 'data_dicts', 'exp_2_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44991,
     "status": "ok",
     "timestamp": 1672298367615,
     "user": {
      "displayName": "29",
      "userId": "05747767364965554341"
     },
     "user_tz": -480
    },
    "id": "E8Ez867BHr2_",
    "outputId": "9686db31-6e12-432b-f1b7-1e36c10b6df9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "resume tuner form /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results\n",
      "2023-01-04 04:59:08,791\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2023-01-04 04:59:10,215\tINFO tensorboardx.py:170 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-01-04 04:59:10,215\tWARNING callback.py:108 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2023-01-04 04:59:10,216\tINFO trial_runner.py:688 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
      "2023-01-04 04:59:10,217\tINFO trial_runner.py:825 -- Using following checkpoint to resume: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6/experiment_state-2023-01-04_03-04-57.json\n",
      "2023-01-04 04:59:10,219\tWARNING trial_runner.py:830 -- Attempting to resume experiment from /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6. This will ignore any new changes to the specification.\n",
      "2023-01-04 04:59:10,358\tINFO tune.py:653 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:10 (running for 00:00:00.21)\n",
      "Memory usage on this node: 18.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=3450947)\u001b[0m /opt/conda/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "\u001b[2m\u001b[36m(pid=3450947)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m /opt/conda/lib/python3.9/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m   warn_deprecated(obj, msg, warning_category)\n",
      "Loading dataset:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m cuda is available\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m load json from /nfs/Workspace/CardiacSeg/dataset/CHGH/data_dicts/exp_2_2.json\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m fold: 2\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m train files (6): ['pid_27', 'pid_30', 'pid_57', 'pid_110', 'pid_1002', 'pid_1003']\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m val files (2): ['pid_107', 'pid_108']\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m test files (2): ['pid_106', 'pid_1000']\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m \n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m load train dataset ...\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:15 (running for 00:00:05.22)\n",
      "Memory usage on this node: 19.3/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:20 (running for 00:00:10.24)\n",
      "Memory usage on this node: 21.0/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Loading dataset:  17%|█▋        | 1/6 [00:09<00:46,  9.35s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:25 (running for 00:00:15.24)\n",
      "Memory usage on this node: 20.3/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:30 (running for 00:00:20.26)\n",
      "Memory usage on this node: 22.3/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Loading dataset:  50%|█████     | 3/6 [00:18<00:17,  5.68s/it]\n",
      "Loading dataset:  67%|██████▋   | 4/6 [00:18<00:07,  3.77s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:35 (running for 00:00:25.27)\n",
      "Memory usage on this node: 19.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:40 (running for 00:00:30.28)\n",
      "Memory usage on this node: 21.1/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Loading dataset: 100%|██████████| 6/6 [00:26<00:00,  4.50s/it]\n",
      "Loading dataset:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m \n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m load val dataset ...\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:45 (running for 00:00:35.29)\n",
      "Memory usage on this node: 20.4/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:50 (running for 00:00:40.31)\n",
      "Memory usage on this node: 21.3/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Loading dataset: 100%|██████████| 2/2 [00:09<00:00,  4.63s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m model: unet3d\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m lrschedule: warmup_cosine\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m => loaded checkpoint './models/final_model.pth' (epoch 460) (bestacc 0.8936110138893127) (early stop count 5)\n",
      "== Status ==\n",
      "Current time: 2023-01-04 04:59:55 (running for 00:00:45.33)\n",
      "Memory usage on this node: 22.1/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 460] Training (2760 Steps) (loss=0.15242):  17%|█▋        | 1/6 [00:03<00:16,  3.29s/it]\n",
      "[Epoch 460] Training (2761 Steps) (loss=0.19895):  33%|███▎      | 2/6 [00:03<00:06,  1.59s/it]\n",
      "[Epoch 460] Training (2762 Steps) (loss=0.12775):  50%|█████     | 3/6 [00:04<00:03,  1.04s/it]\n",
      "[Epoch 460] Training (2763 Steps) (loss=0.13890):  67%|██████▋   | 4/6 [00:04<00:01,  1.28it/s]\n",
      "[Epoch 460] Training (2764 Steps) (loss=0.15085):  83%|████████▎ | 5/6 [00:04<00:00,  1.56it/s]\n",
      "[Epoch 460] Training (2765 Steps) (loss=0.13452): 100%|██████████| 6/6 [00:05<00:00,  1.81it/s]\n",
      "[Epoch 460] Training (2765 Steps) (loss=0.13452): 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validate (2766 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.41s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:00 (running for 00:00:50.34)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3130003 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |     23 |          1608.12 |  0.852613 |   0.893611 |                  5 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Validate (2766 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n",
      "Validate (2766 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Early stop count:  6\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.8936110138893127 Current Avg. Dice: 0.8908940553665161\n",
      "Result for main_c206a_00026:\n",
      "  avg_acc: 0.8908940553665161\n",
      "  best_acc: 0.8936110138893127\n",
      "  date: 2023-01-04_05-00-02\n",
      "  done: false\n",
      "  early_stop_count: 6\n",
      "  experiment_id: f03a51b2ae254b1a8c917f778b2522cb\n",
      "  hostname: owo-785746fd58-zfbct\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.32.221.160\n",
      "  pid: 3450947\n",
      "  time_since_restore: 47.62781238555908\n",
      "  time_this_iter_s: 47.62781238555908\n",
      "  time_total_s: 47.62781238555908\n",
      "  timestamp: 1672808402\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c206a_00026\n",
      "  warmup_time: 0.0044095516204833984\n",
      "  \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Saving checkpoint ./models/final_model.pth\n",
      "[Epoch 461] Training (2766 Steps) (loss=0.24233):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "[Epoch 461] Training (2767 Steps) (loss=0.11706):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 461] Training (2768 Steps) (loss=0.28207):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 461] Training (2769 Steps) (loss=0.17126):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 461] Training (2770 Steps) (loss=0.09339):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 461] Training (2770 Steps) (loss=0.09339):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 461] Training (2771 Steps) (loss=0.12600): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 461] Training (2771 Steps) (loss=0.12600): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 462] Training (2772 Steps) (loss=0.18641):  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\n",
      "[Epoch 462] Training (2773 Steps) (loss=0.12732):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:07 (running for 00:00:57.38)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 462] Training (2774 Steps) (loss=0.14619):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 462] Training (2775 Steps) (loss=0.15551):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 462] Training (2776 Steps) (loss=0.11033):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 462] Training (2777 Steps) (loss=0.08086): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 462] Training (2777 Steps) (loss=0.08086): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 463] Training (2778 Steps) (loss=0.17201):  17%|█▋        | 1/6 [00:01<00:05,  1.04s/it]\n",
      "[Epoch 463] Training (2779 Steps) (loss=0.08336):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 463] Training (2780 Steps) (loss=0.16914):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 463] Training (2781 Steps) (loss=0.18523):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 463] Training (2782 Steps) (loss=0.13002):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 463] Training (2783 Steps) (loss=0.22514): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 463] Training (2783 Steps) (loss=0.22514): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:12 (running for 00:01:02.40)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 464] Training (2784 Steps) (loss=0.16085):  17%|█▋        | 1/6 [00:01<00:06,  1.21s/it]\n",
      "[Epoch 464] Training (2785 Steps) (loss=0.16221):  33%|███▎      | 2/6 [00:01<00:02,  1.38it/s]\n",
      "[Epoch 464] Training (2786 Steps) (loss=0.20572):  50%|█████     | 3/6 [00:01<00:01,  1.76it/s]\n",
      "[Epoch 464] Training (2787 Steps) (loss=0.28433):  67%|██████▋   | 4/6 [00:02<00:00,  2.01it/s]\n",
      "[Epoch 464] Training (2788 Steps) (loss=0.16034):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 464] Training (2789 Steps) (loss=0.12470): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 464] Training (2789 Steps) (loss=0.12470): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 465] Training (2790 Steps) (loss=0.08526):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 465] Training (2791 Steps) (loss=0.28492):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 465] Training (2792 Steps) (loss=0.24748):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 465] Training (2792 Steps) (loss=0.24748):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 465] Training (2793 Steps) (loss=0.22053):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:17 (running for 00:01:07.40)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 465] Training (2794 Steps) (loss=0.12881):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 465] Training (2795 Steps) (loss=0.42306): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 465] Training (2795 Steps) (loss=0.42306): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 466] Training (2796 Steps) (loss=0.15563):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "[Epoch 466] Training (2797 Steps) (loss=0.16071):  33%|███▎      | 2/6 [00:01<00:02,  1.42it/s]\n",
      "[Epoch 466] Training (2798 Steps) (loss=0.19378):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 466] Training (2799 Steps) (loss=0.16239):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 466] Training (2800 Steps) (loss=0.13904):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 466] Training (2801 Steps) (loss=0.09824): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 466] Training (2801 Steps) (loss=0.09824): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:22 (running for 00:01:12.42)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 467] Training (2802 Steps) (loss=0.17369):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 467] Training (2803 Steps) (loss=0.16151):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 467] Training (2804 Steps) (loss=0.19520):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 467] Training (2805 Steps) (loss=0.16733):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 467] Training (2806 Steps) (loss=0.15415):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 467] Training (2807 Steps) (loss=0.10253): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 467] Training (2807 Steps) (loss=0.10253): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 468] Training (2808 Steps) (loss=0.23086):  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]\n",
      "[Epoch 468] Training (2809 Steps) (loss=0.13854):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "[Epoch 468] Training (2810 Steps) (loss=0.11498):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "[Epoch 468] Training (2811 Steps) (loss=0.16957):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 468] Training (2812 Steps) (loss=0.19532):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:27 (running for 00:01:17.43)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 468] Training (2813 Steps) (loss=0.28701): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 468] Training (2813 Steps) (loss=0.28701): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 469] Training (2814 Steps) (loss=0.10027):  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\n",
      "[Epoch 469] Training (2815 Steps) (loss=0.12752):  33%|███▎      | 2/6 [00:01<00:02,  1.40it/s]\n",
      "[Epoch 469] Training (2816 Steps) (loss=0.10671):  50%|█████     | 3/6 [00:01<00:01,  1.78it/s]\n",
      "[Epoch 469] Training (2817 Steps) (loss=0.20730):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 469] Training (2818 Steps) (loss=0.18224):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 469] Training (2819 Steps) (loss=0.23102): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 469] Training (2819 Steps) (loss=0.23102): 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 470] Training (2820 Steps) (loss=0.15050):  17%|█▋        | 1/6 [00:00<00:04,  1.01it/s]\n",
      "[Epoch 470] Training (2821 Steps) (loss=0.23000):  33%|███▎      | 2/6 [00:01<00:02,  1.57it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:32 (running for 00:01:22.45)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 470] Training (2822 Steps) (loss=0.17616):  50%|█████     | 3/6 [00:01<00:01,  1.92it/s]\n",
      "[Epoch 470] Training (2823 Steps) (loss=0.13742):  67%|██████▋   | 4/6 [00:02<00:00,  2.13it/s]\n",
      "[Epoch 470] Training (2824 Steps) (loss=0.12058):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 470] Training (2825 Steps) (loss=0.12722): 100%|██████████| 6/6 [00:02<00:00,  2.38it/s]\n",
      "[Epoch 470] Training (2825 Steps) (loss=0.12722): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 471] Training (2826 Steps) (loss=0.17930):  17%|█▋        | 1/6 [00:01<00:05,  1.02s/it]\n",
      "[Epoch 471] Training (2827 Steps) (loss=0.16276):  33%|███▎      | 2/6 [00:01<00:02,  1.54it/s]\n",
      "[Epoch 471] Training (2828 Steps) (loss=0.13762):  50%|█████     | 3/6 [00:01<00:01,  1.88it/s]\n",
      "[Epoch 471] Training (2829 Steps) (loss=0.17994):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 471] Training (2830 Steps) (loss=0.14182):  83%|████████▎ | 5/6 [00:02<00:00,  2.26it/s]\n",
      "[Epoch 471] Training (2831 Steps) (loss=0.15794): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 471] Training (2831 Steps) (loss=0.15794): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:37 (running for 00:01:27.45)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 472] Training (2832 Steps) (loss=0.12371):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 472] Training (2833 Steps) (loss=0.22585):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 472] Training (2834 Steps) (loss=0.15062):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 472] Training (2835 Steps) (loss=0.11505):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 472] Training (2836 Steps) (loss=0.24921):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 472] Training (2837 Steps) (loss=0.14950): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 472] Training (2837 Steps) (loss=0.14950): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 473] Training (2838 Steps) (loss=0.19030):  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\n",
      "[Epoch 473] Training (2839 Steps) (loss=0.11816):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "[Epoch 473] Training (2840 Steps) (loss=0.20611):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:42 (running for 00:01:32.47)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 473] Training (2841 Steps) (loss=0.07535):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 473] Training (2842 Steps) (loss=0.07111):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 473] Training (2843 Steps) (loss=0.25280): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 473] Training (2843 Steps) (loss=0.25280): 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 474] Training (2844 Steps) (loss=0.40789):   0%|          | 0/6 [00:01<?, ?it/s]\n",
      "[Epoch 474] Training (2844 Steps) (loss=0.40789):  17%|█▋        | 1/6 [00:01<00:06,  1.25s/it]\n",
      "[Epoch 474] Training (2845 Steps) (loss=0.15792):  33%|███▎      | 2/6 [00:01<00:02,  1.34it/s]\n",
      "[Epoch 474] Training (2846 Steps) (loss=0.15249):  50%|█████     | 3/6 [00:02<00:01,  1.71it/s]\n",
      "[Epoch 474] Training (2847 Steps) (loss=0.16175):  67%|██████▋   | 4/6 [00:02<00:01,  1.98it/s]\n",
      "[Epoch 474] Training (2848 Steps) (loss=0.12617):  83%|████████▎ | 5/6 [00:02<00:00,  2.16it/s]\n",
      "[Epoch 474] Training (2849 Steps) (loss=0.13455): 100%|██████████| 6/6 [00:03<00:00,  2.28it/s]\n",
      "[Epoch 474] Training (2849 Steps) (loss=0.13455): 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:47 (running for 00:01:37.48)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 475] Training (2850 Steps) (loss=0.16521):  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]\n",
      "[Epoch 475] Training (2851 Steps) (loss=0.13946):  33%|███▎      | 2/6 [00:01<00:02,  1.42it/s]\n",
      "[Epoch 475] Training (2852 Steps) (loss=0.16822):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 475] Training (2853 Steps) (loss=0.17233):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 475] Training (2854 Steps) (loss=0.13161):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 475] Training (2855 Steps) (loss=0.17342): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 475] Training (2855 Steps) (loss=0.17342): 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 476] Training (2856 Steps) (loss=0.13215):  17%|█▋        | 1/6 [00:01<00:05,  1.07s/it]\n",
      "[Epoch 476] Training (2857 Steps) (loss=0.22052):  33%|███▎      | 2/6 [00:01<00:02,  1.48it/s]\n",
      "[Epoch 476] Training (2858 Steps) (loss=0.16256):  50%|█████     | 3/6 [00:01<00:01,  1.84it/s]\n",
      "[Epoch 476] Training (2859 Steps) (loss=0.17692):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:52 (running for 00:01:42.49)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 476] Training (2860 Steps) (loss=0.08504):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 476] Training (2861 Steps) (loss=0.14237): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 476] Training (2861 Steps) (loss=0.14237): 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 477] Training (2862 Steps) (loss=0.19162):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 477] Training (2863 Steps) (loss=0.11979):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 477] Training (2864 Steps) (loss=0.18660):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 477] Training (2865 Steps) (loss=0.30763):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 477] Training (2866 Steps) (loss=0.10717):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 477] Training (2867 Steps) (loss=0.11537): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 477] Training (2867 Steps) (loss=0.11537): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 478] Training (2868 Steps) (loss=0.15392):  17%|█▋        | 1/6 [00:01<00:05,  1.20s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:00:57 (running for 00:01:47.50)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 478] Training (2869 Steps) (loss=0.08226):  33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]\n",
      "[Epoch 478] Training (2870 Steps) (loss=0.19156):  50%|█████     | 3/6 [00:01<00:01,  1.75it/s]\n",
      "[Epoch 478] Training (2871 Steps) (loss=0.13687):  67%|██████▋   | 4/6 [00:02<00:01,  2.00it/s]\n",
      "[Epoch 478] Training (2872 Steps) (loss=0.15527):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 478] Training (2873 Steps) (loss=0.17820): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 478] Training (2873 Steps) (loss=0.17820): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 479] Training (2874 Steps) (loss=0.24940):  17%|█▋        | 1/6 [00:01<00:05,  1.09s/it]\n",
      "[Epoch 479] Training (2875 Steps) (loss=0.19741):  33%|███▎      | 2/6 [00:01<00:02,  1.48it/s]\n",
      "[Epoch 479] Training (2876 Steps) (loss=0.20349):  50%|█████     | 3/6 [00:01<00:01,  1.84it/s]\n",
      "[Epoch 479] Training (2877 Steps) (loss=0.13657):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:02 (running for 00:01:52.51)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 479] Training (2878 Steps) (loss=0.18540):  83%|████████▎ | 5/6 [00:03<00:00,  1.41it/s]\n",
      "[Epoch 479] Training (2879 Steps) (loss=0.17487): 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "[Epoch 479] Training (2879 Steps) (loss=0.17487): 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 480] Training (2880 Steps) (loss=0.10449):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 480] Training (2881 Steps) (loss=0.11801):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 480] Training (2882 Steps) (loss=0.08501):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 480] Training (2883 Steps) (loss=0.19612):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 480] Training (2884 Steps) (loss=0.12116):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 480] Training (2885 Steps) (loss=0.15068): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 480] Training (2885 Steps) (loss=0.15068): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:07 (running for 00:01:57.52)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      1 |          47.6278 |  0.890894 |   0.893611 |                  6 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |        2674.48   |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |        1831.41   |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |        2674.38   |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |        2637.93   |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |        1285.58   |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |        3369.04   |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |        3779.88   |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |        4651.93   |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |        3584.62   |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |        3189.39   |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |        1806.32   |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |        1983.92   |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |        2110.77   |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |        1662.24   |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |        2654.87   |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |        3151.9    |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Validate (2886 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.48s/it]\n",
      "Validate (2886 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]\n",
      "Validate (2886 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Early stop count:  7\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.8936110138893127 Current Avg. Dice: 0.8766659498214722\n",
      "Result for main_c206a_00026:\n",
      "  avg_acc: 0.8766659498214722\n",
      "  best_acc: 0.8936110138893127\n",
      "  date: 2023-01-04_05-01-11\n",
      "  done: false\n",
      "  early_stop_count: 7\n",
      "  experiment_id: f03a51b2ae254b1a8c917f778b2522cb\n",
      "  hostname: owo-785746fd58-zfbct\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.32.221.160\n",
      "  pid: 3450947\n",
      "  time_since_restore: 116.1243793964386\n",
      "  time_this_iter_s: 68.49656701087952\n",
      "  time_total_s: 116.1243793964386\n",
      "  timestamp: 1672808471\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: c206a_00026\n",
      "  warmup_time: 0.0044095516204833984\n",
      "  \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Saving checkpoint ./models/final_model.pth\n",
      "[Epoch 481] Training (2886 Steps) (loss=0.13503):  17%|█▋        | 1/6 [00:00<00:04,  1.02it/s]\n",
      "[Epoch 481] Training (2887 Steps) (loss=0.11842):  33%|███▎      | 2/6 [00:01<00:02,  1.59it/s]\n",
      "[Epoch 481] Training (2888 Steps) (loss=0.14562):  50%|█████     | 3/6 [00:01<00:01,  1.91it/s]\n",
      "[Epoch 481] Training (2889 Steps) (loss=0.16462):  67%|██████▋   | 4/6 [00:02<00:00,  2.13it/s]\n",
      "[Epoch 481] Training (2890 Steps) (loss=0.20389):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 481] Training (2891 Steps) (loss=0.12069): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 481] Training (2891 Steps) (loss=0.12069): 100%|██████████| 6/6 [00:03<00:00,  1.99it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 482] Training (2892 Steps) (loss=0.14556):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 482] Training (2893 Steps) (loss=0.11151):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 482] Training (2894 Steps) (loss=0.10525):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:16 (running for 00:02:05.88)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 482] Training (2895 Steps) (loss=0.12149):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 482] Training (2896 Steps) (loss=0.17533):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 482] Training (2897 Steps) (loss=0.13668): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 482] Training (2897 Steps) (loss=0.13668): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 483] Training (2898 Steps) (loss=0.14129):  17%|█▋        | 1/6 [00:01<00:05,  1.02s/it]\n",
      "[Epoch 483] Training (2899 Steps) (loss=0.10955):  33%|███▎      | 2/6 [00:01<00:02,  1.54it/s]\n",
      "[Epoch 483] Training (2900 Steps) (loss=0.15390):  50%|█████     | 3/6 [00:01<00:01,  1.88it/s]\n",
      "[Epoch 483] Training (2901 Steps) (loss=0.17082):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 483] Training (2902 Steps) (loss=0.13008):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 483] Training (2903 Steps) (loss=0.20839): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 483] Training (2903 Steps) (loss=0.20839): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:21 (running for 00:02:10.89)\n",
      "Memory usage on this node: 23.0/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 484] Training (2904 Steps) (loss=0.10928):  17%|█▋        | 1/6 [00:00<00:04,  1.03it/s]\n",
      "[Epoch 484] Training (2905 Steps) (loss=0.14793):  33%|███▎      | 2/6 [00:01<00:02,  1.60it/s]\n",
      "[Epoch 484] Training (2906 Steps) (loss=0.09415):  50%|█████     | 3/6 [00:01<00:01,  1.93it/s]\n",
      "[Epoch 484] Training (2907 Steps) (loss=0.09426):  67%|██████▋   | 4/6 [00:02<00:00,  2.14it/s]\n",
      "[Epoch 484] Training (2908 Steps) (loss=0.15539):  83%|████████▎ | 5/6 [00:02<00:00,  2.28it/s]\n",
      "[Epoch 484] Training (2909 Steps) (loss=0.09681): 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n",
      "[Epoch 484] Training (2909 Steps) (loss=0.09681): 100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 485] Training (2910 Steps) (loss=0.07329):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 485] Training (2911 Steps) (loss=0.09772):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 485] Training (2912 Steps) (loss=0.12383):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 485] Training (2913 Steps) (loss=0.29374):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 485] Training (2914 Steps) (loss=0.15253):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:26 (running for 00:02:15.91)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 485] Training (2915 Steps) (loss=0.17004): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 485] Training (2915 Steps) (loss=0.17004): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 486] Training (2916 Steps) (loss=0.30781):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "[Epoch 486] Training (2917 Steps) (loss=0.05744):  33%|███▎      | 2/6 [00:01<00:02,  1.42it/s]\n",
      "[Epoch 486] Training (2918 Steps) (loss=0.16146):  50%|█████     | 3/6 [00:01<00:01,  1.78it/s]\n",
      "[Epoch 486] Training (2919 Steps) (loss=0.09818):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 486] Training (2920 Steps) (loss=0.13718):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 486] Training (2921 Steps) (loss=0.14897): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 486] Training (2921 Steps) (loss=0.14897): 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 487] Training (2922 Steps) (loss=0.18030):  17%|█▋        | 1/6 [00:01<00:06,  1.26s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:31 (running for 00:02:20.91)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 487] Training (2923 Steps) (loss=0.12887):  33%|███▎      | 2/6 [00:01<00:02,  1.34it/s]\n",
      "[Epoch 487] Training (2924 Steps) (loss=0.13701):  50%|█████     | 3/6 [00:02<00:01,  1.71it/s]\n",
      "[Epoch 487] Training (2925 Steps) (loss=0.16057):  67%|██████▋   | 4/6 [00:02<00:01,  1.96it/s]\n",
      "[Epoch 487] Training (2926 Steps) (loss=0.15664):  83%|████████▎ | 5/6 [00:02<00:00,  2.14it/s]\n",
      "[Epoch 487] Training (2927 Steps) (loss=0.14497): 100%|██████████| 6/6 [00:03<00:00,  2.27it/s]\n",
      "[Epoch 487] Training (2927 Steps) (loss=0.14497): 100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 488] Training (2928 Steps) (loss=0.11246):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 488] Training (2929 Steps) (loss=0.11434):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 488] Training (2930 Steps) (loss=0.09924):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 488] Training (2931 Steps) (loss=0.18336):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 488] Training (2932 Steps) (loss=0.15217):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 488] Training (2933 Steps) (loss=0.12639): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 488] Training (2933 Steps) (loss=0.12639): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:36 (running for 00:02:25.93)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 489] Training (2934 Steps) (loss=0.11981):  17%|█▋        | 1/6 [00:01<00:06,  1.21s/it]\n",
      "[Epoch 489] Training (2935 Steps) (loss=0.09728):  33%|███▎      | 2/6 [00:01<00:02,  1.38it/s]\n",
      "[Epoch 489] Training (2936 Steps) (loss=0.16346):  50%|█████     | 3/6 [00:01<00:01,  1.74it/s]\n",
      "[Epoch 489] Training (2937 Steps) (loss=0.17401):  67%|██████▋   | 4/6 [00:02<00:01,  2.00it/s]\n",
      "[Epoch 489] Training (2938 Steps) (loss=0.22092):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 489] Training (2939 Steps) (loss=0.18602): 100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 490] Training (2940 Steps) (loss=0.10912):  17%|█▋        | 1/6 [00:00<00:04,  1.02it/s]\n",
      "[Epoch 490] Training (2941 Steps) (loss=0.13109):  33%|███▎      | 2/6 [00:01<00:02,  1.58it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:41 (running for 00:02:30.94)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 490] Training (2942 Steps) (loss=0.19927):  50%|█████     | 3/6 [00:01<00:01,  1.91it/s]\n",
      "[Epoch 490] Training (2943 Steps) (loss=0.09165):  67%|██████▋   | 4/6 [00:02<00:00,  2.12it/s]\n",
      "[Epoch 490] Training (2944 Steps) (loss=0.15863):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 490] Training (2945 Steps) (loss=0.09945): 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n",
      "[Epoch 490] Training (2945 Steps) (loss=0.09945): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 491] Training (2946 Steps) (loss=0.17668):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 491] Training (2947 Steps) (loss=0.15103):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 491] Training (2948 Steps) (loss=0.09822):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 491] Training (2949 Steps) (loss=0.15929):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 491] Training (2950 Steps) (loss=0.09522):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 491] Training (2951 Steps) (loss=0.13543): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 491] Training (2951 Steps) (loss=0.13543): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:46 (running for 00:02:35.95)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 492] Training (2952 Steps) (loss=0.18108):  17%|█▋        | 1/6 [00:01<00:05,  1.01s/it]\n",
      "[Epoch 492] Training (2953 Steps) (loss=0.21322):  33%|███▎      | 2/6 [00:01<00:02,  1.54it/s]\n",
      "[Epoch 492] Training (2954 Steps) (loss=0.09984):  50%|█████     | 3/6 [00:01<00:01,  1.88it/s]\n",
      "[Epoch 492] Training (2955 Steps) (loss=0.09574):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "[Epoch 492] Training (2956 Steps) (loss=0.12791):  83%|████████▎ | 5/6 [00:02<00:00,  2.26it/s]\n",
      "[Epoch 492] Training (2957 Steps) (loss=0.32860): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 492] Training (2957 Steps) (loss=0.32860): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 493] Training (2958 Steps) (loss=0.12001):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 493] Training (2959 Steps) (loss=0.17593):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 493] Training (2960 Steps) (loss=0.11094):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 493] Training (2961 Steps) (loss=0.25819):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:51 (running for 00:02:40.96)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 493] Training (2962 Steps) (loss=0.11804):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 493] Training (2963 Steps) (loss=0.14877): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 493] Training (2963 Steps) (loss=0.14877): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 494] Training (2964 Steps) (loss=0.14592):  17%|█▋        | 1/6 [00:01<00:05,  1.04s/it]\n",
      "[Epoch 494] Training (2965 Steps) (loss=0.13002):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 494] Training (2966 Steps) (loss=0.15131):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 494] Training (2967 Steps) (loss=0.18969):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 494] Training (2968 Steps) (loss=0.10630):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 494] Training (2969 Steps) (loss=0.27071): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 494] Training (2969 Steps) (loss=0.27071): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 495] Training (2970 Steps) (loss=0.07952):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:01:56 (running for 00:02:45.98)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 495] Training (2971 Steps) (loss=0.07931):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 495] Training (2972 Steps) (loss=0.15244):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 495] Training (2973 Steps) (loss=0.20219):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 495] Training (2974 Steps) (loss=0.17200):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 495] Training (2975 Steps) (loss=0.15595): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 495] Training (2975 Steps) (loss=0.15595): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 496] Training (2976 Steps) (loss=0.14648):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 496] Training (2977 Steps) (loss=0.21500):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 496] Training (2978 Steps) (loss=0.18796):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 496] Training (2979 Steps) (loss=0.17864):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 496] Training (2980 Steps) (loss=0.11040):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 496] Training (2981 Steps) (loss=0.10735): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:01 (running for 00:02:50.98)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 496] Training (2981 Steps) (loss=0.10735): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 497] Training (2982 Steps) (loss=0.16662):  17%|█▋        | 1/6 [00:01<00:06,  1.20s/it]\n",
      "[Epoch 497] Training (2983 Steps) (loss=0.10961):  33%|███▎      | 2/6 [00:01<00:02,  1.38it/s]\n",
      "[Epoch 497] Training (2984 Steps) (loss=0.20922):  50%|█████     | 3/6 [00:01<00:01,  1.74it/s]\n",
      "[Epoch 497] Training (2985 Steps) (loss=0.09691):  67%|██████▋   | 4/6 [00:02<00:01,  2.00it/s]\n",
      "[Epoch 497] Training (2986 Steps) (loss=0.07206):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 497] Training (2987 Steps) (loss=0.10507): 100%|██████████| 6/6 [00:03<00:00,  2.29it/s]\n",
      "[Epoch 497] Training (2987 Steps) (loss=0.10507): 100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 498] Training (2988 Steps) (loss=0.08967):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 498] Training (2989 Steps) (loss=0.16924):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:06 (running for 00:02:56.00)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 498] Training (2990 Steps) (loss=0.13434):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 498] Training (2991 Steps) (loss=0.13165):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 498] Training (2992 Steps) (loss=0.10385):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 498] Training (2993 Steps) (loss=0.22343): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 498] Training (2993 Steps) (loss=0.22343): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 499] Training (2994 Steps) (loss=0.19765):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "[Epoch 499] Training (2995 Steps) (loss=0.13399):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "[Epoch 499] Training (2996 Steps) (loss=0.13883):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "[Epoch 499] Training (2997 Steps) (loss=0.18708):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 499] Training (2998 Steps) (loss=0.14392):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 499] Training (2999 Steps) (loss=0.12465): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 499] Training (2999 Steps) (loss=0.12465): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:11 (running for 00:03:01.01)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 500] Training (3000 Steps) (loss=0.19907):  17%|█▋        | 1/6 [00:01<00:05,  1.03s/it]\n",
      "[Epoch 500] Training (3001 Steps) (loss=0.12339):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 500] Training (3002 Steps) (loss=0.14783):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 500] Training (3003 Steps) (loss=0.15486):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 500] Training (3004 Steps) (loss=0.14341):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 500] Training (3005 Steps) (loss=0.29598): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 500] Training (3005 Steps) (loss=0.29598): 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validate (3006 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.48s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:16 (running for 00:03:06.02)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      2 |          116.124 |  0.876666 |   0.893611 |                  7 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Validate (3006 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]\n",
      "Validate (3006 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Early stop count:  8\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.8936110138893127 Current Avg. Dice: 0.8928300738334656\n",
      "Result for main_c206a_00026:\n",
      "  avg_acc: 0.8928300738334656\n",
      "  best_acc: 0.8936110138893127\n",
      "  date: 2023-01-04_05-02-17\n",
      "  done: false\n",
      "  early_stop_count: 8\n",
      "  experiment_id: f03a51b2ae254b1a8c917f778b2522cb\n",
      "  hostname: owo-785746fd58-zfbct\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.32.221.160\n",
      "  pid: 3450947\n",
      "  time_since_restore: 182.88430094718933\n",
      "  time_this_iter_s: 66.75992155075073\n",
      "  time_total_s: 182.88430094718933\n",
      "  timestamp: 1672808537\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c206a_00026\n",
      "  warmup_time: 0.0044095516204833984\n",
      "  \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Saving checkpoint ./models/final_model.pth\n",
      "[Epoch 501] Training (3006 Steps) (loss=0.11803):  17%|█▋        | 1/6 [00:00<00:04,  1.04it/s]\n",
      "[Epoch 501] Training (3007 Steps) (loss=0.09463):  33%|███▎      | 2/6 [00:01<00:02,  1.61it/s]\n",
      "[Epoch 501] Training (3008 Steps) (loss=0.11972):  50%|█████     | 3/6 [00:01<00:01,  1.94it/s]\n",
      "[Epoch 501] Training (3009 Steps) (loss=0.13285):  67%|██████▋   | 4/6 [00:02<00:00,  2.14it/s]\n",
      "[Epoch 501] Training (3010 Steps) (loss=0.14949):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 501] Training (3011 Steps) (loss=0.12896): 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n",
      "[Epoch 501] Training (3011 Steps) (loss=0.12896): 100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 502] Training (3012 Steps) (loss=0.12019):  17%|█▋        | 1/6 [00:00<00:04,  1.02it/s]\n",
      "[Epoch 502] Training (3013 Steps) (loss=0.15301):  33%|███▎      | 2/6 [00:01<00:02,  1.59it/s]\n",
      "[Epoch 502] Training (3014 Steps) (loss=0.10752):  50%|█████     | 3/6 [00:01<00:01,  1.92it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:22 (running for 00:03:12.63)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 502] Training (3015 Steps) (loss=0.09174):  67%|██████▋   | 4/6 [00:02<00:00,  2.13it/s]\n",
      "[Epoch 502] Training (3016 Steps) (loss=0.11213):  83%|████████▎ | 5/6 [00:02<00:00,  2.28it/s]\n",
      "[Epoch 502] Training (3017 Steps) (loss=0.11384): 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n",
      "[Epoch 502] Training (3017 Steps) (loss=0.11384): 100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 503] Training (3018 Steps) (loss=0.25167):  17%|█▋        | 1/6 [00:01<00:05,  1.04s/it]\n",
      "[Epoch 503] Training (3019 Steps) (loss=0.07510):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 503] Training (3020 Steps) (loss=0.10571):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 503] Training (3021 Steps) (loss=0.16558):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 503] Training (3022 Steps) (loss=0.32494):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 503] Training (3023 Steps) (loss=0.13538): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 503] Training (3023 Steps) (loss=0.13538): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:28 (running for 00:03:17.65)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 504] Training (3024 Steps) (loss=0.11239):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 504] Training (3025 Steps) (loss=0.18301):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 504] Training (3026 Steps) (loss=0.17614):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 504] Training (3027 Steps) (loss=0.14889):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 504] Training (3028 Steps) (loss=0.31960):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 504] Training (3029 Steps) (loss=0.16578): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 504] Training (3029 Steps) (loss=0.16578): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 505] Training (3030 Steps) (loss=0.13413):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 505] Training (3031 Steps) (loss=0.19993):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 505] Training (3032 Steps) (loss=0.14347):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 505] Training (3033 Steps) (loss=0.09919):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:33 (running for 00:03:22.66)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 505] Training (3034 Steps) (loss=0.07629):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 505] Training (3035 Steps) (loss=0.20084): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 505] Training (3035 Steps) (loss=0.20084): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 506] Training (3036 Steps) (loss=0.14891):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 506] Training (3037 Steps) (loss=0.21522):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 506] Training (3038 Steps) (loss=0.10189):  50%|█████     | 3/6 [00:01<00:01,  1.83it/s]\n",
      "[Epoch 506] Training (3039 Steps) (loss=0.50675):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 506] Training (3040 Steps) (loss=0.13170):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 506] Training (3041 Steps) (loss=0.17796): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 506] Training (3041 Steps) (loss=0.17796): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 507] Training (3042 Steps) (loss=0.15622):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:38 (running for 00:03:27.68)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 507] Training (3043 Steps) (loss=0.10531):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 507] Training (3044 Steps) (loss=0.19474):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 507] Training (3045 Steps) (loss=0.13714):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 507] Training (3046 Steps) (loss=0.28196):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 507] Training (3047 Steps) (loss=0.13512): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 507] Training (3047 Steps) (loss=0.13512): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 508] Training (3048 Steps) (loss=0.23506):  17%|█▋        | 1/6 [00:01<00:05,  1.20s/it]\n",
      "[Epoch 508] Training (3049 Steps) (loss=0.17184):  33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]\n",
      "[Epoch 508] Training (3050 Steps) (loss=0.09923):  50%|█████     | 3/6 [00:01<00:01,  1.76it/s]\n",
      "[Epoch 508] Training (3051 Steps) (loss=0.16910):  67%|██████▋   | 4/6 [00:02<00:00,  2.02it/s]\n",
      "[Epoch 508] Training (3052 Steps) (loss=0.10308):  83%|████████▎ | 5/6 [00:02<00:00,  2.19it/s]\n",
      "[Epoch 508] Training (3053 Steps) (loss=0.16562): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:43 (running for 00:03:32.68)\n",
      "Memory usage on this node: 22.4/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 508] Training (3053 Steps) (loss=0.16562): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 509] Training (3054 Steps) (loss=0.18626):  17%|█▋        | 1/6 [00:00<00:04,  1.02it/s]\n",
      "[Epoch 509] Training (3055 Steps) (loss=0.21208):  33%|███▎      | 2/6 [00:01<00:02,  1.58it/s]\n",
      "[Epoch 509] Training (3056 Steps) (loss=0.21705):  50%|█████     | 3/6 [00:01<00:01,  1.91it/s]\n",
      "[Epoch 509] Training (3057 Steps) (loss=0.12546):  67%|██████▋   | 4/6 [00:02<00:00,  2.13it/s]\n",
      "[Epoch 509] Training (3058 Steps) (loss=0.16370):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 509] Training (3059 Steps) (loss=0.14079): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 509] Training (3059 Steps) (loss=0.14079): 100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 510] Training (3060 Steps) (loss=0.13539):  17%|█▋        | 1/6 [00:01<00:06,  1.22s/it]\n",
      "[Epoch 510] Training (3061 Steps) (loss=0.21706):  33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]\n",
      "[Epoch 510] Training (3062 Steps) (loss=0.12421):  50%|█████     | 3/6 [00:01<00:01,  1.74it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:48 (running for 00:03:37.70)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 510] Training (3063 Steps) (loss=0.13763):  67%|██████▋   | 4/6 [00:02<00:01,  2.00it/s]\n",
      "[Epoch 510] Training (3064 Steps) (loss=0.08896):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 510] Training (3065 Steps) (loss=0.10850): 100%|██████████| 6/6 [00:03<00:00,  2.29it/s]\n",
      "[Epoch 510] Training (3065 Steps) (loss=0.10850): 100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 511] Training (3066 Steps) (loss=0.27682):  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]\n",
      "[Epoch 511] Training (3067 Steps) (loss=0.13677):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 511] Training (3068 Steps) (loss=0.16778):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 511] Training (3069 Steps) (loss=0.17661):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 511] Training (3070 Steps) (loss=0.19267):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 511] Training (3071 Steps) (loss=0.17121): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:53 (running for 00:03:42.70)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 512] Training (3072 Steps) (loss=0.15965):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 512] Training (3073 Steps) (loss=0.15252):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 512] Training (3074 Steps) (loss=0.10000):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 512] Training (3075 Steps) (loss=0.35364):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 512] Training (3076 Steps) (loss=0.10177):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 512] Training (3077 Steps) (loss=0.12293): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 512] Training (3077 Steps) (loss=0.12293): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 513] Training (3078 Steps) (loss=0.18650):  17%|█▋        | 1/6 [00:01<00:05,  1.04s/it]\n",
      "[Epoch 513] Training (3079 Steps) (loss=0.12543):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 513] Training (3080 Steps) (loss=0.16660):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 513] Training (3081 Steps) (loss=0.15885):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:02:58 (running for 00:03:47.72)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 513] Training (3082 Steps) (loss=0.14610):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 513] Training (3083 Steps) (loss=0.09342): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 513] Training (3083 Steps) (loss=0.09342): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 514] Training (3084 Steps) (loss=0.18189):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 514] Training (3085 Steps) (loss=0.08221):  33%|███▎      | 2/6 [00:01<00:02,  1.52it/s]\n",
      "[Epoch 514] Training (3086 Steps) (loss=0.07889):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 514] Training (3087 Steps) (loss=0.24394):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 514] Training (3088 Steps) (loss=0.12773):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 514] Training (3089 Steps) (loss=0.08810): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 514] Training (3089 Steps) (loss=0.08810): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 515] Training (3090 Steps) (loss=0.27761):  17%|█▋        | 1/6 [00:01<00:06,  1.22s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:03 (running for 00:03:52.73)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 515] Training (3091 Steps) (loss=0.16982):  33%|███▎      | 2/6 [00:01<00:02,  1.36it/s]\n",
      "[Epoch 515] Training (3092 Steps) (loss=0.16898):  50%|█████     | 3/6 [00:02<00:01,  1.74it/s]\n",
      "[Epoch 515] Training (3093 Steps) (loss=0.08494):  67%|██████▋   | 4/6 [00:02<00:01,  2.00it/s]\n",
      "[Epoch 515] Training (3094 Steps) (loss=0.13196):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 515] Training (3095 Steps) (loss=0.14716): 100%|██████████| 6/6 [00:03<00:00,  2.29it/s]\n",
      "[Epoch 515] Training (3095 Steps) (loss=0.14716): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 516] Training (3096 Steps) (loss=0.08297):  17%|█▋        | 1/6 [00:01<00:06,  1.33s/it]\n",
      "[Epoch 516] Training (3097 Steps) (loss=0.14970):  33%|███▎      | 2/6 [00:01<00:03,  1.28it/s]\n",
      "[Epoch 516] Training (3098 Steps) (loss=0.10454):  50%|█████     | 3/6 [00:02<00:01,  1.67it/s]\n",
      "[Epoch 516] Training (3099 Steps) (loss=0.09247):  67%|██████▋   | 4/6 [00:02<00:01,  1.93it/s]\n",
      "[Epoch 516] Training (3100 Steps) (loss=0.27491):  83%|████████▎ | 5/6 [00:02<00:00,  2.12it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:08 (running for 00:03:57.74)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 516] Training (3101 Steps) (loss=0.13176): 100%|██████████| 6/6 [00:03<00:00,  2.26it/s]\n",
      "[Epoch 516] Training (3101 Steps) (loss=0.13176): 100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 517] Training (3102 Steps) (loss=0.08978):  17%|█▋        | 1/6 [00:01<00:05,  1.03s/it]\n",
      "[Epoch 517] Training (3103 Steps) (loss=0.07307):  33%|███▎      | 2/6 [00:01<00:02,  1.53it/s]\n",
      "[Epoch 517] Training (3104 Steps) (loss=0.17327):  50%|█████     | 3/6 [00:01<00:01,  1.88it/s]\n",
      "[Epoch 517] Training (3105 Steps) (loss=0.15232):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 517] Training (3106 Steps) (loss=0.16380):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 517] Training (3107 Steps) (loss=0.20467): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 517] Training (3107 Steps) (loss=0.20467): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 518] Training (3108 Steps) (loss=0.26954):  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:13 (running for 00:04:02.75)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 518] Training (3109 Steps) (loss=0.09688):  33%|███▎      | 2/6 [00:01<00:02,  1.41it/s]\n",
      "[Epoch 518] Training (3110 Steps) (loss=0.15194):  50%|█████     | 3/6 [00:01<00:01,  1.77it/s]\n",
      "[Epoch 518] Training (3111 Steps) (loss=0.23410):  67%|██████▋   | 4/6 [00:02<00:00,  2.02it/s]\n",
      "[Epoch 518] Training (3112 Steps) (loss=0.11773):  83%|████████▎ | 5/6 [00:02<00:00,  2.19it/s]\n",
      "[Epoch 518] Training (3113 Steps) (loss=0.09652): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 518] Training (3113 Steps) (loss=0.09652): 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 519] Training (3114 Steps) (loss=0.14727):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 519] Training (3115 Steps) (loss=0.08756):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 519] Training (3116 Steps) (loss=0.11155):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 519] Training (3117 Steps) (loss=0.24833):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 519] Training (3118 Steps) (loss=0.14704):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 519] Training (3119 Steps) (loss=0.14164): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 519] Training (3119 Steps) (loss=0.14164): 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:18 (running for 00:04:07.76)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 520] Training (3120 Steps) (loss=0.13216):  17%|█▋        | 1/6 [00:00<00:04,  1.04it/s]\n",
      "[Epoch 520] Training (3121 Steps) (loss=0.12919):  33%|███▎      | 2/6 [00:01<00:02,  1.59it/s]\n",
      "[Epoch 520] Training (3122 Steps) (loss=0.14541):  50%|█████     | 3/6 [00:01<00:01,  1.92it/s]\n",
      "[Epoch 520] Training (3123 Steps) (loss=0.17862):  67%|██████▋   | 4/6 [00:02<00:00,  2.14it/s]\n",
      "[Epoch 520] Training (3124 Steps) (loss=0.28750):  83%|████████▎ | 5/6 [00:02<00:00,  2.28it/s]\n",
      "[Epoch 520] Training (3125 Steps) (loss=0.06539): 100%|██████████| 6/6 [00:02<00:00,  2.39it/s]\n",
      "[Epoch 520] Training (3125 Steps) (loss=0.06539): 100%|██████████| 6/6 [00:02<00:00,  2.00it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validate (3126 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.48s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:23 (running for 00:04:12.77)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      3 |          182.884 |  0.89283  |   0.893611 |                  8 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Validate (3126 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]\n",
      "Validate (3126 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Early stop count:  9\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.8936110138893127 Current Avg. Dice: 0.8882949352264404\n",
      "Result for main_c206a_00026:\n",
      "  avg_acc: 0.8882949352264404\n",
      "  best_acc: 0.8936110138893127\n",
      "  date: 2023-01-04_05-03-24\n",
      "  done: false\n",
      "  early_stop_count: 9\n",
      "  experiment_id: f03a51b2ae254b1a8c917f778b2522cb\n",
      "  hostname: owo-785746fd58-zfbct\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.32.221.160\n",
      "  pid: 3450947\n",
      "  time_since_restore: 249.68057370185852\n",
      "  time_this_iter_s: 66.79627275466919\n",
      "  time_total_s: 249.68057370185852\n",
      "  timestamp: 1672808604\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: c206a_00026\n",
      "  warmup_time: 0.0044095516204833984\n",
      "  \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Saving checkpoint ./models/final_model.pth\n",
      "[Epoch 521] Training (3126 Steps) (loss=0.17005):  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]\n",
      "[Epoch 521] Training (3127 Steps) (loss=0.15540):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 521] Training (3128 Steps) (loss=0.18672):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 521] Training (3129 Steps) (loss=0.06249):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 521] Training (3130 Steps) (loss=0.19778):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 521] Training (3131 Steps) (loss=0.17005): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 521] Training (3131 Steps) (loss=0.17005): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 522] Training (3132 Steps) (loss=0.13012):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 522] Training (3133 Steps) (loss=0.17501):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:29 (running for 00:04:19.44)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 522] Training (3134 Steps) (loss=0.12697):  50%|█████     | 3/6 [00:01<00:01,  1.84it/s]\n",
      "[Epoch 522] Training (3135 Steps) (loss=0.14708):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "[Epoch 522] Training (3136 Steps) (loss=0.12510):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 522] Training (3137 Steps) (loss=0.13494): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 522] Training (3137 Steps) (loss=0.13494): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 523] Training (3138 Steps) (loss=0.17373):  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\n",
      "[Epoch 523] Training (3139 Steps) (loss=0.15242):  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\n",
      "[Epoch 523] Training (3139 Steps) (loss=0.15242):  33%|███▎      | 2/6 [00:01<00:02,  1.44it/s]\n",
      "[Epoch 523] Training (3140 Steps) (loss=0.25442):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 523] Training (3141 Steps) (loss=0.08246):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 523] Training (3142 Steps) (loss=0.16999):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 523] Training (3143 Steps) (loss=0.13071): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 523] Training (3143 Steps) (loss=0.13071): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:34 (running for 00:04:24.45)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 524] Training (3144 Steps) (loss=0.11194):  17%|█▋        | 1/6 [00:01<00:05,  1.02s/it]\n",
      "[Epoch 524] Training (3145 Steps) (loss=0.15520):  33%|███▎      | 2/6 [00:01<00:02,  1.53it/s]\n",
      "[Epoch 524] Training (3146 Steps) (loss=0.11760):  50%|█████     | 3/6 [00:01<00:01,  1.89it/s]\n",
      "[Epoch 524] Training (3147 Steps) (loss=0.05490):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "[Epoch 524] Training (3148 Steps) (loss=0.13100):  83%|████████▎ | 5/6 [00:02<00:00,  2.26it/s]\n",
      "[Epoch 524] Training (3149 Steps) (loss=0.10509): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 524] Training (3149 Steps) (loss=0.10509): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 525] Training (3150 Steps) (loss=0.08811):  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\n",
      "[Epoch 525] Training (3151 Steps) (loss=0.12879):  33%|███▎      | 2/6 [00:01<00:02,  1.40it/s]\n",
      "[Epoch 525] Training (3152 Steps) (loss=0.26779):  50%|█████     | 3/6 [00:01<00:01,  1.77it/s]\n",
      "[Epoch 525] Training (3153 Steps) (loss=0.12219):  67%|██████▋   | 4/6 [00:02<00:00,  2.01it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:39 (running for 00:04:29.46)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 525] Training (3154 Steps) (loss=0.13266):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 525] Training (3155 Steps) (loss=0.13460): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 525] Training (3155 Steps) (loss=0.13460): 100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 526] Training (3156 Steps) (loss=0.15237):  17%|█▋        | 1/6 [00:01<00:06,  1.27s/it]\n",
      "[Epoch 526] Training (3157 Steps) (loss=0.17518):  33%|███▎      | 2/6 [00:01<00:03,  1.33it/s]\n",
      "[Epoch 526] Training (3158 Steps) (loss=0.14242):  50%|█████     | 3/6 [00:02<00:01,  1.70it/s]\n",
      "[Epoch 526] Training (3159 Steps) (loss=0.14360):  67%|██████▋   | 4/6 [00:02<00:01,  1.97it/s]\n",
      "[Epoch 526] Training (3160 Steps) (loss=0.09384):  83%|████████▎ | 5/6 [00:02<00:00,  2.14it/s]\n",
      "[Epoch 526] Training (3161 Steps) (loss=0.16660): 100%|██████████| 6/6 [00:03<00:00,  2.28it/s]\n",
      "[Epoch 526] Training (3161 Steps) (loss=0.16660): 100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:44 (running for 00:04:34.47)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 527] Training (3162 Steps) (loss=0.09391):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "[Epoch 527] Training (3163 Steps) (loss=0.14089):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 527] Training (3164 Steps) (loss=0.16167):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 527] Training (3165 Steps) (loss=0.10483):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 527] Training (3166 Steps) (loss=0.13744):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 527] Training (3167 Steps) (loss=0.04256): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 527] Training (3167 Steps) (loss=0.04256): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 528] Training (3168 Steps) (loss=0.07351):  17%|█▋        | 1/6 [00:01<00:06,  1.23s/it]\n",
      "[Epoch 528] Training (3169 Steps) (loss=0.09297):  33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]\n",
      "[Epoch 528] Training (3170 Steps) (loss=0.13604):  50%|█████     | 3/6 [00:02<00:01,  1.74it/s]\n",
      "[Epoch 528] Training (3171 Steps) (loss=0.12979):  67%|██████▋   | 4/6 [00:02<00:01,  1.99it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:49 (running for 00:04:39.48)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 528] Training (3172 Steps) (loss=0.09972):  83%|████████▎ | 5/6 [00:02<00:00,  2.16it/s]\n",
      "[Epoch 528] Training (3173 Steps) (loss=0.07145): 100%|██████████| 6/6 [00:03<00:00,  2.29it/s]\n",
      "[Epoch 528] Training (3173 Steps) (loss=0.07145): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 529] Training (3174 Steps) (loss=0.11218):  17%|█▋        | 1/6 [00:00<00:04,  1.01it/s]\n",
      "[Epoch 529] Training (3175 Steps) (loss=0.22714):  33%|███▎      | 2/6 [00:01<00:02,  1.57it/s]\n",
      "[Epoch 529] Training (3176 Steps) (loss=0.14418):  50%|█████     | 3/6 [00:01<00:01,  1.92it/s]\n",
      "[Epoch 529] Training (3177 Steps) (loss=0.07172):  67%|██████▋   | 4/6 [00:02<00:00,  2.13it/s]\n",
      "[Epoch 529] Training (3178 Steps) (loss=0.18925):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 529] Training (3179 Steps) (loss=0.13340): 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n",
      "[Epoch 529] Training (3179 Steps) (loss=0.13340): 100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 530] Training (3180 Steps) (loss=0.13176):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:54 (running for 00:04:44.49)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 530] Training (3181 Steps) (loss=0.11745):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 530] Training (3182 Steps) (loss=0.15615):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 530] Training (3183 Steps) (loss=0.13519):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 530] Training (3184 Steps) (loss=0.10878):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 530] Training (3185 Steps) (loss=0.13157): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 530] Training (3185 Steps) (loss=0.13157): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 531] Training (3186 Steps) (loss=0.14927):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 531] Training (3187 Steps) (loss=0.06717):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 531] Training (3188 Steps) (loss=0.21238):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 531] Training (3189 Steps) (loss=0.23329):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 531] Training (3190 Steps) (loss=0.15231):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 531] Training (3191 Steps) (loss=0.10845): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 531] Training (3191 Steps) (loss=0.10845): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:03:59 (running for 00:04:49.50)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 532] Training (3192 Steps) (loss=0.10382):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 532] Training (3193 Steps) (loss=0.12119):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 532] Training (3194 Steps) (loss=0.15058):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 532] Training (3195 Steps) (loss=0.13616):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 532] Training (3196 Steps) (loss=0.08861):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 532] Training (3197 Steps) (loss=0.09600): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 532] Training (3197 Steps) (loss=0.09600): 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 533] Training (3198 Steps) (loss=0.25364):  17%|█▋        | 1/6 [00:01<00:06,  1.20s/it]\n",
      "[Epoch 533] Training (3199 Steps) (loss=0.08495):  33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]\n",
      "[Epoch 533] Training (3200 Steps) (loss=0.13171):  50%|█████     | 3/6 [00:01<00:01,  1.75it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:04 (running for 00:04:54.51)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 533] Training (3201 Steps) (loss=0.12225):  67%|██████▋   | 4/6 [00:02<00:01,  2.00it/s]\n",
      "[Epoch 533] Training (3202 Steps) (loss=0.15626):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 533] Training (3203 Steps) (loss=0.16487): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 533] Training (3203 Steps) (loss=0.16487): 100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 534] Training (3204 Steps) (loss=0.12621):  17%|█▋        | 1/6 [00:01<00:05,  1.01s/it]\n",
      "[Epoch 534] Training (3205 Steps) (loss=0.10102):  33%|███▎      | 2/6 [00:01<00:02,  1.55it/s]\n",
      "[Epoch 534] Training (3206 Steps) (loss=0.12293):  50%|█████     | 3/6 [00:01<00:01,  1.89it/s]\n",
      "[Epoch 534] Training (3207 Steps) (loss=0.10155):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 534] Training (3208 Steps) (loss=0.16912):  83%|████████▎ | 5/6 [00:02<00:00,  2.26it/s]\n",
      "[Epoch 534] Training (3209 Steps) (loss=0.10908): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 534] Training (3209 Steps) (loss=0.10908): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:09 (running for 00:04:59.52)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 535] Training (3210 Steps) (loss=0.10613):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 535] Training (3211 Steps) (loss=0.13101):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 535] Training (3212 Steps) (loss=0.11452):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 535] Training (3213 Steps) (loss=0.14258):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 535] Training (3214 Steps) (loss=0.26887):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 535] Training (3215 Steps) (loss=0.11712): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 535] Training (3215 Steps) (loss=0.11712): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 536] Training (3216 Steps) (loss=0.14936):  17%|█▋        | 1/6 [00:01<00:06,  1.22s/it]\n",
      "[Epoch 536] Training (3217 Steps) (loss=0.11901):  33%|███▎      | 2/6 [00:01<00:02,  1.38it/s]\n",
      "[Epoch 536] Training (3218 Steps) (loss=0.11109):  50%|█████     | 3/6 [00:01<00:01,  1.75it/s]\n",
      "[Epoch 536] Training (3219 Steps) (loss=0.21204):  67%|██████▋   | 4/6 [00:02<00:01,  1.99it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:14 (running for 00:05:04.53)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 536] Training (3220 Steps) (loss=0.10571):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 536] Training (3221 Steps) (loss=0.11073): 100%|██████████| 6/6 [00:03<00:00,  2.29it/s]\n",
      "[Epoch 536] Training (3221 Steps) (loss=0.11073): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 537] Training (3222 Steps) (loss=0.10686):  17%|█▋        | 1/6 [00:00<00:04,  1.06it/s]\n",
      "[Epoch 537] Training (3223 Steps) (loss=0.11186):  33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]\n",
      "[Epoch 537] Training (3224 Steps) (loss=0.11776):  50%|█████     | 3/6 [00:01<00:01,  1.95it/s]\n",
      "[Epoch 537] Training (3225 Steps) (loss=0.16936):  67%|██████▋   | 4/6 [00:02<00:00,  2.15it/s]\n",
      "[Epoch 537] Training (3226 Steps) (loss=0.20472):  83%|████████▎ | 5/6 [00:02<00:00,  2.28it/s]\n",
      "[Epoch 537] Training (3227 Steps) (loss=0.08935): 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n",
      "[Epoch 537] Training (3227 Steps) (loss=0.08935): 100%|██████████| 6/6 [00:03<00:00,  2.00it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 538] Training (3228 Steps) (loss=0.10292):  17%|█▋        | 1/6 [00:01<00:05,  1.02s/it]\n",
      "[Epoch 538] Training (3229 Steps) (loss=0.08507):  33%|███▎      | 2/6 [00:01<00:02,  1.54it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:19 (running for 00:05:09.55)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 538] Training (3230 Steps) (loss=0.15354):  50%|█████     | 3/6 [00:01<00:01,  1.88it/s]\n",
      "[Epoch 538] Training (3231 Steps) (loss=0.11199):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "[Epoch 538] Training (3232 Steps) (loss=0.16586):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 538] Training (3233 Steps) (loss=0.36156): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 538] Training (3233 Steps) (loss=0.36156): 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 539] Training (3234 Steps) (loss=0.10245):  17%|█▋        | 1/6 [00:00<00:04,  1.03it/s]\n",
      "[Epoch 539] Training (3235 Steps) (loss=0.19882):  33%|███▎      | 2/6 [00:01<00:02,  1.58it/s]\n",
      "[Epoch 539] Training (3236 Steps) (loss=0.08503):  50%|█████     | 3/6 [00:01<00:01,  1.92it/s]\n",
      "[Epoch 539] Training (3237 Steps) (loss=0.09632):  67%|██████▋   | 4/6 [00:02<00:00,  2.13it/s]\n",
      "[Epoch 539] Training (3238 Steps) (loss=0.13196):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 539] Training (3239 Steps) (loss=0.18335): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 539] Training (3239 Steps) (loss=0.18335): 100%|██████████| 6/6 [00:03<00:00,  1.99it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:24 (running for 00:05:14.56)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 540] Training (3240 Steps) (loss=0.07473):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 540] Training (3241 Steps) (loss=0.11592):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 540] Training (3242 Steps) (loss=0.12158):  50%|█████     | 3/6 [00:01<00:01,  1.87it/s]\n",
      "[Epoch 540] Training (3243 Steps) (loss=0.17881):  67%|██████▋   | 4/6 [00:02<00:00,  2.10it/s]\n",
      "[Epoch 540] Training (3244 Steps) (loss=0.22089):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 540] Training (3245 Steps) (loss=0.23333): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 540] Training (3245 Steps) (loss=0.23333): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validate (3246 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.37s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:29 (running for 00:05:19.58)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      4 |          249.681 |  0.888295 |   0.893611 |                  9 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Validate (3246 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]\n",
      "Validate (3246 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Early stop count:  10\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.8936110138893127 Current Avg. Dice: 0.8888433575630188\n",
      "Result for main_c206a_00026:\n",
      "  avg_acc: 0.8888433575630188\n",
      "  best_acc: 0.8936110138893127\n",
      "  date: 2023-01-04_05-04-31\n",
      "  done: false\n",
      "  early_stop_count: 10\n",
      "  experiment_id: f03a51b2ae254b1a8c917f778b2522cb\n",
      "  hostname: owo-785746fd58-zfbct\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.32.221.160\n",
      "  pid: 3450947\n",
      "  time_since_restore: 316.35938334465027\n",
      "  time_this_iter_s: 66.67880964279175\n",
      "  time_total_s: 316.35938334465027\n",
      "  timestamp: 1672808671\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c206a_00026\n",
      "  warmup_time: 0.0044095516204833984\n",
      "  \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Saving checkpoint ./models/final_model.pth\n",
      "[Epoch 541] Training (3246 Steps) (loss=0.15784):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "[Epoch 541] Training (3247 Steps) (loss=0.09216):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 541] Training (3248 Steps) (loss=0.23908):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 541] Training (3249 Steps) (loss=0.15694):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 541] Training (3250 Steps) (loss=0.19794):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 541] Training (3251 Steps) (loss=0.08540): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 541] Training (3251 Steps) (loss=0.08540): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 542] Training (3252 Steps) (loss=0.11141):  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]\n",
      "[Epoch 542] Training (3253 Steps) (loss=0.12255):  33%|███▎      | 2/6 [00:01<00:02,  1.41it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:36 (running for 00:05:26.11)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 542] Training (3254 Steps) (loss=0.13129):  50%|█████     | 3/6 [00:01<00:01,  1.78it/s]\n",
      "[Epoch 542] Training (3255 Steps) (loss=0.10166):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 542] Training (3256 Steps) (loss=0.06452):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 542] Training (3257 Steps) (loss=0.16453): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 542] Training (3257 Steps) (loss=0.16453): 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 543] Training (3258 Steps) (loss=0.10915):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 543] Training (3259 Steps) (loss=0.20106):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 543] Training (3260 Steps) (loss=0.16271):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 543] Training (3261 Steps) (loss=0.14833):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 543] Training (3262 Steps) (loss=0.10744):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 543] Training (3263 Steps) (loss=0.18742): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 543] Training (3263 Steps) (loss=0.18742): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:41 (running for 00:05:31.12)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 544] Training (3264 Steps) (loss=0.27339):  17%|█▋        | 1/6 [00:01<00:06,  1.22s/it]\n",
      "[Epoch 544] Training (3265 Steps) (loss=0.09080):  33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]\n",
      "[Epoch 544] Training (3266 Steps) (loss=0.22120):  50%|█████     | 3/6 [00:01<00:01,  1.74it/s]\n",
      "[Epoch 544] Training (3267 Steps) (loss=0.12285):  67%|██████▋   | 4/6 [00:02<00:01,  1.99it/s]\n",
      "[Epoch 544] Training (3268 Steps) (loss=0.13373):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 544] Training (3269 Steps) (loss=0.12970): 100%|██████████| 6/6 [00:03<00:00,  2.29it/s]\n",
      "[Epoch 544] Training (3269 Steps) (loss=0.12970): 100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 545] Training (3270 Steps) (loss=0.10308):  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\n",
      "[Epoch 545] Training (3271 Steps) (loss=0.13570):  33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]\n",
      "[Epoch 545] Training (3272 Steps) (loss=0.11665):  50%|█████     | 3/6 [00:01<00:01,  1.77it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:46 (running for 00:05:36.13)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 545] Training (3273 Steps) (loss=0.05537):  67%|██████▋   | 4/6 [00:02<00:00,  2.02it/s]\n",
      "[Epoch 545] Training (3274 Steps) (loss=0.19168):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 545] Training (3275 Steps) (loss=0.14903): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 545] Training (3275 Steps) (loss=0.14903): 100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 546] Training (3276 Steps) (loss=0.09080):  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]\n",
      "[Epoch 546] Training (3277 Steps) (loss=0.09582):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 546] Training (3278 Steps) (loss=0.12392):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 546] Training (3279 Steps) (loss=0.14575):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 546] Training (3280 Steps) (loss=0.13805):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 546] Training (3281 Steps) (loss=0.16985): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 546] Training (3281 Steps) (loss=0.16985): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:51 (running for 00:05:41.14)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 547] Training (3282 Steps) (loss=0.09562):  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]\n",
      "[Epoch 547] Training (3283 Steps) (loss=0.14752):  33%|███▎      | 2/6 [00:01<00:02,  1.44it/s]\n",
      "[Epoch 547] Training (3284 Steps) (loss=0.11087):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 547] Training (3285 Steps) (loss=0.13041):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 547] Training (3286 Steps) (loss=0.19772):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 547] Training (3287 Steps) (loss=0.16947): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 547] Training (3287 Steps) (loss=0.16947): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 548] Training (3288 Steps) (loss=0.17362):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 548] Training (3289 Steps) (loss=0.14574):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 548] Training (3290 Steps) (loss=0.15625):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 548] Training (3291 Steps) (loss=0.17238):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:04:56 (running for 00:05:46.15)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 548] Training (3292 Steps) (loss=0.09430):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 548] Training (3293 Steps) (loss=0.18313): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 548] Training (3293 Steps) (loss=0.18313): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 549] Training (3294 Steps) (loss=0.12801):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "[Epoch 549] Training (3295 Steps) (loss=0.13687):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 549] Training (3296 Steps) (loss=0.10382):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 549] Training (3297 Steps) (loss=0.13158):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 549] Training (3298 Steps) (loss=0.16798):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 549] Training (3299 Steps) (loss=0.08293): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 549] Training (3299 Steps) (loss=0.08293): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 550] Training (3300 Steps) (loss=0.13924):  17%|█▋        | 1/6 [00:01<00:05,  1.02s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:01 (running for 00:05:51.17)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 550] Training (3301 Steps) (loss=0.29951):  33%|███▎      | 2/6 [00:01<00:02,  1.54it/s]\n",
      "[Epoch 550] Training (3302 Steps) (loss=0.09731):  50%|█████     | 3/6 [00:01<00:01,  1.89it/s]\n",
      "[Epoch 550] Training (3303 Steps) (loss=0.12831):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "[Epoch 550] Training (3304 Steps) (loss=0.16207):  83%|████████▎ | 5/6 [00:02<00:00,  2.26it/s]\n",
      "[Epoch 550] Training (3305 Steps) (loss=0.11099): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 550] Training (3305 Steps) (loss=0.11099): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 551] Training (3306 Steps) (loss=0.18500):  17%|█▋        | 1/6 [00:01<00:05,  1.07s/it]\n",
      "[Epoch 551] Training (3307 Steps) (loss=0.13259):  33%|███▎      | 2/6 [00:01<00:02,  1.49it/s]\n",
      "[Epoch 551] Training (3308 Steps) (loss=0.07609):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 551] Training (3309 Steps) (loss=0.06198):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 551] Training (3310 Steps) (loss=0.18782):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 551] Training (3311 Steps) (loss=0.20235): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 551] Training (3311 Steps) (loss=0.20235): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:06 (running for 00:05:56.17)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 552] Training (3312 Steps) (loss=0.15715):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 552] Training (3313 Steps) (loss=0.08647):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 552] Training (3314 Steps) (loss=0.09142):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 552] Training (3315 Steps) (loss=0.12304):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 552] Training (3316 Steps) (loss=0.19106):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 552] Training (3317 Steps) (loss=0.15748): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 552] Training (3317 Steps) (loss=0.15748): 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 553] Training (3318 Steps) (loss=0.17934):  17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\n",
      "[Epoch 553] Training (3319 Steps) (loss=0.11874):  33%|███▎      | 2/6 [00:01<00:02,  1.40it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:11 (running for 00:06:01.19)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 553] Training (3320 Steps) (loss=0.12262):  50%|█████     | 3/6 [00:01<00:01,  1.76it/s]\n",
      "[Epoch 553] Training (3321 Steps) (loss=0.12034):  67%|██████▋   | 4/6 [00:02<00:00,  2.01it/s]\n",
      "[Epoch 553] Training (3322 Steps) (loss=0.07363):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 553] Training (3323 Steps) (loss=0.11006): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 553] Training (3323 Steps) (loss=0.11006): 100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 554] Training (3324 Steps) (loss=0.14060):  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]\n",
      "[Epoch 554] Training (3325 Steps) (loss=0.10831):  33%|███▎      | 2/6 [00:01<00:02,  1.44it/s]\n",
      "[Epoch 554] Training (3326 Steps) (loss=0.12554):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "[Epoch 554] Training (3327 Steps) (loss=0.07850):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 554] Training (3328 Steps) (loss=0.19412):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 554] Training (3329 Steps) (loss=0.19686): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 554] Training (3329 Steps) (loss=0.19686): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:16 (running for 00:06:06.20)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 555] Training (3330 Steps) (loss=0.14339):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "[Epoch 555] Training (3331 Steps) (loss=0.09075):  33%|███▎      | 2/6 [00:01<00:02,  1.41it/s]\n",
      "[Epoch 555] Training (3332 Steps) (loss=0.08506):  50%|█████     | 3/6 [00:01<00:01,  1.78it/s]\n",
      "[Epoch 555] Training (3333 Steps) (loss=0.12425):  67%|██████▋   | 4/6 [00:02<00:00,  2.02it/s]\n",
      "[Epoch 555] Training (3334 Steps) (loss=0.17142):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 555] Training (3335 Steps) (loss=0.19465): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 555] Training (3335 Steps) (loss=0.19465): 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 556] Training (3336 Steps) (loss=0.15923):  17%|█▋        | 1/6 [00:00<00:04,  1.01it/s]\n",
      "[Epoch 556] Training (3337 Steps) (loss=0.09575):  33%|███▎      | 2/6 [00:01<00:02,  1.56it/s]\n",
      "[Epoch 556] Training (3338 Steps) (loss=0.11022):  50%|█████     | 3/6 [00:01<00:01,  1.90it/s]\n",
      "[Epoch 556] Training (3339 Steps) (loss=0.18556):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:21 (running for 00:06:11.21)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 556] Training (3340 Steps) (loss=0.10850):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 556] Training (3341 Steps) (loss=0.13323): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 556] Training (3341 Steps) (loss=0.13323): 100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 557] Training (3342 Steps) (loss=0.08552):  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]\n",
      "[Epoch 557] Training (3343 Steps) (loss=0.09844):  33%|███▎      | 2/6 [00:01<00:02,  1.47it/s]\n",
      "[Epoch 557] Training (3344 Steps) (loss=0.15656):  50%|█████     | 3/6 [00:01<00:01,  1.83it/s]\n",
      "[Epoch 557] Training (3345 Steps) (loss=0.24870):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "[Epoch 557] Training (3346 Steps) (loss=0.19466):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 557] Training (3347 Steps) (loss=0.23437): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 557] Training (3347 Steps) (loss=0.23437): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 558] Training (3348 Steps) (loss=0.12372):  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:26 (running for 00:06:16.22)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 558] Training (3349 Steps) (loss=0.11694):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "[Epoch 558] Training (3350 Steps) (loss=0.16307):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "[Epoch 558] Training (3351 Steps) (loss=0.15642):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 558] Training (3352 Steps) (loss=0.13182):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 558] Training (3353 Steps) (loss=0.17929): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 558] Training (3353 Steps) (loss=0.17929): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 559] Training (3354 Steps) (loss=0.14709):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 559] Training (3355 Steps) (loss=0.12940):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 559] Training (3356 Steps) (loss=0.12103):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 559] Training (3357 Steps) (loss=0.24183):  67%|██████▋   | 4/6 [00:02<00:00,  2.08it/s]\n",
      "[Epoch 559] Training (3358 Steps) (loss=0.07617):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:31 (running for 00:06:21.23)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 559] Training (3359 Steps) (loss=0.10321): 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "[Epoch 559] Training (3359 Steps) (loss=0.10321): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 560] Training (3360 Steps) (loss=0.07217):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 560] Training (3361 Steps) (loss=0.12699):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 560] Training (3362 Steps) (loss=0.14601):  50%|█████     | 3/6 [00:01<00:01,  1.83it/s]\n",
      "[Epoch 560] Training (3363 Steps) (loss=0.10229):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 560] Training (3364 Steps) (loss=0.13345):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 560] Training (3365 Steps) (loss=0.10074): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 560] Training (3365 Steps) (loss=0.10074): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validate (3366 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.51s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:36 (running for 00:06:26.24)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      5 |          316.359 |  0.888843 |   0.893611 |                 10 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |         2674.48  |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |         1831.41  |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |         2674.38  |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |         2637.93  |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |         1285.58  |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |         3369.04  |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |         3779.88  |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |         4651.93  |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |         3584.62  |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |         3189.39  |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |         1806.32  |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |         1983.92  |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |         2110.77  |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |         1662.24  |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |         2654.87  |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |         3151.9   |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "Validate (3366 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n",
      "Validate (3366 / 10 Steps): 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Early stop count:  11\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.8936110138893127 Current Avg. Dice: 0.8912878632545471\n",
      "Result for main_c206a_00026:\n",
      "  avg_acc: 0.8912878632545471\n",
      "  best_acc: 0.8936110138893127\n",
      "  date: 2023-01-04_05-05-38\n",
      "  done: false\n",
      "  early_stop_count: 11\n",
      "  experiment_id: f03a51b2ae254b1a8c917f778b2522cb\n",
      "  hostname: owo-785746fd58-zfbct\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.32.221.160\n",
      "  pid: 3450947\n",
      "  time_since_restore: 383.70970702171326\n",
      "  time_this_iter_s: 67.35032367706299\n",
      "  time_total_s: 383.70970702171326\n",
      "  timestamp: 1672808738\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: c206a_00026\n",
      "  warmup_time: 0.0044095516204833984\n",
      "  \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(main pid=3450947)\u001b[0m Saving checkpoint ./models/final_model.pth\n",
      "[Epoch 561] Training (3366 Steps) (loss=0.14573):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 561] Training (3367 Steps) (loss=0.12644):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 561] Training (3368 Steps) (loss=0.26111):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "[Epoch 561] Training (3369 Steps) (loss=0.17064):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "[Epoch 561] Training (3370 Steps) (loss=0.15507):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 561] Training (3371 Steps) (loss=0.20260): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 561] Training (3371 Steps) (loss=0.20260): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 562] Training (3372 Steps) (loss=0.27179):  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\n",
      "[Epoch 562] Training (3373 Steps) (loss=0.14054):  33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:43 (running for 00:06:33.47)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 562] Training (3374 Steps) (loss=0.21161):  50%|█████     | 3/6 [00:01<00:01,  1.75it/s]\n",
      "[Epoch 562] Training (3375 Steps) (loss=0.09976):  67%|██████▋   | 4/6 [00:02<00:00,  2.01it/s]\n",
      "[Epoch 562] Training (3376 Steps) (loss=0.11064):  83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]\n",
      "[Epoch 562] Training (3377 Steps) (loss=0.14163): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 562] Training (3377 Steps) (loss=0.14163): 100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 563] Training (3378 Steps) (loss=0.07748):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "[Epoch 563] Training (3379 Steps) (loss=0.19489):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 563] Training (3380 Steps) (loss=0.10867):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "[Epoch 563] Training (3381 Steps) (loss=0.08241):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "[Epoch 563] Training (3382 Steps) (loss=0.24798):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 563] Training (3383 Steps) (loss=0.20953): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 563] Training (3383 Steps) (loss=0.20953): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:48 (running for 00:06:38.47)\n",
      "Memory usage on this node: 22.9/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 564] Training (3384 Steps) (loss=0.12686):  17%|█▋        | 1/6 [00:01<00:05,  1.09s/it]\n",
      "[Epoch 564] Training (3385 Steps) (loss=0.12419):  33%|███▎      | 2/6 [00:01<00:02,  1.47it/s]\n",
      "[Epoch 564] Training (3386 Steps) (loss=0.21581):  50%|█████     | 3/6 [00:01<00:01,  1.83it/s]\n",
      "[Epoch 564] Training (3387 Steps) (loss=0.19017):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "[Epoch 564] Training (3388 Steps) (loss=0.10244):  83%|████████▎ | 5/6 [00:02<00:00,  2.23it/s]\n",
      "[Epoch 564] Training (3389 Steps) (loss=0.12879): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 564] Training (3389 Steps) (loss=0.12879): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 565] Training (3390 Steps) (loss=0.27964):  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\n",
      "[Epoch 565] Training (3391 Steps) (loss=0.12515):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "[Epoch 565] Training (3392 Steps) (loss=0.14481):  50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\n",
      "[Epoch 565] Training (3393 Steps) (loss=0.10987):  67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:53 (running for 00:06:43.49)\n",
      "Memory usage on this node: 22.6/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 565] Training (3394 Steps) (loss=0.15063):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 565] Training (3395 Steps) (loss=0.13614): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 565] Training (3395 Steps) (loss=0.13614): 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 566] Training (3396 Steps) (loss=0.13064):   0%|          | 0/6 [00:01<?, ?it/s]\n",
      "[Epoch 566] Training (3396 Steps) (loss=0.13064):  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\n",
      "[Epoch 566] Training (3397 Steps) (loss=0.07661):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 566] Training (3398 Steps) (loss=0.13498):  50%|█████     | 3/6 [00:01<00:01,  1.81it/s]\n",
      "[Epoch 566] Training (3399 Steps) (loss=0.08728):  67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\n",
      "[Epoch 566] Training (3400 Steps) (loss=0.11991):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 566] Training (3401 Steps) (loss=0.15335): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 566] Training (3401 Steps) (loss=0.15335): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:05:58 (running for 00:06:48.49)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 567] Training (3402 Steps) (loss=0.10799):  17%|█▋        | 1/6 [00:01<00:06,  1.20s/it]\n",
      "[Epoch 567] Training (3403 Steps) (loss=0.11568):  33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]\n",
      "[Epoch 567] Training (3404 Steps) (loss=0.06422):  50%|█████     | 3/6 [00:01<00:01,  1.76it/s]\n",
      "[Epoch 567] Training (3405 Steps) (loss=0.14121):  67%|██████▋   | 4/6 [00:02<00:00,  2.01it/s]\n",
      "[Epoch 567] Training (3406 Steps) (loss=0.15053):  83%|████████▎ | 5/6 [00:02<00:00,  2.17it/s]\n",
      "[Epoch 567] Training (3407 Steps) (loss=0.08659): 100%|██████████| 6/6 [00:03<00:00,  2.30it/s]\n",
      "[Epoch 567] Training (3407 Steps) (loss=0.08659): 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 568] Training (3408 Steps) (loss=0.08195):  17%|█▋        | 1/6 [00:01<00:06,  1.25s/it]\n",
      "[Epoch 568] Training (3409 Steps) (loss=0.11022):  33%|███▎      | 2/6 [00:01<00:02,  1.34it/s]\n",
      "[Epoch 568] Training (3410 Steps) (loss=0.13730):  50%|█████     | 3/6 [00:02<00:01,  1.71it/s]\n",
      "[Epoch 568] Training (3411 Steps) (loss=0.16743):  67%|██████▋   | 4/6 [00:02<00:01,  1.97it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:03 (running for 00:06:53.51)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 568] Training (3412 Steps) (loss=0.12222):  83%|████████▎ | 5/6 [00:02<00:00,  2.15it/s]\n",
      "[Epoch 568] Training (3413 Steps) (loss=0.12585): 100%|██████████| 6/6 [00:03<00:00,  2.28it/s]\n",
      "[Epoch 568] Training (3413 Steps) (loss=0.12585): 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 569] Training (3414 Steps) (loss=0.18071):  17%|█▋        | 1/6 [00:01<00:05,  1.01s/it]\n",
      "[Epoch 569] Training (3415 Steps) (loss=0.08595):  33%|███▎      | 2/6 [00:01<00:02,  1.54it/s]\n",
      "[Epoch 569] Training (3416 Steps) (loss=0.16726):  50%|█████     | 3/6 [00:01<00:01,  1.89it/s]\n",
      "[Epoch 569] Training (3417 Steps) (loss=0.09760):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "[Epoch 569] Training (3418 Steps) (loss=0.19753):  83%|████████▎ | 5/6 [00:02<00:00,  2.26it/s]\n",
      "[Epoch 569] Training (3419 Steps) (loss=0.08979): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 569] Training (3419 Steps) (loss=0.08979): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 570] Training (3420 Steps) (loss=0.13730):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:08 (running for 00:06:58.52)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 570] Training (3421 Steps) (loss=0.09789):  33%|███▎      | 2/6 [00:01<00:02,  1.42it/s]\n",
      "[Epoch 570] Training (3422 Steps) (loss=0.12411):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 570] Training (3423 Steps) (loss=0.07996):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 570] Training (3424 Steps) (loss=0.15534):  83%|████████▎ | 5/6 [00:02<00:00,  2.19it/s]\n",
      "[Epoch 570] Training (3425 Steps) (loss=0.10071): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 570] Training (3425 Steps) (loss=0.10071): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 571] Training (3426 Steps) (loss=0.13059):  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]\n",
      "[Epoch 571] Training (3427 Steps) (loss=0.09974):  33%|███▎      | 2/6 [00:01<00:02,  1.41it/s]\n",
      "[Epoch 571] Training (3428 Steps) (loss=0.09914):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 571] Training (3429 Steps) (loss=0.22012):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 571] Training (3430 Steps) (loss=0.19279):  83%|████████▎ | 5/6 [00:02<00:00,  2.19it/s]\n",
      "[Epoch 571] Training (3431 Steps) (loss=0.05817): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:13 (running for 00:07:03.53)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 571] Training (3431 Steps) (loss=0.05817): 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 572] Training (3432 Steps) (loss=0.09891):  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\n",
      "[Epoch 572] Training (3433 Steps) (loss=0.29977):  33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "[Epoch 572] Training (3434 Steps) (loss=0.16054):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 572] Training (3435 Steps) (loss=0.08900):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 572] Training (3436 Steps) (loss=0.13862):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 572] Training (3437 Steps) (loss=0.16814): 100%|██████████| 6/6 [00:03<00:00,  2.34it/s]\n",
      "[Epoch 572] Training (3437 Steps) (loss=0.16814): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 573] Training (3438 Steps) (loss=0.12512):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "[Epoch 573] Training (3439 Steps) (loss=0.10973):  33%|███▎      | 2/6 [00:01<00:02,  1.41it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:18 (running for 00:07:08.54)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 573] Training (3440 Steps) (loss=0.07631):  50%|█████     | 3/6 [00:01<00:01,  1.78it/s]\n",
      "[Epoch 573] Training (3441 Steps) (loss=0.15557):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 573] Training (3442 Steps) (loss=0.16400):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 573] Training (3443 Steps) (loss=0.26010): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 573] Training (3443 Steps) (loss=0.26010): 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 574] Training (3444 Steps) (loss=0.12952):  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]\n",
      "[Epoch 574] Training (3445 Steps) (loss=0.09669):  33%|███▎      | 2/6 [00:01<00:02,  1.46it/s]\n",
      "[Epoch 574] Training (3446 Steps) (loss=0.17641):  50%|█████     | 3/6 [00:01<00:01,  1.82it/s]\n",
      "[Epoch 574] Training (3447 Steps) (loss=0.22238):  67%|██████▋   | 4/6 [00:02<00:00,  2.06it/s]\n",
      "[Epoch 574] Training (3448 Steps) (loss=0.08869):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "[Epoch 574] Training (3449 Steps) (loss=0.06836): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 574] Training (3449 Steps) (loss=0.06836): 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:23 (running for 00:07:13.55)\n",
      "Memory usage on this node: 22.8/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 575] Training (3450 Steps) (loss=0.11336):  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]\n",
      "[Epoch 575] Training (3451 Steps) (loss=0.11772):  33%|███▎      | 2/6 [00:01<00:02,  1.41it/s]\n",
      "[Epoch 575] Training (3452 Steps) (loss=0.21148):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 575] Training (3453 Steps) (loss=0.09733):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 575] Training (3454 Steps) (loss=0.12433):  83%|████████▎ | 5/6 [00:02<00:00,  2.20it/s]\n",
      "[Epoch 575] Training (3455 Steps) (loss=0.11553): 100%|██████████| 6/6 [00:03<00:00,  2.31it/s]\n",
      "[Epoch 575] Training (3455 Steps) (loss=0.11553): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 576] Training (3456 Steps) (loss=0.13272):  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]\n",
      "[Epoch 576] Training (3457 Steps) (loss=0.08005):  33%|███▎      | 2/6 [00:01<00:02,  1.50it/s]\n",
      "[Epoch 576] Training (3458 Steps) (loss=0.11624):  50%|█████     | 3/6 [00:01<00:01,  1.85it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:28 (running for 00:07:18.56)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 576] Training (3459 Steps) (loss=0.13049):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 576] Training (3460 Steps) (loss=0.16928):  83%|████████▎ | 5/6 [00:02<00:00,  2.24it/s]\n",
      "[Epoch 576] Training (3461 Steps) (loss=0.16378): 100%|██████████| 6/6 [00:03<00:00,  2.35it/s]\n",
      "[Epoch 576] Training (3461 Steps) (loss=0.16378): 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 577] Training (3462 Steps) (loss=0.10486):  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\n",
      "[Epoch 577] Training (3463 Steps) (loss=0.09956):  33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "[Epoch 577] Training (3464 Steps) (loss=0.23982):  50%|█████     | 3/6 [00:01<00:01,  1.79it/s]\n",
      "[Epoch 577] Training (3465 Steps) (loss=0.11942):  67%|██████▋   | 4/6 [00:02<00:00,  2.03it/s]\n",
      "[Epoch 577] Training (3466 Steps) (loss=0.10672):  83%|████████▎ | 5/6 [00:02<00:00,  2.21it/s]\n",
      "[Epoch 577] Training (3467 Steps) (loss=0.10715): 100%|██████████| 6/6 [00:03<00:00,  2.32it/s]\n",
      "[Epoch 577] Training (3467 Steps) (loss=0.10715): 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:33 (running for 00:07:23.57)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 578] Training (3468 Steps) (loss=0.12546):  17%|█▋        | 1/6 [00:01<00:05,  1.01s/it]\n",
      "[Epoch 578] Training (3469 Steps) (loss=0.13288):  33%|███▎      | 2/6 [00:01<00:02,  1.55it/s]\n",
      "[Epoch 578] Training (3470 Steps) (loss=0.13142):  50%|█████     | 3/6 [00:01<00:01,  1.89it/s]\n",
      "[Epoch 578] Training (3471 Steps) (loss=0.11351):  67%|██████▋   | 4/6 [00:02<00:00,  2.11it/s]\n",
      "[Epoch 578] Training (3472 Steps) (loss=0.06449):  83%|████████▎ | 5/6 [00:02<00:00,  2.27it/s]\n",
      "[Epoch 578] Training (3473 Steps) (loss=0.24123): 100%|██████████| 6/6 [00:02<00:00,  2.36it/s]\n",
      "[Epoch 578] Training (3473 Steps) (loss=0.24123): 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 579] Training (3474 Steps) (loss=0.10259):  17%|█▋        | 1/6 [00:01<00:05,  1.08s/it]\n",
      "[Epoch 579] Training (3475 Steps) (loss=0.16632):  33%|███▎      | 2/6 [00:01<00:02,  1.47it/s]\n",
      "[Epoch 579] Training (3476 Steps) (loss=0.12845):  50%|█████     | 3/6 [00:01<00:01,  1.83it/s]\n",
      "[Epoch 579] Training (3477 Steps) (loss=0.12598):  67%|██████▋   | 4/6 [00:02<00:00,  2.07it/s]\n",
      "[Epoch 579] Training (3478 Steps) (loss=0.13326):  83%|████████▎ | 5/6 [00:02<00:00,  2.22it/s]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:38 (running for 00:07:28.58)\n",
      "Memory usage on this node: 22.7/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n",
      "[Epoch 579] Training (3479 Steps) (loss=0.07799): 100%|██████████| 6/6 [00:03<00:00,  2.33it/s]\n",
      "[Epoch 579] Training (3479 Steps) (loss=0.07799): 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "[Epoch 580] Training (3480 Steps) (loss=0.12487):  17%|█▋        | 1/6 [00:01<00:05,  1.05s/it]\n",
      "[Epoch 580] Training (3481 Steps) (loss=0.12189):  33%|███▎      | 2/6 [00:01<00:02,  1.51it/s]\n",
      "[Epoch 580] Training (3482 Steps) (loss=0.13092):  50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\n",
      "[Epoch 580] Training (3483 Steps) (loss=0.10083):  67%|██████▋   | 4/6 [00:02<00:00,  2.09it/s]\n",
      "[Epoch 580] Training (3484 Steps) (loss=0.11931):  83%|████████▎ | 5/6 [00:02<00:00,  2.25it/s]\n",
      "[Epoch 580] Training (3485 Steps) (loss=0.26421): 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "[Epoch 580] Training (3485 Steps) (loss=0.26421): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validate (3486 / 10 Steps):  50%|█████     | 1/2 [00:01<00:01,  1.43s/it]\n",
      "== Status ==\n",
      "Current time: 2023-01-04 05:06:43 (running for 00:07:33.59)\n",
      "Memory usage on this node: 22.5/503.8 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/20.84 GiB heap, 0.0/10.42 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t6\n",
      "Number of trials: 30/30 (3 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "| Trial name       | status     | loc                   | lrschedule           |   max_early_stop_count | optim                | transform            |   iter |   total time (s) |   avg_acc |   best_acc |   early_stop_count |\n",
      "|------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------|\n",
      "| main_c206a_00026 | RUNNING    | 10.32.221.160:3450947 | {'warmup_epochs_cb40 |                     20 | {'optim_lr': 0._ca40 | {'a_min': 32, '_c240 |      6 |           383.71 |  0.891288 |   0.893611 |                 11 |\n",
      "| main_c206a_00027 | PENDING    |                       | {'warmup_epochs_3e40 |                     20 | {'optim_lr': 0._3d40 | {'a_min': 32, '_3540 |        |                  |           |            |                    |\n",
      "| main_c206a_00028 | PENDING    |                       | {'warmup_epochs_7540 |                     20 | {'optim_lr': 0._75c0 | {'a_min': 32, '_0080 |        |                  |           |            |                    |\n",
      "| main_c206a_00029 | PENDING    |                       | {'warmup_epochs_a6c0 |                     20 | {'optim_lr': 0._a5c0 | {'a_min': 32, '_f040 |        |                  |           |            |                    |\n",
      "| main_c206a_00000 | TERMINATED | 10.32.221.160:63579   | {'warmup_epochs_ea80 |                     10 | {'optim_lr': 0._ec00 | {'a_min': 32, '_c640 |     39 |          2674.48 |  0.895483 |   0.904971 |                 10 |\n",
      "| main_c206a_00001 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_a340 |                     10 | {'optim_lr': 0._a240 | {'a_min': 32, '_8a00 |     26 |          1831.41 |  0.894089 |   0.898971 |                 10 |\n",
      "| main_c206a_00002 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_3700 |                     10 | {'optim_lr': 0._3380 | {'a_min': 32, '_3b80 |     39 |          2674.38 |  0.892412 |   0.905787 |                 10 |\n",
      "| main_c206a_00003 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5840 |                     10 | {'optim_lr': 0._5740 | {'a_min': 32, '_1f00 |     38 |          2637.93 |  0.895172 |   0.899276 |                 10 |\n",
      "| main_c206a_00004 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_f540 |                     10 | {'optim_lr': 0._f440 | {'a_min': 32, '_8c00 |     18 |          1285.58 |  0.856042 |   0.88901  |                 10 |\n",
      "| main_c206a_00005 | TERMINATED | 10.32.221.160:193983  | {'warmup_epochs_1bc0 |                     20 | {'optim_lr': 0._1f00 | {'a_min': 32, '_e700 |     49 |          3369.04 |  0.894665 |   0.900948 |                 20 |\n",
      "| main_c206a_00006 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8ac0 |                     20 | {'optim_lr': 0._8800 | {'a_min': 32, '_d700 |     55 |          3779.88 |  0.894861 |   0.905364 |                 20 |\n",
      "| main_c206a_00007 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_5b40 |                     20 | {'optim_lr': 0._5a40 | {'a_min': 32, '_6800 |     67 |          4651.93 |  0.892643 |   0.90195  |                 20 |\n",
      "| main_c206a_00008 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_1940 |                     20 | {'optim_lr': 0._11c0 | {'a_min': 32, '_4800 |     52 |          3584.62 |  0.893551 |   0.899705 |                 20 |\n",
      "| main_c206a_00009 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_51c0 |                     20 | {'optim_lr': 0._50c0 | {'a_min': 32, '_4e80 |     46 |          3189.39 |  0.903065 |   0.904677 |                 20 |\n",
      "| main_c206a_00010 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_ac00 |                     10 | {'optim_lr': 0._a500 | {'a_min': 32, '_5680 |     26 |          1806.32 |  0.8918   |   0.896496 |                 10 |\n",
      "| main_c206a_00011 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_8040 |                     10 | {'optim_lr': 0._8200 | {'a_min': 32, '_7c00 |     28 |          1983.92 |  0.879016 |   0.901394 |                 10 |\n",
      "| main_c206a_00012 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_4ac0 |                     10 | {'optim_lr': 0._4a00 | {'a_min': 32, '_4a40 |     30 |          2110.77 |  0.888223 |   0.897717 |                 10 |\n",
      "| main_c206a_00013 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_b5c0 |                     10 | {'optim_lr': 0._b800 | {'a_min': 32, '_b500 |     24 |          1662.24 |  0.880807 |   0.897455 |                 10 |\n",
      "| main_c206a_00014 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_7240 |                     10 | {'optim_lr': 0._7140 | {'a_min': 32, '_4900 |     39 |          2654.87 |  0.889765 |   0.904094 |                 10 |\n",
      "| main_c206a_00015 | TERMINATED | 10.32.221.160:488872  | {'warmup_epochs_6c80 |                     20 | {'optim_lr': 0._6980 | {'a_min': 32, '_0dc0 |     45 |          3151.9  |  0.892558 |   0.906717 |                 20 |\n",
      "+------------------+------------+-----------------------+----------------------+------------------------+----------------------+----------------------+--------+------------------+-----------+------------+--------------------+\n",
      "... 10 more trials not shown (10 TERMINATED)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "!PYTHONPATH=/nfs/Workspace/CardiacSeg /opt/conda/bin/python /nfs/Workspace/CardiacSeg/expers/chgh/tune.py \\\n",
    "--exp_name={exp_name} \\\n",
    "--local_dir={root_dir} \\\n",
    "--model_name={model_name}\\\n",
    "--data_dir={data_dir} \\\n",
    "--model_dir={model_dir} \\\n",
    "--log_dir={log_dir} \\\n",
    "--start_epoch=0 \\\n",
    "--val_every=20 \\\n",
    "--max_epoch=8000 \\\n",
    "--optim_lr=1e-4 \\\n",
    "--pin_memory \\\n",
    "--num_fold=3 \\\n",
    "--fold=2 \\\n",
    "--split_train_ratio=0.75 \\\n",
    "--data_dicts_json={data_dicts_json} \\\n",
    "--max_early_stop_count=10 \\\n",
    "--tune_mode={tune_mode} \\\n",
    "--checkpoint={final_checkpoint} \\\n",
    "--lrschedule='warmup_cosine' \\\n",
    "--resume_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t5...\n",
      "/opt/conda/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "Trial 68b16_00000:  {'optim': {'optim_lr': 0.0004, 'reg_weight': 5e-05}, 'lrschedule': {'warmup_epochs': 20, 'max_epoch': 1200}} 0.8822389245033264\n",
      "Trial 68b16_00001:  {'optim': {'optim_lr': 0.0004, 'reg_weight': 5e-05}, 'lrschedule': {'warmup_epochs': 40, 'max_epoch': 1200}} 0.8888839483261108\n",
      "Trial 68b16_00002:  {'optim': {'optim_lr': 0.004, 'reg_weight': 5e-05}, 'lrschedule': {'warmup_epochs': 20, 'max_epoch': 1200}} 0.8812320232391357\n",
      "Trial 68b16_00003:  {'optim': {'optim_lr': 0.004, 'reg_weight': 5e-05}, 'lrschedule': {'warmup_epochs': 40, 'max_epoch': 1200}} 0.888558030128479\n",
      "Trial 68b16_00004:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.0005}, 'lrschedule': {'warmup_epochs': 20, 'max_epoch': 1200}} 0.8816050291061401\n",
      "Trial 68b16_00005:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.0005}, 'lrschedule': {'warmup_epochs': 40, 'max_epoch': 1200}} 0.8932540416717529\n",
      "Trial 68b16_00006:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.005}, 'lrschedule': {'warmup_epochs': 20, 'max_epoch': 1200}} 0.8923649787902832\n",
      "Trial 68b16_00007:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.005}, 'lrschedule': {'warmup_epochs': 40, 'max_epoch': 1200}} 0.8864316344261169\n",
      "Trial 68b16_00008:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.05}, 'lrschedule': {'warmup_epochs': 20, 'max_epoch': 1200}} 0.8872197866439819\n",
      "Trial 68b16_00009:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.05}, 'lrschedule': {'warmup_epochs': 40, 'max_epoch': 1200}} 0.8930647373199463\n",
      "\n",
      "Best trial 68b16_00005:  {'optim': {'optim_lr': 0.004, 'reg_weight': 0.0005}, 'lrschedule': {'warmup_epochs': 40, 'max_epoch': 1200}} 0.8932540416717529\n",
      "best log dir: /nfs/Workspace/CardiacSeg/UNet3D/CHGH/tune_results/exp_2_2_t5/main_68b16_00005_5_lrschedule=warmup_epochs_40_max_epoch_1200,optim=optim_lr_0_004_reg_weight_0_0005_2022-12-31_01-57-28\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=/nfs/Workspace/CardiacSeg  /opt/conda/bin/python /nfs/Workspace/CardiacSeg/expers/chgh/tune_anal.py \\\n",
    "--exp_name={exp_name} \\\n",
    "--local_dir={root_dir}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
