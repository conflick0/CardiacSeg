{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HfBsNHQp62I7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669640341290,"user_tz":-480,"elapsed":13161,"user":{"displayName":"20","userId":"00260548354071665304"}},"outputId":"c34bd8fb-c612-4f3a-f09f-c143a55ea838"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1jz_DGnICBmKWCr_JL904PDQdIEK0_EQG/CardiacSeg/SwinUNETR/Pretrain/Pretrain\n"]}],"source":["# mount driver\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/CardiacSeg/SwinUNETR/Pretrain/Pretrain\n","\n","# install dependents\n","!pip install -q nnunet\n","!pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n","!pip install -q tensorboardX==2.1\n","!python -c \"import matplotlib\" || pip install -q matplotlib\n","%matplotlib inline\n","\n","# sync python module\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["import sys\n","# set package path\n","sys.path.append(\"/content/drive/MyDrive/CardiacSeg\")\n","\n","import os\n","from pathlib import PurePath\n","\n","from monai.transforms import (\n","    Compose,\n","    LoadImaged,\n",")\n","\n","from data_utils.json_dataset import generate_dataset_json"],"metadata":{"id":"h3M6JI7_7U6e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Gen data dict json"],"metadata":{"id":"uPwewTXGy8dq"}},{"cell_type":"code","source":["# import sys\n","\n","# # set package path\n","# sys.path.append(\"/content/drive/MyDrive/CardiacSeg\")\n","\n","# from data_utils.chgh_dataset import get_data_dicts\n","# from data_utils.io import save_json\n","\n","# exp_name = 'exp_2_2'\n","# model_dir = f'/content/drive/MyDrive/CardiacSeg/SwinUNETR/CHGH/pretrain/{exp_name}'\n","# root_data_dir = '/content/drive/MyDrive/CardiacSeg/dataset/CHGH'\n","# data_dir = '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain'\n","# data_dicts_json = os.path.join(root_data_dir, 'data_dicts', f'{exp_name}_pretrain.json')\n","# data_dicts = get_data_dicts(data_dir)\n","# data_dicts\n","# tr_data_dicts = data_dicts[0:3] + data_dicts[4:7] + data_dicts[8:-1]\n","# tt_data_dicts = [data_dicts[3], data_dicts[7], data_dicts[-1]]\n","# target_data_dicts = tr_data_dicts + tt_data_dicts + tt_data_dicts\n","# save_json(target_data_dicts, data_dicts_json)\n","# target_data_dicts"],"metadata":{"id":"SU6Hqrsdy0vE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669639038445,"user_tz":-480,"elapsed":5,"user":{"displayName":"20","userId":"00260548354071665304"}},"outputId":"c7a30613-8d7d-4cfa-f0f9-b30e70d57aa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["save json to /content/drive/MyDrive/CardiacSeg/dataset/CHGH/data_dicts/exp_2_2_pretrain.json\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_05/pid_05.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_05/pid_05_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_06/pid_06.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_06/pid_06_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_07/pid_07.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_07/pid_07_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_21/pid_21.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_21/pid_21_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_23/pid_23.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_23/pid_23_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_24/pid_24.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_24/pid_24_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_30/pid_30.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_30/pid_30_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_34/pid_34.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_34/pid_34_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_57/pid_57.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_57/pid_57_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_110/pid_110.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_110/pid_110_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_1002/pid_1002.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_1002/pid_1002_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_08/pid_08.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_08/pid_08_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_27/pid_27.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_27/pid_27_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_1003/pid_1003.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_1003/pid_1003_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_08/pid_08.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_08/pid_08_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_27/pid_27.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_27/pid_27_gt.nii.gz'},\n"," {'image': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_1003/pid_1003.nii.gz',\n","  'label': '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/pretrain/pid_1003/pid_1003_gt.nii.gz'}]"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["## Generate data json file"],"metadata":{"id":"bXAggojBs9u0"}},{"cell_type":"code","source":["# data_json_pth = os.path.join(root_data_dir, 'data_dicts', f'{exp_name}_pretrain_data.json')\n","# generate_dataset_json(\n","#     target_data_dicts,\n","#     data_json_pth,\n","#     dataset_name='segthor',\n","#     labels={0: 'background', 2: 'heart'},\n","#     tensorImageSize='3D',\n","#     sort_keys=True,\n","#     modalities=['CT'],\n","#     license='see challenge website',\n","#     split_train_ratio=0.8,\n","#     fold=3,\n","#     num_fold=4,\n","# )"],"metadata":{"id":"KUhohVc8s7uB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669638812950,"user_tz":-480,"elapsed":342,"user":{"displayName":"20","userId":"00260548354071665304"}},"outputId":"1d5c8f94-1d2a-45b5-9868-f95c1e7e6675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fold: 3\n","train files (11): ['pid_05', 'pid_06', 'pid_07', 'pid_21', 'pid_23', 'pid_24', 'pid_30', 'pid_34', 'pid_57', 'pid_110', 'pid_1002']\n","val files (3): ['pid_08', 'pid_27', 'pid_1003']\n","test files (3): ['pid_08', 'pid_27', 'pid_1003']\n","WARNING: output file name is not dataset.json! This may be intentional or not. You decide. Proceeding anyways...\n","save json to /content/drive/MyDrive/CardiacSeg/dataset/CHGH/data_dicts/exp_2_2_pretrain_data.json\n"]}]},{"cell_type":"markdown","source":["## Pretrain"],"metadata":{"id":"th4_0JZYLCfy"}},{"cell_type":"code","source":["exp_name = 'exp_2_2'\n","model_dir = f'/content/drive/MyDrive/CardiacSeg/SwinUNETR/CHGH/pretrain/{exp_name}'\n","data_dicts_dir = '/content/drive/MyDrive/CardiacSeg/dataset/CHGH/data_dicts'\n","data_dicts_json = os.path.join(data_dicts_dir, f'{exp_name}_pretrain_data.json')\n","best_model_path = os.path.join(model_dir, 'model_bestValRMSE.pt')"],"metadata":{"id":"nyOo-W92PiRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"EzFsls0OhbDt","executionInfo":{"status":"ok","timestamp":1669643745153,"user_tz":-480,"elapsed":6,"user":{"displayName":"20","userId":"00260548354071665304"}},"outputId":"fe06f65b-20e5-4723-8755-d087d3bc9952"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/CardiacSeg/SwinUNETR/CHGH/pretrain/exp_2_2/model_bestValRMSE.pt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["!python main.py\\\n","--use_checkpoint \\\n","--batch_size=1 \\\n","--num_steps=100000 \\\n","--lrdecay \\\n","--eval_num=100 \\\n","--logdir={model_dir} \\\n","--data_name={data_dicts_json} \\\n","--space_x=0.7 \\\n","--space_y=0.7 \\\n","--space_z=1.0 \\\n","--resume={best_model_path}\n","# --lr=<Lr> \n","# --roi_x=<Roi_x> \\\n","# --roi_y=<Roi_y> \\\n","# --roi_z=<Roi_z> \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZvqEQoDLKbx","outputId":"041a83a1-e309-4a70-c6cd-67a4150b0314","executionInfo":{"status":"ok","timestamp":1669649045962,"user_tz":-480,"elapsed":5105307,"user":{"displayName":"20","userId":"00260548354071665304"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with a single process on 1 GPUs.\n","load model: /content/drive/MyDrive/CardiacSeg/SwinUNETR/CHGH/pretrain/exp_2_2/model_bestValRMSE.pt\n","['/content/drive/MyDrive/CardiacSeg/dataset/CHGH/data_dicts/exp_2_2_pretrain_data.json']\n","load json from /content/drive/MyDrive/CardiacSeg/dataset/CHGH/data_dicts/exp_2_2_pretrain_data.json\n","load json from /content/drive/MyDrive/CardiacSeg/dataset/CHGH/data_dicts/exp_2_2_pretrain_data.json\n","Dataset 1 data_dict: number of tr data: 11\n","Dataset 1 data_dict: number of val data: 3\n","Dataset all training: number of data: 11\n","Dataset all validation: number of data: 3\n","/usr/local/lib/python3.7/dist-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n","  warn_deprecated(obj, msg, warning_category)\n","Using generic dataset\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Step:0/100000, Loss:2.6010, Time:8.1600\n","Step:1/100000, Loss:3.1680, Time:3.5900\n","Step:2/100000, Loss:2.4124, Time:2.9642\n","Step:3/100000, Loss:2.5105, Time:3.2712\n","Step:4/100000, Loss:2.1238, Time:3.5106\n","Step:5/100000, Loss:2.8292, Time:3.5880\n","Step:6/100000, Loss:1.3779, Time:4.2176\n","Step:7/100000, Loss:2.8292, Time:3.1400\n","Step:8/100000, Loss:1.0377, Time:3.6321\n","Step:9/100000, Loss:3.0342, Time:2.4076\n","Step:10/100000, Loss:2.7176, Time:2.4011\n","Step:11/100000, Loss:1.6408, Time:3.5978\n","Step:12/100000, Loss:1.6666, Time:4.0947\n","Step:13/100000, Loss:2.8149, Time:2.8264\n","Step:14/100000, Loss:2.6375, Time:4.1132\n","Step:15/100000, Loss:2.4555, Time:3.7610\n","Step:16/100000, Loss:2.5996, Time:3.4362\n","Step:17/100000, Loss:2.4436, Time:3.9065\n","Step:18/100000, Loss:2.9169, Time:3.2718\n","Step:19/100000, Loss:1.6682, Time:2.7918\n","Step:20/100000, Loss:2.1605, Time:2.5016\n","Step:21/100000, Loss:3.0508, Time:2.3932\n","Step:22/100000, Loss:2.6083, Time:3.9728\n","Step:23/100000, Loss:2.2745, Time:3.7850\n","Step:24/100000, Loss:2.7603, Time:2.9230\n","Step:25/100000, Loss:1.6708, Time:3.7912\n","Step:26/100000, Loss:1.5225, Time:3.7331\n","Step:27/100000, Loss:2.5472, Time:3.2976\n","Step:28/100000, Loss:3.0758, Time:4.2322\n","Step:29/100000, Loss:2.9605, Time:2.9713\n","Step:30/100000, Loss:1.1731, Time:2.9052\n","Step:31/100000, Loss:2.4629, Time:2.5271\n","Step:32/100000, Loss:1.8036, Time:2.3794\n","Step:33/100000, Loss:2.7686, Time:3.9775\n","Step:34/100000, Loss:2.0601, Time:3.8010\n","Step:35/100000, Loss:3.2318, Time:3.0145\n","Step:36/100000, Loss:2.5506, Time:3.7761\n","Step:37/100000, Loss:2.5509, Time:3.5908\n","Step:38/100000, Loss:2.2162, Time:3.3255\n","Step:39/100000, Loss:2.3054, Time:3.7295\n","Step:40/100000, Loss:2.2067, Time:3.2832\n","Step:41/100000, Loss:2.9580, Time:2.7440\n","Step:42/100000, Loss:2.2968, Time:2.6206\n","Step:43/100000, Loss:2.4894, Time:2.4064\n","Step:44/100000, Loss:2.6322, Time:3.6449\n","Step:45/100000, Loss:2.6403, Time:3.7807\n","Step:46/100000, Loss:2.8193, Time:3.1604\n","Step:47/100000, Loss:3.1601, Time:3.5908\n","Step:48/100000, Loss:2.6469, Time:3.9015\n","Step:49/100000, Loss:2.5416, Time:3.3587\n","Step:50/100000, Loss:2.7820, Time:4.1609\n","Step:51/100000, Loss:2.5465, Time:3.1025\n","Step:52/100000, Loss:2.9796, Time:2.7774\n","Step:53/100000, Loss:2.8578, Time:2.4777\n","Step:54/100000, Loss:2.9899, Time:2.4115\n","Step:55/100000, Loss:2.9422, Time:4.2273\n","Step:56/100000, Loss:2.4507, Time:3.8229\n","Step:57/100000, Loss:2.9499, Time:3.0911\n","Step:58/100000, Loss:2.5920, Time:3.7370\n","Step:59/100000, Loss:2.5589, Time:4.7297\n","Step:60/100000, Loss:2.5972, Time:3.4469\n","Step:61/100000, Loss:2.2182, Time:3.7721\n","Step:62/100000, Loss:2.2825, Time:3.4241\n","Step:63/100000, Loss:3.1106, Time:2.7890\n","Step:64/100000, Loss:2.6405, Time:2.6492\n","Step:65/100000, Loss:2.2435, Time:2.4202\n","Step:66/100000, Loss:3.3544, Time:3.8237\n","Step:67/100000, Loss:2.4697, Time:3.8218\n","Step:68/100000, Loss:2.3801, Time:3.1711\n","Step:69/100000, Loss:2.7398, Time:3.6921\n","Step:70/100000, Loss:2.6681, Time:3.8299\n","Step:71/100000, Loss:1.6300, Time:3.6518\n","Step:72/100000, Loss:2.7270, Time:4.1081\n","Step:73/100000, Loss:3.0246, Time:2.8543\n","Step:74/100000, Loss:3.1583, Time:2.9174\n","Step:75/100000, Loss:2.9716, Time:2.4752\n","Step:76/100000, Loss:3.1693, Time:2.3981\n","Step:77/100000, Loss:2.1804, Time:3.9418\n","Step:78/100000, Loss:2.9127, Time:3.6591\n","Step:79/100000, Loss:2.6397, Time:3.0343\n","Step:80/100000, Loss:2.7727, Time:3.6135\n","Step:81/100000, Loss:2.6071, Time:4.0632\n","Step:82/100000, Loss:2.5042, Time:3.5835\n","Step:83/100000, Loss:2.5218, Time:4.2651\n","Step:84/100000, Loss:2.8028, Time:2.8042\n","Step:85/100000, Loss:2.4924, Time:2.9812\n","Step:86/100000, Loss:2.7287, Time:2.3928\n","Step:87/100000, Loss:2.4395, Time:2.3815\n","Step:88/100000, Loss:3.5512, Time:3.8506\n","Step:89/100000, Loss:2.6879, Time:3.7544\n","Step:90/100000, Loss:3.0026, Time:3.1878\n","Step:91/100000, Loss:2.4673, Time:3.6764\n","Step:92/100000, Loss:2.4507, Time:3.8168\n","Step:93/100000, Loss:2.8620, Time:3.6481\n","Step:94/100000, Loss:2.8422, Time:4.1014\n","Step:95/100000, Loss:3.3731, Time:2.9987\n","Step:96/100000, Loss:2.5686, Time:2.9776\n","Step:97/100000, Loss:3.6755, Time:2.5144\n","Step:98/100000, Loss:2.0462, Time:2.4560\n","Step:99/100000, Loss:2.7896, Time:4.7439\n","/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","Validation step:0, Loss:2.6623, Loss Reconstruction:0.1557\n","Validation step:1, Loss:2.6687, Loss Reconstruction:0.1435\n","Validation step:2, Loss:2.4941, Loss Reconstruction:0.1581\n","Model was saved ! Best Recon. Val Loss: 0.1524, Recon. Val Loss: 0.1524\n","Step:100/100000, Loss:2.4961, Time:2.8323\n","Step:101/100000, Loss:2.5121, Time:3.3037\n","Step:102/100000, Loss:2.4856, Time:3.9475\n","Step:103/100000, Loss:2.8671, Time:3.4356\n","Step:104/100000, Loss:2.7336, Time:3.6874\n","Step:105/100000, Loss:2.9597, Time:3.7036\n","Step:106/100000, Loss:2.5116, Time:3.2374\n","Step:107/100000, Loss:2.5268, Time:2.5407\n","Step:108/100000, Loss:3.0675, Time:2.4358\n","Step:109/100000, Loss:2.8293, Time:2.4780\n","Step:110/100000, Loss:2.7389, Time:3.8240\n","Step:111/100000, Loss:2.7192, Time:3.7720\n","Step:112/100000, Loss:2.8013, Time:3.0905\n","Step:113/100000, Loss:2.9745, Time:4.7333\n","Step:114/100000, Loss:2.8363, Time:3.9516\n","Step:115/100000, Loss:3.1157, Time:3.4589\n","Step:116/100000, Loss:2.5790, Time:3.7333\n","Step:117/100000, Loss:2.3541, Time:3.5112\n","Step:118/100000, Loss:2.5081, Time:2.7891\n","Step:119/100000, Loss:2.6901, Time:2.6116\n","Step:120/100000, Loss:2.3054, Time:2.4147\n","Step:121/100000, Loss:2.3177, Time:4.0684\n","Step:122/100000, Loss:3.0074, Time:4.0079\n","Step:123/100000, Loss:3.0677, Time:3.1912\n","Step:124/100000, Loss:2.4038, Time:3.2784\n","Step:125/100000, Loss:3.2407, Time:4.2661\n","Step:126/100000, Loss:2.7905, Time:3.4266\n","Step:127/100000, Loss:3.0094, Time:3.9605\n","Step:128/100000, Loss:2.9640, Time:3.1444\n","Step:129/100000, Loss:2.3610, Time:2.9599\n","Step:130/100000, Loss:2.4591, Time:2.5523\n","Step:131/100000, Loss:2.5706, Time:2.4252\n","Step:132/100000, Loss:2.8055, Time:3.5889\n","Step:133/100000, Loss:2.1444, Time:3.7438\n","Step:134/100000, Loss:2.9877, Time:3.1465\n","Step:135/100000, Loss:3.0290, Time:3.5945\n","Step:136/100000, Loss:2.8154, Time:3.8999\n","Step:137/100000, Loss:2.1648, Time:3.4432\n","Step:138/100000, Loss:2.1196, Time:4.0238\n","Step:139/100000, Loss:2.6515, Time:3.2370\n","Step:140/100000, Loss:2.0613, Time:3.0002\n","Step:141/100000, Loss:2.9376, Time:2.3892\n","Step:142/100000, Loss:2.4525, Time:2.4226\n","Step:143/100000, Loss:2.2191, Time:3.9059\n","Step:144/100000, Loss:3.4548, Time:3.6560\n","Step:145/100000, Loss:2.5057, Time:2.9369\n","Step:146/100000, Loss:2.0158, Time:3.8441\n","Step:147/100000, Loss:2.5550, Time:3.8850\n","Step:148/100000, Loss:1.7428, Time:3.4506\n","Step:149/100000, Loss:2.6527, Time:4.0451\n","Step:150/100000, Loss:2.6395, Time:3.0704\n","Step:151/100000, Loss:2.5702, Time:2.9326\n","Step:152/100000, Loss:1.7725, Time:2.4059\n","Step:153/100000, Loss:2.6088, Time:2.3990\n","Step:154/100000, Loss:2.0963, Time:3.6655\n","Step:155/100000, Loss:0.6418, Time:3.7740\n","Step:156/100000, Loss:2.4318, Time:2.9948\n","Step:157/100000, Loss:2.2875, Time:3.5322\n","Step:158/100000, Loss:2.9498, Time:3.8652\n","Step:159/100000, Loss:4.5394, Time:3.4473\n","Step:160/100000, Loss:3.2933, Time:4.2053\n","Step:161/100000, Loss:2.6971, Time:2.8953\n","Step:162/100000, Loss:1.5936, Time:2.8843\n","Step:163/100000, Loss:2.4678, Time:2.4977\n","Step:164/100000, Loss:2.4154, Time:2.4362\n","Step:165/100000, Loss:2.3452, Time:3.8346\n","Step:166/100000, Loss:2.6434, Time:3.5613\n","Step:167/100000, Loss:2.3438, Time:3.0106\n","Step:168/100000, Loss:1.7619, Time:3.5493\n","Step:169/100000, Loss:3.0597, Time:3.9738\n","Step:170/100000, Loss:2.4140, Time:3.7103\n","Step:171/100000, Loss:2.3066, Time:4.8164\n","Step:172/100000, Loss:1.1719, Time:3.3642\n","Step:173/100000, Loss:2.6455, Time:2.7780\n","Step:174/100000, Loss:3.0447, Time:2.4690\n","Step:175/100000, Loss:3.3603, Time:2.4445\n","Step:176/100000, Loss:2.4801, Time:3.6448\n","Step:177/100000, Loss:2.1432, Time:3.8001\n","Step:178/100000, Loss:2.5293, Time:3.3018\n","Step:179/100000, Loss:2.6422, Time:3.2701\n","Step:180/100000, Loss:2.2414, Time:4.0187\n","Step:181/100000, Loss:3.3832, Time:3.6926\n","Step:182/100000, Loss:2.4572, Time:4.1819\n","Step:183/100000, Loss:2.0666, Time:3.0103\n","Step:184/100000, Loss:2.5671, Time:2.8717\n","Step:185/100000, Loss:2.4964, Time:2.4815\n","Step:186/100000, Loss:2.5028, Time:2.4041\n","Step:187/100000, Loss:1.6586, Time:3.7917\n","Step:188/100000, Loss:1.7464, Time:3.7027\n","Step:189/100000, Loss:3.6913, Time:3.5094\n","Step:190/100000, Loss:2.2963, Time:4.1328\n","Step:191/100000, Loss:1.3576, Time:3.7933\n","Step:192/100000, Loss:2.6834, Time:3.4428\n","Step:193/100000, Loss:2.5351, Time:4.0035\n","Step:194/100000, Loss:1.6597, Time:2.9267\n","Step:195/100000, Loss:2.4659, Time:2.9643\n","Step:196/100000, Loss:3.0849, Time:2.3758\n","Step:197/100000, Loss:2.5242, Time:2.4280\n","Step:198/100000, Loss:2.8105, Time:3.7228\n","Step:199/100000, Loss:1.6388, Time:3.8651\n","Validation step:0, Loss:2.7787, Loss Reconstruction:0.1177\n","Validation step:1, Loss:2.4313, Loss Reconstruction:0.1114\n","Validation step:2, Loss:1.7241, Loss Reconstruction:0.1181\n","Model was saved ! Best Recon. Val Loss: 0.1158, Recon. Val Loss: 0.1158\n","Step:200/100000, Loss:2.2830, Time:2.8117\n","Step:201/100000, Loss:2.0280, Time:3.3362\n","Step:202/100000, Loss:2.5908, Time:3.5462\n","Step:203/100000, Loss:2.5812, Time:4.3494\n","Step:204/100000, Loss:1.6825, Time:3.6043\n","Step:205/100000, Loss:2.6623, Time:3.1224\n","Step:206/100000, Loss:2.9973, Time:2.7137\n","Step:207/100000, Loss:2.2708, Time:2.3934\n","Step:208/100000, Loss:2.5492, Time:2.3950\n","Step:209/100000, Loss:1.9088, Time:3.6367\n","Step:210/100000, Loss:3.2988, Time:3.4166\n","Step:211/100000, Loss:2.5671, Time:2.9739\n","Step:212/100000, Loss:2.1076, Time:3.5451\n","Step:213/100000, Loss:1.6618, Time:3.8932\n","Step:214/100000, Loss:2.4715, Time:3.5194\n","Step:215/100000, Loss:2.2829, Time:3.9378\n","Step:216/100000, Loss:1.5168, Time:3.2023\n","Step:217/100000, Loss:2.0353, Time:2.9312\n","Step:218/100000, Loss:2.3544, Time:2.4175\n","Step:219/100000, Loss:3.1813, Time:2.4240\n","Step:220/100000, Loss:2.8434, Time:3.4575\n","Step:221/100000, Loss:2.7598, Time:3.7914\n","Step:222/100000, Loss:1.6411, Time:3.3906\n","Step:223/100000, Loss:3.0757, Time:3.6279\n","Step:224/100000, Loss:2.9231, Time:3.7192\n","Step:225/100000, Loss:2.1340, Time:3.3653\n","Step:226/100000, Loss:2.0405, Time:4.8113\n","Step:227/100000, Loss:2.9858, Time:3.8032\n","Step:228/100000, Loss:2.0698, Time:2.8179\n","Step:229/100000, Loss:3.3718, Time:2.4941\n","Step:230/100000, Loss:2.4922, Time:2.4201\n","Step:231/100000, Loss:2.2352, Time:3.8520\n","Step:232/100000, Loss:3.0504, Time:4.5009\n","Step:233/100000, Loss:1.1668, Time:3.2054\n","Step:234/100000, Loss:2.7979, Time:3.7146\n","Step:235/100000, Loss:3.6017, Time:3.7343\n","Step:236/100000, Loss:2.3907, Time:3.6563\n","Step:237/100000, Loss:3.3209, Time:4.1520\n","Step:238/100000, Loss:3.6538, Time:3.0780\n","Step:239/100000, Loss:3.4148, Time:2.9913\n","Step:240/100000, Loss:3.5110, Time:2.3679\n","Step:241/100000, Loss:1.7980, Time:2.4134\n","Step:242/100000, Loss:1.9976, Time:3.8065\n","Step:243/100000, Loss:2.1055, Time:3.6695\n","Step:244/100000, Loss:2.1243, Time:3.6449\n","Step:245/100000, Loss:1.9540, Time:3.6491\n","Step:246/100000, Loss:3.8034, Time:3.6943\n","Step:247/100000, Loss:2.1001, Time:3.3855\n","Step:248/100000, Loss:2.4051, Time:4.1947\n","Step:249/100000, Loss:2.9788, Time:3.0748\n","Step:250/100000, Loss:2.3839, Time:2.9525\n","Step:251/100000, Loss:3.9257, Time:2.4341\n","Step:252/100000, Loss:3.2076, Time:2.4073\n","Step:253/100000, Loss:2.7011, Time:3.6912\n","Step:254/100000, Loss:2.3149, Time:3.8483\n","Step:255/100000, Loss:2.6003, Time:3.1492\n","Step:256/100000, Loss:2.3730, Time:4.0314\n","Step:257/100000, Loss:1.8637, Time:3.7520\n","Step:258/100000, Loss:3.4878, Time:3.5229\n","Step:259/100000, Loss:1.7405, Time:4.2846\n","Step:260/100000, Loss:2.4461, Time:3.0112\n","Step:261/100000, Loss:1.7689, Time:2.8821\n","Step:262/100000, Loss:1.6228, Time:2.4234\n","Step:263/100000, Loss:1.6004, Time:2.4047\n","Step:264/100000, Loss:1.9738, Time:3.8435\n","Step:265/100000, Loss:2.8164, Time:3.7912\n","Step:266/100000, Loss:2.0625, Time:3.3458\n","Step:267/100000, Loss:2.1127, Time:3.5635\n","Step:268/100000, Loss:2.6299, Time:4.2112\n","Step:269/100000, Loss:1.6842, Time:3.3698\n","Step:270/100000, Loss:1.4714, Time:4.0281\n","Step:271/100000, Loss:2.6944, Time:3.0297\n","Step:272/100000, Loss:3.1355, Time:2.9411\n","Step:273/100000, Loss:2.8375, Time:2.4132\n","Step:274/100000, Loss:3.3431, Time:2.3933\n","Step:275/100000, Loss:2.8242, Time:3.8375\n","Step:276/100000, Loss:3.2483, Time:3.7301\n","Step:277/100000, Loss:1.8105, Time:3.5348\n","Step:278/100000, Loss:2.7071, Time:3.4494\n","Step:279/100000, Loss:2.8618, Time:3.9486\n","Step:280/100000, Loss:2.9002, Time:3.4764\n","Step:281/100000, Loss:1.8685, Time:4.2880\n","Step:282/100000, Loss:1.6203, Time:2.8052\n","Step:283/100000, Loss:1.5682, Time:2.9278\n","Step:284/100000, Loss:1.8808, Time:2.4442\n","Step:285/100000, Loss:2.6132, Time:2.3904\n","Step:286/100000, Loss:2.6218, Time:5.4186\n","Step:287/100000, Loss:2.3670, Time:3.7634\n","Step:288/100000, Loss:2.8502, Time:2.9258\n","Step:289/100000, Loss:2.6158, Time:3.5171\n","Step:290/100000, Loss:2.4712, Time:3.7703\n","Step:291/100000, Loss:2.5949, Time:3.4800\n","Step:292/100000, Loss:2.7173, Time:3.9503\n","Step:293/100000, Loss:2.6766, Time:3.2063\n","Step:294/100000, Loss:2.6964, Time:2.7664\n","Step:295/100000, Loss:2.8728, Time:2.4225\n","Step:296/100000, Loss:2.9543, Time:2.4300\n","Step:297/100000, Loss:2.5268, Time:4.0493\n","Step:298/100000, Loss:3.4156, Time:3.6108\n","Step:299/100000, Loss:3.3556, Time:3.2432\n","Validation step:0, Loss:2.5280, Loss Reconstruction:0.2507\n","Validation step:1, Loss:2.6923, Loss Reconstruction:0.2317\n","Validation step:2, Loss:2.9806, Loss Reconstruction:0.2698\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2507\n","early stop count: 1\n","Step:300/100000, Loss:2.7258, Time:2.7816\n","Step:301/100000, Loss:2.7529, Time:3.6799\n","Step:302/100000, Loss:2.7142, Time:3.9201\n","Step:303/100000, Loss:2.8201, Time:3.9814\n","Step:304/100000, Loss:2.9549, Time:2.8516\n","Step:305/100000, Loss:2.6399, Time:2.8848\n","Step:306/100000, Loss:2.9996, Time:2.4115\n","Step:307/100000, Loss:2.6759, Time:2.3859\n","Step:308/100000, Loss:2.6692, Time:3.8531\n","Step:309/100000, Loss:2.9511, Time:3.9014\n","Step:310/100000, Loss:2.8272, Time:3.4270\n","Step:311/100000, Loss:2.6515, Time:3.3881\n","Step:312/100000, Loss:2.6740, Time:3.8536\n","Step:313/100000, Loss:2.6697, Time:3.5218\n","Step:314/100000, Loss:3.4640, Time:3.8725\n","Step:315/100000, Loss:3.2811, Time:3.0215\n","Step:316/100000, Loss:3.5811, Time:2.7489\n","Step:317/100000, Loss:3.2335, Time:2.4319\n","Step:318/100000, Loss:2.9667, Time:2.4292\n","Step:319/100000, Loss:2.7064, Time:4.0154\n","Step:320/100000, Loss:2.7378, Time:4.0581\n","Step:321/100000, Loss:3.2325, Time:3.3852\n","Step:322/100000, Loss:2.5430, Time:3.3933\n","Step:323/100000, Loss:3.4330, Time:3.7825\n","Step:324/100000, Loss:2.8584, Time:3.2085\n","Step:325/100000, Loss:2.6528, Time:3.9017\n","Step:326/100000, Loss:3.3145, Time:3.2969\n","Step:327/100000, Loss:2.8906, Time:2.8430\n","Step:328/100000, Loss:2.8611, Time:2.4773\n","Step:329/100000, Loss:2.4180, Time:2.4156\n","Step:330/100000, Loss:3.0108, Time:3.5883\n","Step:331/100000, Loss:2.8122, Time:3.9028\n","Step:332/100000, Loss:3.1797, Time:3.1477\n","Step:333/100000, Loss:2.4083, Time:3.6095\n","Step:334/100000, Loss:2.6965, Time:3.8379\n","Step:335/100000, Loss:2.5371, Time:3.4778\n","Step:336/100000, Loss:3.6359, Time:3.9356\n","Step:337/100000, Loss:2.9345, Time:3.1139\n","Step:338/100000, Loss:2.7273, Time:2.9066\n","Step:339/100000, Loss:3.3495, Time:2.3926\n","Step:340/100000, Loss:2.4913, Time:2.4279\n","Step:341/100000, Loss:2.7607, Time:4.1036\n","Step:342/100000, Loss:3.3729, Time:3.7312\n","Step:343/100000, Loss:2.6010, Time:3.1809\n","Step:344/100000, Loss:2.6674, Time:4.6047\n","Step:345/100000, Loss:2.7467, Time:4.4086\n","Step:346/100000, Loss:2.5902, Time:3.5757\n","Step:347/100000, Loss:2.8252, Time:3.9043\n","Step:348/100000, Loss:2.5960, Time:2.9901\n","Step:349/100000, Loss:2.6238, Time:2.9375\n","Step:350/100000, Loss:2.7484, Time:2.3795\n","Step:351/100000, Loss:2.8200, Time:2.3904\n","Step:352/100000, Loss:3.0130, Time:3.9033\n","Step:353/100000, Loss:2.9396, Time:3.5807\n","Step:354/100000, Loss:3.2444, Time:3.4102\n","Step:355/100000, Loss:2.8948, Time:3.3783\n","Step:356/100000, Loss:3.2701, Time:3.9573\n","Step:357/100000, Loss:2.7920, Time:3.5613\n","Step:358/100000, Loss:3.0328, Time:3.9764\n","Step:359/100000, Loss:2.6033, Time:3.0216\n","Step:360/100000, Loss:2.8209, Time:2.9426\n","Step:361/100000, Loss:2.6590, Time:2.4149\n","Step:362/100000, Loss:2.5561, Time:2.3791\n","Step:363/100000, Loss:3.0027, Time:3.5771\n","Step:364/100000, Loss:2.5698, Time:3.6684\n","Step:365/100000, Loss:2.6660, Time:3.4947\n","Step:366/100000, Loss:2.6578, Time:3.4888\n","Step:367/100000, Loss:2.8245, Time:3.8901\n","Step:368/100000, Loss:2.9062, Time:3.7856\n","Step:369/100000, Loss:2.7165, Time:4.0276\n","Step:370/100000, Loss:2.3804, Time:2.8336\n","Step:371/100000, Loss:2.2757, Time:2.8493\n","Step:372/100000, Loss:2.6297, Time:2.4074\n","Step:373/100000, Loss:3.0424, Time:2.4004\n","Step:374/100000, Loss:2.5500, Time:3.6976\n","Step:375/100000, Loss:2.5503, Time:3.6899\n","Step:376/100000, Loss:2.7921, Time:3.1911\n","Step:377/100000, Loss:3.0920, Time:3.5007\n","Step:378/100000, Loss:2.8500, Time:3.6255\n","Step:379/100000, Loss:2.7865, Time:3.4588\n","Step:380/100000, Loss:2.5942, Time:4.1160\n","Step:381/100000, Loss:3.2303, Time:3.1674\n","Step:382/100000, Loss:2.9692, Time:2.8455\n","Step:383/100000, Loss:2.8007, Time:2.4812\n","Step:384/100000, Loss:3.1522, Time:2.4281\n","Step:385/100000, Loss:2.9790, Time:3.5952\n","Step:386/100000, Loss:2.9391, Time:3.6586\n","Step:387/100000, Loss:2.6190, Time:3.0176\n","Step:388/100000, Loss:2.8138, Time:3.6864\n","Step:389/100000, Loss:2.9404, Time:3.6918\n","Step:390/100000, Loss:2.5404, Time:3.4666\n","Step:391/100000, Loss:2.6985, Time:4.0757\n","Step:392/100000, Loss:2.9147, Time:3.0204\n","Step:393/100000, Loss:3.0685, Time:2.9860\n","Step:394/100000, Loss:2.9180, Time:2.4400\n","Step:395/100000, Loss:2.9202, Time:2.4069\n","Step:396/100000, Loss:2.5500, Time:3.7430\n","Step:397/100000, Loss:2.8567, Time:3.8204\n","Step:398/100000, Loss:2.7766, Time:3.2844\n","Step:399/100000, Loss:2.4514, Time:3.5762\n","Validation step:0, Loss:3.1605, Loss Reconstruction:0.2423\n","Validation step:1, Loss:2.7453, Loss Reconstruction:0.2279\n","Validation step:2, Loss:2.7371, Loss Reconstruction:0.2332\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2345\n","early stop count: 2\n","Step:400/100000, Loss:2.8352, Time:2.6945\n","Step:401/100000, Loss:2.6759, Time:3.4448\n","Step:402/100000, Loss:2.9179, Time:3.7397\n","Step:403/100000, Loss:2.9174, Time:3.8100\n","Step:404/100000, Loss:3.0482, Time:2.7728\n","Step:405/100000, Loss:2.8882, Time:2.4608\n","Step:406/100000, Loss:3.0526, Time:2.6848\n","Step:407/100000, Loss:2.7608, Time:3.6356\n","Step:408/100000, Loss:2.7381, Time:3.6044\n","Step:409/100000, Loss:2.8024, Time:3.1833\n","Step:410/100000, Loss:2.7253, Time:3.5860\n","Step:411/100000, Loss:2.6513, Time:3.9569\n","Step:412/100000, Loss:2.7538, Time:3.4657\n","Step:413/100000, Loss:2.9444, Time:4.2674\n","Step:414/100000, Loss:2.8137, Time:2.8716\n","Step:415/100000, Loss:2.4184, Time:2.9343\n","Step:416/100000, Loss:2.7770, Time:2.3999\n","Step:417/100000, Loss:3.0273, Time:2.4125\n","Step:418/100000, Loss:2.7544, Time:4.0695\n","Step:419/100000, Loss:3.0934, Time:3.6780\n","Step:420/100000, Loss:2.6148, Time:3.0703\n","Step:421/100000, Loss:2.7869, Time:3.5433\n","Step:422/100000, Loss:2.6792, Time:3.8030\n","Step:423/100000, Loss:2.7493, Time:3.3707\n","Step:424/100000, Loss:2.8067, Time:4.1247\n","Step:425/100000, Loss:2.8496, Time:3.0793\n","Step:426/100000, Loss:2.8884, Time:2.8149\n","Step:427/100000, Loss:3.0609, Time:2.4765\n","Step:428/100000, Loss:2.7931, Time:2.4116\n","Step:429/100000, Loss:2.7634, Time:3.8956\n","Step:430/100000, Loss:2.8272, Time:3.7182\n","Step:431/100000, Loss:2.6687, Time:3.5991\n","Step:432/100000, Loss:2.5765, Time:3.8474\n","Step:433/100000, Loss:2.7646, Time:3.6813\n","Step:434/100000, Loss:2.7274, Time:3.5004\n","Step:435/100000, Loss:2.7659, Time:3.7570\n","Step:436/100000, Loss:3.0047, Time:3.1434\n","Step:437/100000, Loss:2.6088, Time:2.9643\n","Step:438/100000, Loss:2.6619, Time:2.3995\n","Step:439/100000, Loss:2.9009, Time:2.4220\n","Step:440/100000, Loss:2.7536, Time:3.8551\n","Step:441/100000, Loss:2.9608, Time:3.7140\n","Step:442/100000, Loss:2.7914, Time:3.2380\n","Step:443/100000, Loss:2.6091, Time:3.4278\n","Step:444/100000, Loss:2.6898, Time:3.8259\n","Step:445/100000, Loss:2.7283, Time:3.6351\n","Step:446/100000, Loss:2.7366, Time:4.2905\n","Step:447/100000, Loss:2.7343, Time:2.9991\n","Step:448/100000, Loss:2.8634, Time:2.9241\n","Step:449/100000, Loss:2.7844, Time:2.3977\n","Step:450/100000, Loss:2.7921, Time:2.4199\n","Step:451/100000, Loss:2.7287, Time:3.8700\n","Step:452/100000, Loss:2.7909, Time:4.0597\n","Step:453/100000, Loss:2.7740, Time:3.4414\n","Step:454/100000, Loss:2.7494, Time:3.4732\n","Step:455/100000, Loss:2.6248, Time:3.8076\n","Step:456/100000, Loss:2.7224, Time:3.0948\n","Step:457/100000, Loss:2.6176, Time:4.0783\n","Step:458/100000, Loss:2.7755, Time:3.3019\n","Step:459/100000, Loss:2.5998, Time:2.8239\n","Step:460/100000, Loss:2.8720, Time:2.5095\n","Step:461/100000, Loss:2.9768, Time:2.4313\n","Step:462/100000, Loss:2.7101, Time:3.9449\n","Step:463/100000, Loss:2.8377, Time:3.7565\n","Step:464/100000, Loss:2.7901, Time:3.1773\n","Step:465/100000, Loss:2.8275, Time:3.2923\n","Step:466/100000, Loss:2.5141, Time:4.0394\n","Step:467/100000, Loss:2.7159, Time:3.6674\n","Step:468/100000, Loss:3.1203, Time:4.8042\n","Step:469/100000, Loss:3.0262, Time:3.8327\n","Step:470/100000, Loss:2.7874, Time:2.9783\n","Step:471/100000, Loss:2.7607, Time:2.4172\n","Step:472/100000, Loss:3.0930, Time:2.4278\n","Step:473/100000, Loss:2.9864, Time:4.0305\n","Step:474/100000, Loss:2.9225, Time:3.7434\n","Step:475/100000, Loss:2.8941, Time:3.1605\n","Step:476/100000, Loss:2.7768, Time:3.5808\n","Step:477/100000, Loss:2.7585, Time:3.6336\n","Step:478/100000, Loss:3.0506, Time:3.5886\n","Step:479/100000, Loss:2.9512, Time:4.0879\n","Step:480/100000, Loss:2.9448, Time:2.9805\n","Step:481/100000, Loss:2.8897, Time:2.9373\n","Step:482/100000, Loss:2.8813, Time:2.4421\n","Step:483/100000, Loss:2.5297, Time:2.4184\n","Step:484/100000, Loss:2.6459, Time:3.5480\n","Step:485/100000, Loss:2.8919, Time:3.8233\n","Step:486/100000, Loss:2.5170, Time:3.6046\n","Step:487/100000, Loss:2.7881, Time:3.6125\n","Step:488/100000, Loss:2.6891, Time:4.0096\n","Step:489/100000, Loss:2.8469, Time:3.7557\n","Step:490/100000, Loss:2.8011, Time:3.7471\n","Step:491/100000, Loss:2.3788, Time:3.1968\n","Step:492/100000, Loss:2.9262, Time:2.9585\n","Step:493/100000, Loss:2.7854, Time:2.3820\n","Step:494/100000, Loss:2.8626, Time:2.4354\n","Step:495/100000, Loss:2.7390, Time:3.8928\n","Step:496/100000, Loss:2.9109, Time:3.4987\n","Step:497/100000, Loss:2.7279, Time:3.0222\n","Step:498/100000, Loss:2.6827, Time:3.4983\n","Step:499/100000, Loss:2.6018, Time:3.8254\n","Validation step:0, Loss:2.6923, Loss Reconstruction:0.2634\n","Validation step:1, Loss:2.7224, Loss Reconstruction:0.2182\n","Validation step:2, Loss:2.6030, Loss Reconstruction:0.2640\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2485\n","early stop count: 3\n","Step:500/100000, Loss:2.7765, Time:2.7682\n","Step:501/100000, Loss:2.8220, Time:3.5396\n","Step:502/100000, Loss:2.9105, Time:3.4240\n","Step:503/100000, Loss:2.8911, Time:2.6627\n","Step:504/100000, Loss:3.0168, Time:2.5127\n","Step:505/100000, Loss:2.8124, Time:2.3761\n","Step:506/100000, Loss:2.7946, Time:3.9152\n","Step:507/100000, Loss:2.6028, Time:3.5680\n","Step:508/100000, Loss:2.7755, Time:3.0303\n","Step:509/100000, Loss:2.6290, Time:3.3934\n","Step:510/100000, Loss:2.7180, Time:3.8319\n","Step:511/100000, Loss:2.7839, Time:3.6177\n","Step:512/100000, Loss:2.6783, Time:4.2888\n","Step:513/100000, Loss:2.8130, Time:2.8224\n","Step:514/100000, Loss:2.6340, Time:3.0061\n","Step:515/100000, Loss:3.2251, Time:2.4005\n","Step:516/100000, Loss:2.3786, Time:2.3928\n","Step:517/100000, Loss:2.8854, Time:3.7331\n","Step:518/100000, Loss:3.3229, Time:3.7237\n","Step:519/100000, Loss:2.5658, Time:3.6496\n","Step:520/100000, Loss:2.8923, Time:3.4449\n","Step:521/100000, Loss:2.5383, Time:3.7108\n","Step:522/100000, Loss:2.8164, Time:3.3727\n","Step:523/100000, Loss:2.9826, Time:3.9850\n","Step:524/100000, Loss:2.8389, Time:2.9675\n","Step:525/100000, Loss:2.9189, Time:2.8192\n","Step:526/100000, Loss:2.6925, Time:2.4512\n","Step:527/100000, Loss:2.4792, Time:2.3787\n","Step:528/100000, Loss:2.4977, Time:3.6166\n","Step:529/100000, Loss:2.8273, Time:3.6531\n","Step:530/100000, Loss:2.8386, Time:3.7610\n","Step:531/100000, Loss:3.0409, Time:4.2928\n","Step:532/100000, Loss:2.8696, Time:3.8813\n","Step:533/100000, Loss:2.7707, Time:3.5331\n","Step:534/100000, Loss:3.2939, Time:3.9210\n","Step:535/100000, Loss:2.4595, Time:3.2819\n","Step:536/100000, Loss:2.8793, Time:2.9447\n","Step:537/100000, Loss:2.9369, Time:2.4615\n","Step:538/100000, Loss:2.6537, Time:2.4177\n","Step:539/100000, Loss:2.7909, Time:3.8004\n","Step:540/100000, Loss:2.6041, Time:3.8887\n","Step:541/100000, Loss:2.6143, Time:3.1117\n","Step:542/100000, Loss:2.6456, Time:3.2449\n","Step:543/100000, Loss:2.8422, Time:4.2189\n","Step:544/100000, Loss:2.1698, Time:3.3383\n","Step:545/100000, Loss:3.0142, Time:4.1394\n","Step:546/100000, Loss:2.4024, Time:3.1062\n","Step:547/100000, Loss:3.2101, Time:2.9359\n","Step:548/100000, Loss:3.2373, Time:2.5283\n","Step:549/100000, Loss:2.8124, Time:2.4761\n","Step:550/100000, Loss:2.9995, Time:3.6961\n","Step:551/100000, Loss:2.6962, Time:3.6623\n","Step:552/100000, Loss:2.7418, Time:3.0323\n","Step:553/100000, Loss:2.7090, Time:3.4775\n","Step:554/100000, Loss:2.8847, Time:3.7619\n","Step:555/100000, Loss:2.6841, Time:3.4489\n","Step:556/100000, Loss:2.6481, Time:3.9802\n","Step:557/100000, Loss:2.8009, Time:3.0104\n","Step:558/100000, Loss:2.8221, Time:2.8959\n","Step:559/100000, Loss:3.0918, Time:2.4979\n","Step:560/100000, Loss:2.6001, Time:2.3848\n","Step:561/100000, Loss:2.6076, Time:3.6506\n","Step:562/100000, Loss:2.5066, Time:3.6423\n","Step:563/100000, Loss:2.5984, Time:3.4302\n","Step:564/100000, Loss:2.6535, Time:3.5929\n","Step:565/100000, Loss:2.8277, Time:3.9854\n","Step:566/100000, Loss:2.5586, Time:3.7512\n","Step:567/100000, Loss:2.3345, Time:3.7986\n","Step:568/100000, Loss:3.4695, Time:3.1443\n","Step:569/100000, Loss:3.3409, Time:2.9326\n","Step:570/100000, Loss:2.5450, Time:2.3512\n","Step:571/100000, Loss:3.0582, Time:2.4041\n","Step:572/100000, Loss:3.2291, Time:4.1177\n","Step:573/100000, Loss:2.7052, Time:3.9236\n","Step:574/100000, Loss:2.7517, Time:3.1504\n","Step:575/100000, Loss:2.7059, Time:3.4447\n","Step:576/100000, Loss:2.9185, Time:3.9455\n","Step:577/100000, Loss:2.7297, Time:3.2267\n","Step:578/100000, Loss:2.7544, Time:3.9772\n","Step:579/100000, Loss:2.7615, Time:3.2909\n","Step:580/100000, Loss:2.5921, Time:2.7367\n","Step:581/100000, Loss:2.6620, Time:2.4954\n","Step:582/100000, Loss:2.7439, Time:2.4514\n","Step:583/100000, Loss:2.7295, Time:3.7016\n","Step:584/100000, Loss:2.8958, Time:3.7664\n","Step:585/100000, Loss:2.5477, Time:3.4916\n","Step:586/100000, Loss:2.7717, Time:3.6423\n","Step:587/100000, Loss:2.7683, Time:3.7332\n","Step:588/100000, Loss:2.5826, Time:3.6202\n","Step:589/100000, Loss:2.7079, Time:3.7615\n","Step:590/100000, Loss:2.6073, Time:2.7753\n","Step:591/100000, Loss:3.2423, Time:2.8590\n","Step:592/100000, Loss:2.6962, Time:2.3737\n","Step:593/100000, Loss:2.5941, Time:2.4002\n","Step:594/100000, Loss:2.8135, Time:3.6984\n","Step:595/100000, Loss:2.6773, Time:3.5973\n","Step:596/100000, Loss:2.7478, Time:3.5070\n","Step:597/100000, Loss:2.7204, Time:3.3540\n","Step:598/100000, Loss:2.8940, Time:4.1501\n","Step:599/100000, Loss:2.8168, Time:4.6353\n","Validation step:0, Loss:2.7697, Loss Reconstruction:0.1974\n","Validation step:1, Loss:2.8574, Loss Reconstruction:0.2455\n","Validation step:2, Loss:3.1475, Loss Reconstruction:0.2749\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2393\n","early stop count: 4\n","Step:600/100000, Loss:3.0641, Time:2.7422\n","Step:601/100000, Loss:2.5093, Time:2.7272\n","Step:602/100000, Loss:2.4573, Time:2.3875\n","Step:603/100000, Loss:2.7278, Time:2.4463\n","Step:604/100000, Loss:2.5334, Time:2.6332\n","Step:605/100000, Loss:3.3013, Time:3.7827\n","Step:606/100000, Loss:2.5638, Time:3.7683\n","Step:607/100000, Loss:2.6791, Time:2.9712\n","Step:608/100000, Loss:2.2842, Time:3.5505\n","Step:609/100000, Loss:2.9396, Time:3.9383\n","Step:610/100000, Loss:3.2466, Time:3.4974\n","Step:611/100000, Loss:2.9695, Time:3.8842\n","Step:612/100000, Loss:2.5693, Time:2.8663\n","Step:613/100000, Loss:2.8842, Time:2.7167\n","Step:614/100000, Loss:2.7801, Time:2.4173\n","Step:615/100000, Loss:2.8682, Time:2.4505\n","Step:616/100000, Loss:2.4345, Time:3.4748\n","Step:617/100000, Loss:2.8725, Time:3.5660\n","Step:618/100000, Loss:2.7517, Time:3.0091\n","Step:619/100000, Loss:2.7531, Time:3.3515\n","Step:620/100000, Loss:2.9751, Time:3.9659\n","Step:621/100000, Loss:2.6093, Time:3.4649\n","Step:622/100000, Loss:2.5234, Time:4.1258\n","Step:623/100000, Loss:2.8402, Time:3.2133\n","Step:624/100000, Loss:3.0158, Time:2.9169\n","Step:625/100000, Loss:2.7000, Time:2.3993\n","Step:626/100000, Loss:2.7389, Time:2.3564\n","Step:627/100000, Loss:2.8143, Time:3.8651\n","Step:628/100000, Loss:2.7722, Time:3.6655\n","Step:629/100000, Loss:2.4315, Time:3.3336\n","Step:630/100000, Loss:2.8624, Time:3.4136\n","Step:631/100000, Loss:3.0746, Time:3.9965\n","Step:632/100000, Loss:2.9858, Time:3.3556\n","Step:633/100000, Loss:3.0502, Time:4.0211\n","Step:634/100000, Loss:2.9042, Time:3.3257\n","Step:635/100000, Loss:2.5220, Time:2.9166\n","Step:636/100000, Loss:2.8458, Time:2.4491\n","Step:637/100000, Loss:2.8036, Time:2.3908\n","Step:638/100000, Loss:2.9636, Time:3.7380\n","Step:639/100000, Loss:2.7050, Time:3.6590\n","Step:640/100000, Loss:2.7360, Time:2.8567\n","Step:641/100000, Loss:3.1019, Time:3.8243\n","Step:642/100000, Loss:2.6473, Time:3.7895\n","Step:643/100000, Loss:2.7132, Time:3.4579\n","Step:644/100000, Loss:2.8776, Time:3.9107\n","Step:645/100000, Loss:2.6668, Time:3.1557\n","Step:646/100000, Loss:2.7787, Time:2.8661\n","Step:647/100000, Loss:3.1075, Time:2.3908\n","Step:648/100000, Loss:2.6571, Time:2.3817\n","Step:649/100000, Loss:2.5396, Time:3.5522\n","Step:650/100000, Loss:2.5524, Time:3.8235\n","Step:651/100000, Loss:3.2190, Time:3.2721\n","Step:652/100000, Loss:2.5534, Time:3.5819\n","Step:653/100000, Loss:2.7803, Time:3.7648\n","Step:654/100000, Loss:2.6507, Time:3.4182\n","Step:655/100000, Loss:2.7629, Time:3.9222\n","Step:656/100000, Loss:2.8425, Time:3.1025\n","Step:657/100000, Loss:3.0294, Time:2.8283\n","Step:658/100000, Loss:3.4543, Time:2.4502\n","Step:659/100000, Loss:2.8276, Time:2.3647\n","Step:660/100000, Loss:2.7798, Time:3.7947\n","Step:661/100000, Loss:2.8702, Time:3.9145\n","Step:662/100000, Loss:2.8196, Time:3.3178\n","Step:663/100000, Loss:2.6015, Time:3.6567\n","Step:664/100000, Loss:2.7971, Time:3.6663\n","Step:665/100000, Loss:2.8537, Time:3.5417\n","Step:666/100000, Loss:2.7244, Time:5.3213\n","Step:667/100000, Loss:2.5731, Time:3.2230\n","Step:668/100000, Loss:2.8019, Time:2.9579\n","Step:669/100000, Loss:2.9066, Time:2.4107\n","Step:670/100000, Loss:2.5524, Time:2.3985\n","Step:671/100000, Loss:3.1332, Time:3.7953\n","Step:672/100000, Loss:2.5800, Time:3.6508\n","Step:673/100000, Loss:2.7458, Time:3.3064\n","Step:674/100000, Loss:2.5216, Time:3.5035\n","Step:675/100000, Loss:2.8439, Time:3.7868\n","Step:676/100000, Loss:3.1703, Time:3.2000\n","Step:677/100000, Loss:3.0277, Time:3.7643\n","Step:678/100000, Loss:3.1696, Time:3.2675\n","Step:679/100000, Loss:2.8903, Time:2.7110\n","Step:680/100000, Loss:3.0521, Time:2.6871\n","Step:681/100000, Loss:2.7599, Time:2.3771\n","Step:682/100000, Loss:2.6201, Time:3.9267\n","Step:683/100000, Loss:2.6774, Time:3.6035\n","Step:684/100000, Loss:2.6854, Time:2.8992\n","Step:685/100000, Loss:2.8881, Time:3.7060\n","Step:686/100000, Loss:2.8226, Time:3.9230\n","Step:687/100000, Loss:2.9603, Time:3.6450\n","Step:688/100000, Loss:3.2355, Time:3.7614\n","Step:689/100000, Loss:2.7438, Time:3.1171\n","Step:690/100000, Loss:3.0482, Time:2.9038\n","Step:691/100000, Loss:2.5873, Time:2.3677\n","Step:692/100000, Loss:2.8952, Time:2.3799\n","Step:693/100000, Loss:2.6775, Time:3.8189\n","Step:694/100000, Loss:2.8424, Time:3.6800\n","Step:695/100000, Loss:2.5850, Time:2.8800\n","Step:696/100000, Loss:2.5948, Time:3.4686\n","Step:697/100000, Loss:2.6419, Time:4.0487\n","Step:698/100000, Loss:2.6306, Time:3.3064\n","Step:699/100000, Loss:2.9151, Time:3.9941\n","Validation step:0, Loss:2.5952, Loss Reconstruction:0.1329\n","Validation step:1, Loss:2.9574, Loss Reconstruction:0.2055\n","Validation step:2, Loss:2.6985, Loss Reconstruction:0.2352\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.1912\n","early stop count: 5\n","Step:700/100000, Loss:2.5742, Time:2.3903\n","Step:701/100000, Loss:2.5957, Time:2.4554\n","Step:702/100000, Loss:2.8580, Time:2.3777\n","Step:703/100000, Loss:3.1393, Time:2.4375\n","Step:704/100000, Loss:3.1610, Time:3.4083\n","Step:705/100000, Loss:2.9161, Time:3.7328\n","Step:706/100000, Loss:2.7752, Time:3.1494\n","Step:707/100000, Loss:3.1811, Time:3.4458\n","Step:708/100000, Loss:3.0103, Time:3.7393\n","Step:709/100000, Loss:2.8814, Time:3.3250\n","Step:710/100000, Loss:2.9669, Time:4.1184\n","Step:711/100000, Loss:2.6027, Time:3.1914\n","Step:712/100000, Loss:2.4355, Time:2.8268\n","Step:713/100000, Loss:2.8870, Time:2.4849\n","Step:714/100000, Loss:2.7106, Time:2.3672\n","Step:715/100000, Loss:2.6292, Time:4.0189\n","Step:716/100000, Loss:2.8560, Time:4.0161\n","Step:717/100000, Loss:2.8425, Time:3.1702\n","Step:718/100000, Loss:2.7030, Time:3.3857\n","Step:719/100000, Loss:2.7193, Time:3.7200\n","Step:720/100000, Loss:2.6858, Time:3.2257\n","Step:721/100000, Loss:2.7199, Time:4.2247\n","Step:722/100000, Loss:3.0085, Time:3.1208\n","Step:723/100000, Loss:2.8511, Time:2.8211\n","Step:724/100000, Loss:2.8448, Time:2.5356\n","Step:725/100000, Loss:2.7579, Time:2.4179\n","Step:726/100000, Loss:2.6781, Time:3.5975\n","Step:727/100000, Loss:2.6914, Time:3.3762\n","Step:728/100000, Loss:2.9661, Time:3.3721\n","Step:729/100000, Loss:2.7376, Time:3.6397\n","Step:730/100000, Loss:2.7309, Time:3.6542\n","Step:731/100000, Loss:2.5239, Time:3.6543\n","Step:732/100000, Loss:2.9455, Time:3.7129\n","Step:733/100000, Loss:2.6193, Time:3.1004\n","Step:734/100000, Loss:2.9562, Time:2.7811\n","Step:735/100000, Loss:2.7890, Time:2.4541\n","Step:736/100000, Loss:2.9962, Time:2.4269\n","Step:737/100000, Loss:2.7587, Time:3.4384\n","Step:738/100000, Loss:2.5715, Time:3.8000\n","Step:739/100000, Loss:2.6460, Time:2.9127\n","Step:740/100000, Loss:2.5888, Time:3.4211\n","Step:741/100000, Loss:2.7514, Time:3.7813\n","Step:742/100000, Loss:2.7216, Time:3.5822\n","Step:743/100000, Loss:2.7370, Time:4.0096\n","Step:744/100000, Loss:2.6643, Time:2.9334\n","Step:745/100000, Loss:2.7065, Time:2.9190\n","Step:746/100000, Loss:2.7721, Time:2.4538\n","Step:747/100000, Loss:2.7529, Time:2.3889\n","Step:748/100000, Loss:2.5024, Time:3.6430\n","Step:749/100000, Loss:2.8905, Time:3.5157\n","Step:750/100000, Loss:2.6627, Time:3.2817\n","Step:751/100000, Loss:2.7234, Time:3.4234\n","Step:752/100000, Loss:2.7576, Time:3.8753\n","Step:753/100000, Loss:2.5521, Time:3.3320\n","Step:754/100000, Loss:2.7256, Time:4.0717\n","Step:755/100000, Loss:2.8340, Time:2.9973\n","Step:756/100000, Loss:2.4760, Time:2.6831\n","Step:757/100000, Loss:2.9302, Time:2.3882\n","Step:758/100000, Loss:2.9073, Time:2.3785\n","Step:759/100000, Loss:2.9150, Time:3.6842\n","Step:760/100000, Loss:3.0575, Time:3.8620\n","Step:761/100000, Loss:2.7232, Time:3.1733\n","Step:762/100000, Loss:2.7876, Time:3.6102\n","Step:763/100000, Loss:2.7306, Time:3.8878\n","Step:764/100000, Loss:2.6071, Time:3.4563\n","Step:765/100000, Loss:2.7675, Time:4.4335\n","Step:766/100000, Loss:2.8575, Time:2.7788\n","Step:767/100000, Loss:2.6604, Time:2.8894\n","Step:768/100000, Loss:2.6878, Time:2.3861\n","Step:769/100000, Loss:2.5091, Time:2.6356\n","Step:770/100000, Loss:2.7425, Time:3.9203\n","Step:771/100000, Loss:2.7308, Time:3.8527\n","Step:772/100000, Loss:2.6623, Time:3.4186\n","Step:773/100000, Loss:2.5457, Time:3.4704\n","Step:774/100000, Loss:2.8174, Time:4.0203\n","Step:775/100000, Loss:2.3464, Time:3.3717\n","Step:776/100000, Loss:2.8131, Time:4.0344\n","Step:777/100000, Loss:3.0006, Time:2.9994\n","Step:778/100000, Loss:3.0756, Time:2.8832\n","Step:779/100000, Loss:2.9238, Time:2.4549\n","Step:780/100000, Loss:2.8265, Time:2.3959\n","Step:781/100000, Loss:2.6837, Time:3.6346\n","Step:782/100000, Loss:2.5430, Time:3.4316\n","Step:783/100000, Loss:2.5437, Time:3.5630\n","Step:784/100000, Loss:2.4894, Time:3.6789\n","Step:785/100000, Loss:2.9134, Time:3.9012\n","Step:786/100000, Loss:2.6904, Time:3.1994\n","Step:787/100000, Loss:2.6529, Time:3.9511\n","Step:788/100000, Loss:2.6916, Time:3.1702\n","Step:789/100000, Loss:2.8164, Time:2.7649\n","Step:790/100000, Loss:2.7431, Time:2.5453\n","Step:791/100000, Loss:2.6564, Time:2.3802\n","Step:792/100000, Loss:2.8688, Time:3.9701\n","Step:793/100000, Loss:2.7138, Time:3.5463\n","Step:794/100000, Loss:2.6639, Time:3.2352\n","Step:795/100000, Loss:2.6693, Time:3.5996\n","Step:796/100000, Loss:2.7794, Time:4.0007\n","Step:797/100000, Loss:2.4250, Time:3.6936\n","Step:798/100000, Loss:2.9329, Time:4.1107\n","Step:799/100000, Loss:3.0041, Time:2.7391\n","Validation step:0, Loss:2.8962, Loss Reconstruction:0.3783\n","Validation step:1, Loss:2.3132, Loss Reconstruction:0.2306\n","Validation step:2, Loss:2.6787, Loss Reconstruction:0.2360\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2816\n","early stop count: 6\n","Step:800/100000, Loss:3.0075, Time:2.3822\n","Step:801/100000, Loss:2.4703, Time:2.3710\n","Step:802/100000, Loss:2.9547, Time:2.3737\n","Step:803/100000, Loss:3.2072, Time:3.7860\n","Step:804/100000, Loss:2.2775, Time:3.4895\n","Step:805/100000, Loss:3.0484, Time:3.2241\n","Step:806/100000, Loss:2.9138, Time:3.3974\n","Step:807/100000, Loss:3.0360, Time:4.9705\n","Step:808/100000, Loss:2.7285, Time:3.5679\n","Step:809/100000, Loss:2.9346, Time:3.9791\n","Step:810/100000, Loss:2.6640, Time:3.2214\n","Step:811/100000, Loss:2.8181, Time:2.9012\n","Step:812/100000, Loss:2.7177, Time:2.3691\n","Step:813/100000, Loss:2.8162, Time:2.5204\n","Step:814/100000, Loss:2.8430, Time:3.7366\n","Step:815/100000, Loss:2.7488, Time:3.6468\n","Step:816/100000, Loss:2.7073, Time:3.0970\n","Step:817/100000, Loss:2.7896, Time:3.6676\n","Step:818/100000, Loss:2.7665, Time:3.6616\n","Step:819/100000, Loss:2.8628, Time:3.4930\n","Step:820/100000, Loss:2.6439, Time:4.1698\n","Step:821/100000, Loss:3.0035, Time:2.8749\n","Step:822/100000, Loss:2.8413, Time:2.9586\n","Step:823/100000, Loss:2.9403, Time:2.3591\n","Step:824/100000, Loss:2.7671, Time:2.3665\n","Step:825/100000, Loss:2.7151, Time:3.8964\n","Step:826/100000, Loss:2.7435, Time:3.4902\n","Step:827/100000, Loss:2.7224, Time:3.3903\n","Step:828/100000, Loss:2.7328, Time:3.3529\n","Step:829/100000, Loss:2.7317, Time:3.9013\n","Step:830/100000, Loss:2.7311, Time:3.2497\n","Step:831/100000, Loss:2.5821, Time:3.9981\n","Step:832/100000, Loss:2.8047, Time:3.1704\n","Step:833/100000, Loss:2.6020, Time:2.8128\n","Step:834/100000, Loss:2.9138, Time:2.4538\n","Step:835/100000, Loss:3.0052, Time:2.4217\n","Step:836/100000, Loss:2.7389, Time:4.0060\n","Step:837/100000, Loss:2.7017, Time:3.9546\n","Step:838/100000, Loss:2.6068, Time:3.2695\n","Step:839/100000, Loss:2.4796, Time:3.5311\n","Step:840/100000, Loss:2.5602, Time:3.7735\n","Step:841/100000, Loss:2.8560, Time:3.4498\n","Step:842/100000, Loss:2.8261, Time:4.2053\n","Step:843/100000, Loss:2.5844, Time:3.0004\n","Step:844/100000, Loss:2.7378, Time:2.9202\n","Step:845/100000, Loss:2.7881, Time:2.4093\n","Step:846/100000, Loss:2.6367, Time:2.4121\n","Step:847/100000, Loss:2.6309, Time:3.4165\n","Step:848/100000, Loss:2.7668, Time:3.5451\n","Step:849/100000, Loss:2.7386, Time:3.1596\n","Step:850/100000, Loss:2.6730, Time:3.5241\n","Step:851/100000, Loss:2.8634, Time:4.0140\n","Step:852/100000, Loss:2.8477, Time:3.5919\n","Step:853/100000, Loss:2.8700, Time:4.0148\n","Step:854/100000, Loss:2.8710, Time:2.8947\n","Step:855/100000, Loss:2.8936, Time:2.8930\n","Step:856/100000, Loss:2.7390, Time:2.4288\n","Step:857/100000, Loss:2.7726, Time:2.4584\n","Step:858/100000, Loss:2.6704, Time:3.8067\n","Step:859/100000, Loss:2.7779, Time:3.4473\n","Step:860/100000, Loss:2.7098, Time:3.4313\n","Step:861/100000, Loss:2.5763, Time:3.9235\n","Step:862/100000, Loss:2.7944, Time:3.6893\n","Step:863/100000, Loss:2.6042, Time:3.4122\n","Step:864/100000, Loss:2.6794, Time:4.1703\n","Step:865/100000, Loss:2.8190, Time:2.9916\n","Step:866/100000, Loss:2.5258, Time:2.9407\n","Step:867/100000, Loss:2.7898, Time:2.4115\n","Step:868/100000, Loss:3.0369, Time:2.4198\n","Step:869/100000, Loss:3.0354, Time:3.9596\n","Step:870/100000, Loss:2.4959, Time:3.6559\n","Step:871/100000, Loss:3.0762, Time:3.1363\n","Step:872/100000, Loss:2.6751, Time:3.5519\n","Step:873/100000, Loss:2.6504, Time:3.7759\n","Step:874/100000, Loss:2.9339, Time:3.9026\n","Step:875/100000, Loss:2.8064, Time:4.1191\n","Step:876/100000, Loss:2.5772, Time:2.7515\n","Step:877/100000, Loss:2.9262, Time:2.9461\n","Step:878/100000, Loss:2.9162, Time:2.3828\n","Step:879/100000, Loss:2.6073, Time:2.4020\n","Step:880/100000, Loss:2.6925, Time:3.6437\n","Step:881/100000, Loss:2.8291, Time:3.8085\n","Step:882/100000, Loss:2.6667, Time:4.6924\n","Step:883/100000, Loss:2.7072, Time:3.5169\n","Step:884/100000, Loss:2.7879, Time:3.9374\n","Step:885/100000, Loss:2.6687, Time:3.5129\n","Step:886/100000, Loss:2.6486, Time:4.0479\n","Step:887/100000, Loss:2.8528, Time:3.0430\n","Step:888/100000, Loss:2.7604, Time:2.8974\n","Step:889/100000, Loss:2.7371, Time:2.4139\n","Step:890/100000, Loss:2.7157, Time:2.4070\n","Step:891/100000, Loss:2.8202, Time:3.5860\n","Step:892/100000, Loss:2.7875, Time:3.6170\n","Step:893/100000, Loss:2.7597, Time:3.1757\n","Step:894/100000, Loss:2.6416, Time:3.3998\n","Step:895/100000, Loss:2.6975, Time:3.7616\n","Step:896/100000, Loss:2.7863, Time:3.6223\n","Step:897/100000, Loss:2.6194, Time:3.9278\n","Step:898/100000, Loss:2.7886, Time:2.8934\n","Step:899/100000, Loss:2.7543, Time:2.8798\n","Validation step:0, Loss:2.6435, Loss Reconstruction:0.2082\n","Validation step:1, Loss:2.9395, Loss Reconstruction:0.2157\n","Validation step:2, Loss:2.5783, Loss Reconstruction:0.1760\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2000\n","early stop count: 7\n","Step:900/100000, Loss:2.8931, Time:2.3891\n","Step:901/100000, Loss:2.9430, Time:2.3925\n","Step:902/100000, Loss:2.7283, Time:3.9819\n","Step:903/100000, Loss:2.6824, Time:3.7799\n","Step:904/100000, Loss:2.6974, Time:3.5379\n","Step:905/100000, Loss:2.7233, Time:3.6476\n","Step:906/100000, Loss:2.6463, Time:3.7665\n","Step:907/100000, Loss:2.7171, Time:3.6616\n","Step:908/100000, Loss:2.8839, Time:4.2206\n","Step:909/100000, Loss:2.7324, Time:2.9788\n","Step:910/100000, Loss:2.8635, Time:2.7715\n","Step:911/100000, Loss:2.7774, Time:2.4188\n","Step:912/100000, Loss:2.7595, Time:2.3808\n","Step:913/100000, Loss:2.7575, Time:3.9573\n","Step:914/100000, Loss:2.7454, Time:3.8275\n","Step:915/100000, Loss:2.6689, Time:2.9247\n","Step:916/100000, Loss:2.7434, Time:3.3150\n","Step:917/100000, Loss:2.6359, Time:3.6755\n","Step:918/100000, Loss:3.0717, Time:3.7011\n","Step:919/100000, Loss:2.7107, Time:3.9335\n","Step:920/100000, Loss:2.5634, Time:3.2138\n","Step:921/100000, Loss:2.6738, Time:2.9554\n","Step:922/100000, Loss:2.7053, Time:2.4697\n","Step:923/100000, Loss:2.8246, Time:2.4126\n","Step:924/100000, Loss:2.8664, Time:3.8187\n","Step:925/100000, Loss:2.7574, Time:3.8638\n","Step:926/100000, Loss:2.8944, Time:3.3475\n","Step:927/100000, Loss:2.5954, Time:3.5652\n","Step:928/100000, Loss:2.8585, Time:3.8263\n","Step:929/100000, Loss:2.8418, Time:3.1783\n","Step:930/100000, Loss:2.7601, Time:4.0319\n","Step:931/100000, Loss:2.8677, Time:3.0945\n","Step:932/100000, Loss:2.6929, Time:2.8246\n","Step:933/100000, Loss:2.7761, Time:2.4438\n","Step:934/100000, Loss:2.7489, Time:2.4053\n","Step:935/100000, Loss:2.6610, Time:3.6828\n","Step:936/100000, Loss:2.6839, Time:4.0086\n","Step:937/100000, Loss:2.6202, Time:2.8250\n","Step:938/100000, Loss:2.7674, Time:3.6079\n","Step:939/100000, Loss:2.6785, Time:3.8491\n","Step:940/100000, Loss:2.5303, Time:3.6152\n","Step:941/100000, Loss:2.5068, Time:4.1210\n","Step:942/100000, Loss:3.2161, Time:2.8181\n","Step:943/100000, Loss:2.7507, Time:3.0056\n","Step:944/100000, Loss:2.7119, Time:2.3907\n","Step:945/100000, Loss:2.6684, Time:2.3950\n","Step:946/100000, Loss:2.6496, Time:3.6268\n","Step:947/100000, Loss:2.8762, Time:3.3121\n","Step:948/100000, Loss:2.8234, Time:3.2988\n","Step:949/100000, Loss:2.7263, Time:3.4939\n","Step:950/100000, Loss:2.8039, Time:3.9174\n","Step:951/100000, Loss:2.6333, Time:3.7852\n","Step:952/100000, Loss:2.9629, Time:4.1016\n","Step:953/100000, Loss:2.7843, Time:3.1156\n","Step:954/100000, Loss:2.9020, Time:2.8900\n","Step:955/100000, Loss:2.8187, Time:2.4410\n","Step:956/100000, Loss:2.8969, Time:2.3651\n","Step:957/100000, Loss:2.5902, Time:3.6873\n","Step:958/100000, Loss:2.7321, Time:3.8854\n","Step:959/100000, Loss:2.9988, Time:2.9368\n","Step:960/100000, Loss:2.7107, Time:3.5713\n","Step:961/100000, Loss:2.7254, Time:3.7516\n","Step:962/100000, Loss:2.6328, Time:3.4647\n","Step:963/100000, Loss:2.6887, Time:4.0024\n","Step:964/100000, Loss:2.7187, Time:2.9582\n","Step:965/100000, Loss:2.8025, Time:2.9735\n","Step:966/100000, Loss:2.8287, Time:2.4173\n","Step:967/100000, Loss:2.7194, Time:2.3919\n","Step:968/100000, Loss:2.5709, Time:3.8608\n","Step:969/100000, Loss:2.6846, Time:3.7195\n","Step:970/100000, Loss:2.7580, Time:3.4065\n","Step:971/100000, Loss:2.7933, Time:3.5589\n","Step:972/100000, Loss:2.7937, Time:3.8752\n","Step:973/100000, Loss:2.6939, Time:3.8744\n","Step:974/100000, Loss:2.7670, Time:4.0231\n","Step:975/100000, Loss:2.6356, Time:2.9743\n","Step:976/100000, Loss:2.6842, Time:2.9014\n","Step:977/100000, Loss:2.7719, Time:2.3962\n","Step:978/100000, Loss:2.9051, Time:2.3973\n","Step:979/100000, Loss:2.7474, Time:3.5715\n","Step:980/100000, Loss:2.7316, Time:3.7565\n","Step:981/100000, Loss:2.7042, Time:2.8271\n","Step:982/100000, Loss:2.4553, Time:3.4623\n","Step:983/100000, Loss:2.9552, Time:3.7646\n","Step:984/100000, Loss:2.9719, Time:3.5910\n","Step:985/100000, Loss:2.7447, Time:4.1755\n","Step:986/100000, Loss:2.5609, Time:2.9214\n","Step:987/100000, Loss:2.7410, Time:2.9237\n","Step:988/100000, Loss:2.7191, Time:2.3847\n","Step:989/100000, Loss:2.9057, Time:2.3911\n","Step:990/100000, Loss:2.8199, Time:3.8422\n","Step:991/100000, Loss:2.6975, Time:3.5884\n","Step:992/100000, Loss:2.6257, Time:3.3536\n","Step:993/100000, Loss:2.8718, Time:3.6099\n","Step:994/100000, Loss:2.7137, Time:3.6930\n","Step:995/100000, Loss:2.7464, Time:3.5660\n","Step:996/100000, Loss:2.6974, Time:4.4751\n","Step:997/100000, Loss:2.4985, Time:3.0581\n","Step:998/100000, Loss:2.5439, Time:3.1759\n","Step:999/100000, Loss:2.8746, Time:2.3909\n","Validation step:0, Loss:2.9747, Loss Reconstruction:0.2602\n","Validation step:1, Loss:2.9560, Loss Reconstruction:0.2458\n","Validation step:2, Loss:3.0585, Loss Reconstruction:0.2732\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2597\n","early stop count: 8\n","Step:1000/100000, Loss:2.5687, Time:2.4002\n","Step:1001/100000, Loss:2.6547, Time:4.2430\n","Step:1002/100000, Loss:2.7685, Time:3.8696\n","Step:1003/100000, Loss:2.6318, Time:3.0790\n","Step:1004/100000, Loss:2.8928, Time:3.5260\n","Step:1005/100000, Loss:2.5837, Time:3.8382\n","Step:1006/100000, Loss:2.8169, Time:3.3322\n","Step:1007/100000, Loss:2.6783, Time:3.6490\n","Step:1008/100000, Loss:2.8863, Time:3.2437\n","Step:1009/100000, Loss:3.0027, Time:2.8167\n","Step:1010/100000, Loss:2.9038, Time:2.5264\n","Step:1011/100000, Loss:2.7688, Time:2.4264\n","Step:1012/100000, Loss:2.8534, Time:3.8636\n","Step:1013/100000, Loss:2.6052, Time:3.8428\n","Step:1014/100000, Loss:2.5358, Time:3.4316\n","Step:1015/100000, Loss:2.8205, Time:3.7433\n","Step:1016/100000, Loss:2.6234, Time:4.5024\n","Step:1017/100000, Loss:2.6334, Time:4.6930\n","Step:1018/100000, Loss:2.9028, Time:4.0738\n","Step:1019/100000, Loss:2.7270, Time:2.7870\n","Step:1020/100000, Loss:2.7477, Time:2.8455\n","Step:1021/100000, Loss:2.7271, Time:2.3804\n","Step:1022/100000, Loss:2.7985, Time:2.3687\n","Step:1023/100000, Loss:2.8232, Time:3.6582\n","Step:1024/100000, Loss:2.6526, Time:3.7126\n","Step:1025/100000, Loss:2.9613, Time:3.5916\n","Step:1026/100000, Loss:2.8047, Time:3.5847\n","Step:1027/100000, Loss:2.7791, Time:3.6606\n","Step:1028/100000, Loss:2.8950, Time:3.6726\n","Step:1029/100000, Loss:2.6229, Time:3.9964\n","Step:1030/100000, Loss:2.7092, Time:3.0524\n","Step:1031/100000, Loss:2.5844, Time:2.8965\n","Step:1032/100000, Loss:2.5940, Time:2.3638\n","Step:1033/100000, Loss:2.5832, Time:2.4417\n","Step:1034/100000, Loss:2.8020, Time:3.5714\n","Step:1035/100000, Loss:2.6641, Time:3.9323\n","Step:1036/100000, Loss:2.5989, Time:3.2488\n","Step:1037/100000, Loss:2.6036, Time:3.4043\n","Step:1038/100000, Loss:2.5278, Time:3.9616\n","Step:1039/100000, Loss:2.5341, Time:3.5389\n","Step:1040/100000, Loss:2.5691, Time:4.0475\n","Step:1041/100000, Loss:2.7338, Time:2.7815\n","Step:1042/100000, Loss:2.8283, Time:2.8751\n","Step:1043/100000, Loss:2.6419, Time:2.4120\n","Step:1044/100000, Loss:2.5079, Time:2.5468\n","Step:1045/100000, Loss:2.8663, Time:3.9004\n","Step:1046/100000, Loss:3.2467, Time:3.5786\n","Step:1047/100000, Loss:2.5485, Time:3.3009\n","Step:1048/100000, Loss:2.6347, Time:3.6528\n","Step:1049/100000, Loss:2.8321, Time:3.8724\n","Step:1050/100000, Loss:2.7834, Time:3.6957\n","Step:1051/100000, Loss:2.4671, Time:4.1357\n","Step:1052/100000, Loss:3.1405, Time:2.8319\n","Step:1053/100000, Loss:2.7787, Time:2.9820\n","Step:1054/100000, Loss:2.8530, Time:2.4209\n","Step:1055/100000, Loss:3.1359, Time:2.4011\n","Step:1056/100000, Loss:2.8527, Time:3.6586\n","Step:1057/100000, Loss:2.6695, Time:3.7516\n","Step:1058/100000, Loss:2.5403, Time:3.0787\n","Step:1059/100000, Loss:2.7973, Time:3.3502\n","Step:1060/100000, Loss:2.5263, Time:3.9559\n","Step:1061/100000, Loss:2.7185, Time:3.6685\n","Step:1062/100000, Loss:2.8708, Time:3.8271\n","Step:1063/100000, Loss:2.7758, Time:3.1739\n","Step:1064/100000, Loss:2.9552, Time:2.9798\n","Step:1065/100000, Loss:3.1432, Time:2.4203\n","Step:1066/100000, Loss:2.6538, Time:2.4039\n","Step:1067/100000, Loss:2.9227, Time:3.8252\n","Step:1068/100000, Loss:2.9584, Time:3.7835\n","Step:1069/100000, Loss:2.3846, Time:3.2305\n","Step:1070/100000, Loss:3.2033, Time:3.7042\n","Step:1071/100000, Loss:2.9122, Time:3.7833\n","Step:1072/100000, Loss:2.6488, Time:3.6795\n","Step:1073/100000, Loss:2.8450, Time:4.1299\n","Step:1074/100000, Loss:2.9208, Time:2.9083\n","Step:1075/100000, Loss:2.9544, Time:2.8890\n","Step:1076/100000, Loss:2.6986, Time:2.4150\n","Step:1077/100000, Loss:2.8315, Time:2.4032\n","Step:1078/100000, Loss:2.5970, Time:3.8637\n","Step:1079/100000, Loss:2.8393, Time:3.6491\n","Step:1080/100000, Loss:2.7883, Time:3.3801\n","Step:1081/100000, Loss:2.6877, Time:3.6662\n","Step:1082/100000, Loss:2.6428, Time:3.8485\n","Step:1083/100000, Loss:2.7928, Time:3.2502\n","Step:1084/100000, Loss:2.8322, Time:4.0207\n","Step:1085/100000, Loss:2.9630, Time:2.9698\n","Step:1086/100000, Loss:2.4833, Time:2.8528\n","Step:1087/100000, Loss:2.8543, Time:2.4095\n","Step:1088/100000, Loss:2.8557, Time:2.3423\n","Step:1089/100000, Loss:2.9381, Time:4.1095\n","Step:1090/100000, Loss:2.7632, Time:3.5848\n","Step:1091/100000, Loss:2.7860, Time:3.4030\n","Step:1092/100000, Loss:2.5363, Time:4.1559\n","Step:1093/100000, Loss:2.8295, Time:4.9446\n","Step:1094/100000, Loss:2.4962, Time:3.5686\n","Step:1095/100000, Loss:2.8732, Time:3.8556\n","Step:1096/100000, Loss:2.5503, Time:3.0951\n","Step:1097/100000, Loss:2.8864, Time:2.8793\n","Step:1098/100000, Loss:2.8721, Time:2.4352\n","Step:1099/100000, Loss:2.7233, Time:2.4139\n","Validation step:0, Loss:2.6653, Loss Reconstruction:0.2059\n","Validation step:1, Loss:2.8650, Loss Reconstruction:0.2409\n","Validation step:2, Loss:2.8813, Loss Reconstruction:0.2958\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2475\n","early stop count: 9\n","Step:1100/100000, Loss:2.5428, Time:3.8632\n","Step:1101/100000, Loss:2.6038, Time:4.2473\n","Step:1102/100000, Loss:2.6530, Time:3.1531\n","Step:1103/100000, Loss:2.6662, Time:3.6846\n","Step:1104/100000, Loss:2.9273, Time:3.7448\n","Step:1105/100000, Loss:2.5292, Time:3.5428\n","Step:1106/100000, Loss:2.6317, Time:4.0078\n","Step:1107/100000, Loss:2.9152, Time:2.9994\n","Step:1108/100000, Loss:2.7991, Time:2.9461\n","Step:1109/100000, Loss:2.8460, Time:2.4267\n","Step:1110/100000, Loss:2.6033, Time:2.4475\n","Step:1111/100000, Loss:2.9309, Time:3.9904\n","Step:1112/100000, Loss:2.5414, Time:3.6787\n","Step:1113/100000, Loss:2.8072, Time:3.4373\n","Step:1114/100000, Loss:3.0178, Time:3.5574\n","Step:1115/100000, Loss:2.7546, Time:3.6010\n","Step:1116/100000, Loss:2.6476, Time:3.6620\n","Step:1117/100000, Loss:2.7607, Time:3.8915\n","Step:1118/100000, Loss:2.8066, Time:2.9148\n","Step:1119/100000, Loss:2.7390, Time:2.8661\n","Step:1120/100000, Loss:2.7454, Time:2.4738\n","Step:1121/100000, Loss:2.7701, Time:2.4417\n","Step:1122/100000, Loss:2.8407, Time:3.9651\n","Step:1123/100000, Loss:2.8383, Time:3.9810\n","Step:1124/100000, Loss:2.7205, Time:3.2630\n","Step:1125/100000, Loss:2.7646, Time:3.5619\n","Step:1126/100000, Loss:2.5370, Time:4.0842\n","Step:1127/100000, Loss:2.7663, Time:3.3249\n","Step:1128/100000, Loss:2.7916, Time:4.1802\n","Step:1129/100000, Loss:2.8255, Time:2.8293\n","Step:1130/100000, Loss:2.6124, Time:2.9316\n","Step:1131/100000, Loss:2.6663, Time:2.4554\n","Step:1132/100000, Loss:2.5844, Time:2.3924\n","Step:1133/100000, Loss:2.8560, Time:3.7390\n","Step:1134/100000, Loss:2.9521, Time:4.0226\n","Step:1135/100000, Loss:2.6914, Time:3.4976\n","Step:1136/100000, Loss:2.9007, Time:3.6044\n","Step:1137/100000, Loss:2.6736, Time:3.8494\n","Step:1138/100000, Loss:2.7159, Time:3.5356\n","Step:1139/100000, Loss:2.6950, Time:3.9439\n","Step:1140/100000, Loss:2.8441, Time:3.0601\n","Step:1141/100000, Loss:2.8400, Time:2.9515\n","Step:1142/100000, Loss:2.6849, Time:2.4366\n","Step:1143/100000, Loss:2.5902, Time:2.4157\n","Step:1144/100000, Loss:2.7440, Time:3.7505\n","Step:1145/100000, Loss:2.5261, Time:3.7093\n","Step:1146/100000, Loss:2.9674, Time:3.0413\n","Step:1147/100000, Loss:2.6269, Time:3.4814\n","Step:1148/100000, Loss:3.0145, Time:4.0754\n","Step:1149/100000, Loss:2.7803, Time:3.5803\n","Step:1150/100000, Loss:2.8837, Time:4.1716\n","Step:1151/100000, Loss:2.5188, Time:2.8728\n","Step:1152/100000, Loss:2.6544, Time:2.9044\n","Step:1153/100000, Loss:2.7230, Time:2.4221\n","Step:1154/100000, Loss:2.8898, Time:2.3606\n","Step:1155/100000, Loss:2.7395, Time:4.0490\n","Step:1156/100000, Loss:2.5893, Time:3.6792\n","Step:1157/100000, Loss:2.8208, Time:3.1218\n","Step:1158/100000, Loss:2.7269, Time:3.5504\n","Step:1159/100000, Loss:2.8103, Time:3.9059\n","Step:1160/100000, Loss:2.7117, Time:3.5638\n","Step:1161/100000, Loss:2.7364, Time:3.8340\n","Step:1162/100000, Loss:2.6929, Time:3.0452\n","Step:1163/100000, Loss:2.7355, Time:2.9139\n","Step:1164/100000, Loss:2.6182, Time:2.4076\n","Step:1165/100000, Loss:2.8505, Time:2.3950\n","Step:1166/100000, Loss:2.7396, Time:3.7514\n","Step:1167/100000, Loss:2.6805, Time:3.7927\n","Step:1168/100000, Loss:2.6485, Time:3.0942\n","Step:1169/100000, Loss:2.6624, Time:3.6591\n","Step:1170/100000, Loss:2.9315, Time:4.6661\n","Step:1171/100000, Loss:2.6645, Time:4.1836\n","Step:1172/100000, Loss:2.7236, Time:4.1603\n","Step:1173/100000, Loss:2.8361, Time:2.7661\n","Step:1174/100000, Loss:2.6854, Time:2.8429\n","Step:1175/100000, Loss:2.6522, Time:2.4569\n","Step:1176/100000, Loss:2.8012, Time:2.3722\n","Step:1177/100000, Loss:2.7200, Time:3.8073\n","Step:1178/100000, Loss:2.8357, Time:3.7023\n","Step:1179/100000, Loss:2.5953, Time:2.9481\n","Step:1180/100000, Loss:2.8100, Time:3.0481\n","Step:1181/100000, Loss:2.5221, Time:4.3594\n","Step:1182/100000, Loss:2.5049, Time:3.5676\n","Step:1183/100000, Loss:2.9124, Time:3.8228\n","Step:1184/100000, Loss:2.6698, Time:3.1764\n","Step:1185/100000, Loss:2.7329, Time:2.9552\n","Step:1186/100000, Loss:2.6727, Time:2.4352\n","Step:1187/100000, Loss:2.9224, Time:2.3859\n","Step:1188/100000, Loss:2.6809, Time:3.8955\n","Step:1189/100000, Loss:2.6105, Time:3.7610\n","Step:1190/100000, Loss:2.9135, Time:3.4103\n","Step:1191/100000, Loss:2.8964, Time:3.4696\n","Step:1192/100000, Loss:2.7713, Time:3.6399\n","Step:1193/100000, Loss:2.4760, Time:3.2784\n","Step:1194/100000, Loss:2.5932, Time:3.7666\n","Step:1195/100000, Loss:2.9722, Time:3.4527\n","Step:1196/100000, Loss:2.7064, Time:2.7125\n","Step:1197/100000, Loss:2.8215, Time:2.4329\n","Step:1198/100000, Loss:2.7832, Time:2.4055\n","Step:1199/100000, Loss:2.6872, Time:3.7982\n","Validation step:0, Loss:2.8096, Loss Reconstruction:0.3170\n","Validation step:1, Loss:2.6189, Loss Reconstruction:0.1517\n","Validation step:2, Loss:2.7426, Loss Reconstruction:0.2076\n","Model was not saved ! Best Recon. Val Loss: 0.1158 Recon. Val Loss: 0.2254\n","early stop count: 10\n","Step:1200/100000, Loss:2.6534, Time:2.7406\n","Step:1201/100000, Loss:2.5981, Time:3.1678\n","Step:1202/100000, Loss:2.7531, Time:3.2202\n","Step:1203/100000, Loss:2.5359, Time:4.0044\n","Step:1204/100000, Loss:2.7871, Time:3.6896\n","Step:1205/100000, Loss:2.7902, Time:3.4080\n","Step:1206/100000, Loss:2.6651, Time:3.0988\n","Step:1207/100000, Loss:2.9376, Time:2.6917\n","Step:1208/100000, Loss:2.7506, Time:2.4120\n","Step:1209/100000, Loss:2.7528, Time:2.3961\n"]}]}]}