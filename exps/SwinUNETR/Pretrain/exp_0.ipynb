{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"HfBsNHQp62I7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665045454090,"user_tz":-480,"elapsed":55875,"user":{"displayName":"t3","userId":"02136306931120995994"}},"outputId":"b12709b1-798d-461e-ff1d-5abe294abc09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1jz_DGnICBmKWCr_JL904PDQdIEK0_EQG/CardiacSeg/SwinUNETR/Pretrain/Pretrain\n","\u001b[K     |████████████████████████████████| 251 kB 24.7 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 151 kB 57.3 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 331 kB/s \n","\u001b[K     |████████████████████████████████| 52.8 MB 256 kB/s \n","\u001b[K     |████████████████████████████████| 96 kB 432 kB/s \n","\u001b[K     |████████████████████████████████| 13.0 MB 58.8 MB/s \n","\u001b[K     |████████████████████████████████| 2.0 MB 53.0 MB/s \n","\u001b[?25h  Building wheel for nnunet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.1 MB 30.3 MB/s \n","\u001b[?25h"]}],"source":["# mount driver\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/CardiacSeg/SwinUNETR/Pretrain/Pretrain\n","\n","# install dependents\n","!pip install -q nnunet\n","!pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n","!pip install -q tensorboardX==2.1\n","!python -c \"import matplotlib\" || pip install -q matplotlib\n","%matplotlib inline\n","\n","# sync python module\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["import sys\n","# set package path\n","sys.path.append(\"/content/drive/MyDrive/CardiacSeg\")\n","\n","import os\n","from pathlib import PurePath\n","\n","from monai.transforms import (\n","    Compose,\n","    LoadImaged,\n",")\n","\n","from data_utils.json_dataset import generate_dataset_json\n","from data_utils import (\n","    segthor_dataset as sg_ds,\n","    mmwhs_dataset as mmwhs_ds\n",")"],"metadata":{"id":"h3M6JI7_7U6e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"8Xt6KKZ2xDY-"}},{"cell_type":"code","source":["sg_dir = '/content/drive/MyDrive/CardiacSeg/dataset/SegTHOR'\n","sg_data_dir = os.path.join(sg_dir, 'train')\n","sg_data_json_pth = os.path.join(sg_dir, 'dataset.json')\n","\n","mmwhs_dir = '/content/drive/MyDrive/CardiacSeg/dataset/MM_WHS_2017'\n","mmwhs_data_dir = os.path.join(mmwhs_dir, 'ct_train')\n","mmwhs_data_json_pth = os.path.join(mmwhs_dir, 'dataset.json')"],"metadata":{"id":"rtQlnV69w_jR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generate data json file"],"metadata":{"id":"bXAggojBs9u0"}},{"cell_type":"code","source":["# segthor\n","sg_data_dicts = sg_ds.get_data_dicts(sg_data_dir)\n","generate_dataset_json(\n","    sg_data_dicts,\n","    sg_data_json_pth,\n","    dataset_name='segthor',\n","    labels={0: 'background', 2: 'heart'},\n","    tensorImageSize='3D',\n","    sort_keys=True,\n","    modalities=['CT'],\n","    license='see challenge website',\n","    split_train_ratio=0.8,\n","    fold=4,\n","    num_fold=5,\n",")"],"metadata":{"id":"KUhohVc8s7uB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664959546036,"user_tz":-480,"elapsed":5,"user":{"displayName":"t2","userId":"07580859786475662000"}},"outputId":"292a07fd-dd81-4b62-9a42-986907ed3a3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fold: 4\n","train files (26): ['Patient_01', 'Patient_02', 'Patient_03', 'Patient_04', 'Patient_05', 'Patient_06', 'Patient_07', 'Patient_08', 'Patient_09', 'Patient_10', 'Patient_11', 'Patient_12', 'Patient_13', 'Patient_14', 'Patient_15', 'Patient_16', 'Patient_17', 'Patient_18', 'Patient_19', 'Patient_20', 'Patient_21', 'Patient_22', 'Patient_23', 'Patient_24', 'Patient_25', 'Patient_26']\n","val files (6): ['Patient_27', 'Patient_28', 'Patient_29', 'Patient_30', 'Patient_31', 'Patient_32']\n","test files (8): ['Patient_33', 'Patient_34', 'Patient_35', 'Patient_36', 'Patient_37', 'Patient_38', 'Patient_39', 'Patient_40']\n","save json to /content/drive/MyDrive/CardiacSeg/dataset/SegTHOR/dataset.json\n"]}]},{"cell_type":"code","source":["# mmwhs\n","mmwhs_data_dicts = mmwhs_ds.get_data_dicts(mmwhs_data_dir)\n","generate_dataset_json(\n","    mmwhs_data_dicts,\n","    mmwhs_data_json_pth,\n","    dataset_name='mmwhs',\n","    labels={\n","        0: 'background', \n","        500: 'lv', \n","        600: 'rv', \n","        420: 'la', \n","        550: 'ra', \n","        205: 'mlv',\n","        820: 'aa',\n","        850: 'pa',\n","    },\n","    tensorImageSize='3D',\n","    sort_keys=True,\n","    modalities=['CT'],\n","    license='see challenge website',\n","    split_train_ratio=0.8,\n","    fold=4,\n","    num_fold=5,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7V6OUGvMAUT","executionInfo":{"status":"ok","timestamp":1664959547290,"user_tz":-480,"elapsed":2,"user":{"displayName":"t2","userId":"07580859786475662000"}},"outputId":"efa0de2f-f78f-4558-aef1-59045d5c8c91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fold: 4\n","train files (13): ['ct_train_1001_image', 'ct_train_1002_image', 'ct_train_1003_image', 'ct_train_1004_image', 'ct_train_1005_image', 'ct_train_1006_image', 'ct_train_1007_image', 'ct_train_1008_image', 'ct_train_1009_image', 'ct_train_1010_image', 'ct_train_1011_image', 'ct_train_1012_image', 'ct_train_1013_image']\n","val files (3): ['ct_train_1014_image', 'ct_train_1015_image', 'ct_train_1016_image']\n","test files (4): ['ct_train_1017_image', 'ct_train_1018_image', 'ct_train_1019_image', 'ct_train_1020_image']\n","save json to /content/drive/MyDrive/CardiacSeg/dataset/MM_WHS_2017/dataset.json\n"]}]},{"cell_type":"markdown","source":["## Pretrain"],"metadata":{"id":"th4_0JZYLCfy"}},{"cell_type":"code","source":["!python main.py\\\n","--use_checkpoint \\\n","--batch_size=1 \\\n","--num_steps=100000 \\\n","--lrdecay \\\n","--eval_num=100 \\\n","--logdir='exp_0'\n","# --lr=<Lr> \n","# --roi_x=<Roi_x> \\\n","# --roi_y=<Roi_y> \\\n","# --roi_z=<Roi_z> \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZvqEQoDLKbx","outputId":"a3241108-22c4-4cdb-ac7f-855cb41913db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with a single process on 1 GPUs.\n","load json from /content/drive/MyDrive/CardiacSeg/dataset/SegTHOR/dataset.json\n","load json from /content/drive/MyDrive/CardiacSeg/dataset/MM_WHS_2017/dataset.json\n","load json from /content/drive/MyDrive/CardiacSeg/dataset/SegTHOR/dataset.json\n","load json from /content/drive/MyDrive/CardiacSeg/dataset/MM_WHS_2017/dataset.json\n","Dataset 1 SegTHOR: number of tr data: 26\n","Dataset 2 MMWHS: number of tr data: 13\n","Dataset 1 SegTHOR: number of val data: 6\n","Dataset 2 MMWHS: number of val data: 3\n","Dataset all training: number of data: 39\n","Dataset all validation: number of data: 9\n","/usr/local/lib/python3.7/dist-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n","  warn_deprecated(obj, msg, warning_category)\n","Using generic dataset\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Step:0/100000, Loss:2.9511, Time:13.3065\n","Step:1/100000, Loss:2.2932, Time:2.4642\n","Step:2/100000, Loss:2.6227, Time:3.0532\n","Step:3/100000, Loss:2.8405, Time:3.0359\n","Step:4/100000, Loss:2.6441, Time:3.3461\n","Step:5/100000, Loss:2.8806, Time:4.2637\n","Step:6/100000, Loss:2.7178, Time:3.2085\n","Step:7/100000, Loss:2.7034, Time:2.9539\n","Step:8/100000, Loss:2.7029, Time:3.2998\n","Step:9/100000, Loss:2.8747, Time:3.2001\n","Step:10/100000, Loss:2.9568, Time:3.3954\n","Step:11/100000, Loss:2.8135, Time:2.7260\n","Step:12/100000, Loss:3.0414, Time:3.3143\n","Step:13/100000, Loss:3.4593, Time:3.6035\n","Step:14/100000, Loss:2.6728, Time:2.9720\n","Step:15/100000, Loss:2.5228, Time:3.9124\n","Step:16/100000, Loss:2.4998, Time:2.8206\n","Step:17/100000, Loss:2.3206, Time:4.0805\n","Step:18/100000, Loss:3.0621, Time:2.7115\n","Step:19/100000, Loss:2.6081, Time:3.5606\n","Step:20/100000, Loss:2.3100, Time:2.7210\n","Step:21/100000, Loss:2.3113, Time:3.3357\n","Step:22/100000, Loss:2.1636, Time:3.2077\n","Step:23/100000, Loss:4.3552, Time:3.5883\n","Step:24/100000, Loss:2.9823, Time:3.5445\n","Step:25/100000, Loss:1.6016, Time:3.4409\n","Step:26/100000, Loss:2.6521, Time:3.0647\n","Step:27/100000, Loss:2.7075, Time:3.0825\n","Step:28/100000, Loss:2.4609, Time:3.6893\n","Step:29/100000, Loss:3.9126, Time:3.1384\n","Step:30/100000, Loss:2.9184, Time:3.7871\n","Step:31/100000, Loss:3.6479, Time:3.4890\n","Step:32/100000, Loss:2.4424, Time:3.1841\n","Step:33/100000, Loss:2.8940, Time:3.6813\n","Step:34/100000, Loss:2.2970, Time:3.6589\n","Step:35/100000, Loss:2.5021, Time:3.6050\n","Step:36/100000, Loss:3.2440, Time:2.9574\n","Step:37/100000, Loss:3.3908, Time:2.5048\n","Step:38/100000, Loss:2.7294, Time:2.4585\n","Step:39/100000, Loss:3.2409, Time:4.0531\n","Step:40/100000, Loss:1.9444, Time:3.6215\n","Step:41/100000, Loss:2.6693, Time:3.6254\n","Step:42/100000, Loss:3.7543, Time:3.3694\n","Step:43/100000, Loss:3.2807, Time:2.9097\n","Step:44/100000, Loss:2.7167, Time:2.8088\n","Step:45/100000, Loss:3.2301, Time:2.7376\n","Step:46/100000, Loss:2.8007, Time:2.8119\n","Step:47/100000, Loss:2.2424, Time:2.8233\n","Step:48/100000, Loss:2.7110, Time:2.9308\n","Step:49/100000, Loss:2.3577, Time:2.7414\n","Step:50/100000, Loss:2.0687, Time:2.8198\n","Step:51/100000, Loss:2.9879, Time:2.8496\n","Step:52/100000, Loss:2.0139, Time:2.8441\n","Step:53/100000, Loss:3.4908, Time:2.9079\n","Step:54/100000, Loss:3.1282, Time:2.9544\n","Step:55/100000, Loss:4.8824, Time:3.0764\n","Step:56/100000, Loss:2.5448, Time:3.0252\n","Step:57/100000, Loss:3.2657, Time:2.7885\n","Step:58/100000, Loss:2.8271, Time:2.7860\n","Step:59/100000, Loss:3.3852, Time:2.8435\n","Step:60/100000, Loss:2.9782, Time:2.7199\n","Step:61/100000, Loss:2.2541, Time:3.0373\n","Step:62/100000, Loss:2.8269, Time:4.3313\n","Step:63/100000, Loss:2.5165, Time:3.1744\n","Step:64/100000, Loss:2.2988, Time:3.8402\n","Step:65/100000, Loss:2.8940, Time:4.2780\n","Step:66/100000, Loss:2.7829, Time:2.8919\n","Step:67/100000, Loss:3.3941, Time:2.9388\n","Step:68/100000, Loss:2.8344, Time:3.1346\n","Step:69/100000, Loss:2.8689, Time:3.1091\n","Step:70/100000, Loss:4.2892, Time:3.5357\n","Step:71/100000, Loss:3.1566, Time:3.6389\n","Step:72/100000, Loss:3.1871, Time:3.3645\n","Step:73/100000, Loss:2.5829, Time:2.9878\n","Step:74/100000, Loss:1.6212, Time:2.4781\n","Step:75/100000, Loss:3.2107, Time:2.3899\n","Step:76/100000, Loss:3.4361, Time:2.4130\n","Step:77/100000, Loss:3.0908, Time:2.3811\n","Step:78/100000, Loss:1.4422, Time:4.0475\n","Step:79/100000, Loss:1.8747, Time:3.6341\n","Step:80/100000, Loss:1.5306, Time:3.4977\n","Step:81/100000, Loss:2.8844, Time:3.9409\n","Step:82/100000, Loss:2.5957, Time:2.7596\n","Step:83/100000, Loss:2.2634, Time:2.7938\n","Step:84/100000, Loss:2.2963, Time:2.7594\n","Step:85/100000, Loss:2.2741, Time:2.8288\n","Step:86/100000, Loss:2.2507, Time:2.8856\n","Step:87/100000, Loss:3.1452, Time:2.9361\n","Step:88/100000, Loss:2.0452, Time:2.7059\n","Step:89/100000, Loss:2.3825, Time:2.8415\n","Step:90/100000, Loss:3.3300, Time:2.8410\n","Step:91/100000, Loss:2.2795, Time:2.7960\n","Step:92/100000, Loss:3.0462, Time:2.8337\n","Step:93/100000, Loss:2.3084, Time:2.8088\n","Step:94/100000, Loss:2.5572, Time:2.9967\n","Step:95/100000, Loss:1.6860, Time:2.7947\n","Step:96/100000, Loss:1.4414, Time:2.8167\n","Step:97/100000, Loss:2.7206, Time:2.7921\n","Step:98/100000, Loss:3.2440, Time:2.7476\n","Step:99/100000, Loss:2.5145, Time:2.8287\n","/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","Validation step:0, Loss:1.8219, Loss Reconstruction:0.1450\n","Validation step:1, Loss:3.0174, Loss Reconstruction:0.1783\n","Validation step:2, Loss:2.8734, Loss Reconstruction:0.1470\n","Validation step:3, Loss:1.8205, Loss Reconstruction:0.1280\n","Validation step:4, Loss:2.1536, Loss Reconstruction:0.1200\n","Validation step:5, Loss:1.4684, Loss Reconstruction:0.1477\n","Validation step:6, Loss:3.1174, Loss Reconstruction:0.1294\n","Validation step:7, Loss:3.2697, Loss Reconstruction:0.1179\n","Validation step:8, Loss:1.7889, Loss Reconstruction:0.1500\n","Model was saved ! Best Recon. Val Loss: 0.1404, Recon. Val Loss: 0.1404\n","Step:100/100000, Loss:3.8635, Time:2.7148\n","Step:101/100000, Loss:3.5083, Time:4.5177\n","Step:102/100000, Loss:3.2678, Time:3.9452\n","Step:103/100000, Loss:1.3090, Time:3.8460\n","Step:104/100000, Loss:3.2614, Time:2.9793\n","Step:105/100000, Loss:2.4046, Time:2.8705\n","Step:106/100000, Loss:2.9720, Time:3.1494\n","Step:107/100000, Loss:2.3912, Time:3.2177\n","Step:108/100000, Loss:3.1482, Time:3.2578\n","Step:109/100000, Loss:2.6133, Time:3.7465\n","Step:110/100000, Loss:2.0043, Time:3.5070\n","Step:111/100000, Loss:2.4208, Time:2.9991\n","Step:112/100000, Loss:2.2700, Time:2.8275\n","Step:113/100000, Loss:1.6969, Time:2.4552\n","Step:114/100000, Loss:2.6734, Time:2.4061\n","Step:115/100000, Loss:2.9733, Time:2.4013\n","Step:116/100000, Loss:2.0292, Time:2.4974\n","Step:117/100000, Loss:3.4318, Time:4.0618\n","Step:118/100000, Loss:1.9102, Time:3.8760\n","Step:119/100000, Loss:2.9416, Time:3.6511\n","Step:120/100000, Loss:2.0574, Time:3.3385\n","Step:121/100000, Loss:2.3734, Time:2.8526\n","Step:122/100000, Loss:2.8374, Time:2.7055\n","Step:123/100000, Loss:2.8318, Time:2.8498\n","Step:124/100000, Loss:1.5608, Time:2.7253\n","Step:125/100000, Loss:2.5953, Time:2.8963\n","Step:126/100000, Loss:2.3456, Time:2.6853\n","Step:127/100000, Loss:2.5762, Time:2.7612\n","Step:128/100000, Loss:2.9689, Time:2.7269\n","Step:129/100000, Loss:2.0573, Time:2.8030\n","Step:130/100000, Loss:2.9430, Time:2.7706\n","Step:131/100000, Loss:2.9024, Time:2.9976\n","Step:132/100000, Loss:1.1580, Time:2.7683\n","Step:133/100000, Loss:2.7876, Time:3.1119\n","Step:134/100000, Loss:2.6121, Time:2.8335\n","Step:135/100000, Loss:2.0775, Time:2.8303\n","Step:136/100000, Loss:2.2951, Time:2.7609\n","Step:137/100000, Loss:1.8775, Time:2.8276\n","Step:138/100000, Loss:2.5173, Time:2.8351\n","Step:139/100000, Loss:2.2984, Time:2.9493\n","Step:140/100000, Loss:1.2087, Time:4.2125\n","Step:141/100000, Loss:2.1498, Time:2.8749\n","Step:142/100000, Loss:2.8534, Time:3.4575\n","Step:143/100000, Loss:2.4401, Time:3.3197\n","Step:144/100000, Loss:1.7069, Time:2.7401\n","Step:145/100000, Loss:1.4479, Time:3.3847\n","Step:146/100000, Loss:2.1874, Time:2.9673\n","Step:147/100000, Loss:2.3012, Time:2.9746\n","Step:148/100000, Loss:3.0676, Time:3.8114\n","Step:149/100000, Loss:2.8243, Time:3.1728\n","Step:150/100000, Loss:1.3112, Time:3.1202\n","Step:151/100000, Loss:3.7908, Time:2.7914\n","Step:152/100000, Loss:2.7065, Time:2.5314\n","Step:153/100000, Loss:3.3021, Time:2.4101\n","Step:154/100000, Loss:2.6719, Time:2.4181\n","Step:155/100000, Loss:1.7227, Time:2.4620\n","Step:156/100000, Loss:3.1270, Time:4.0622\n","Step:157/100000, Loss:2.1086, Time:3.6754\n","Step:158/100000, Loss:1.5677, Time:3.6978\n","Step:159/100000, Loss:1.6376, Time:3.4602\n","Step:160/100000, Loss:2.4269, Time:2.9256\n","Step:161/100000, Loss:2.0179, Time:2.7974\n","Step:162/100000, Loss:3.1415, Time:2.8460\n","Step:163/100000, Loss:1.9487, Time:2.7414\n","Step:164/100000, Loss:1.6883, Time:2.8513\n","Step:165/100000, Loss:1.5588, Time:2.7433\n","Step:166/100000, Loss:3.2378, Time:2.7730\n","Step:167/100000, Loss:2.4691, Time:2.7510\n","Step:168/100000, Loss:2.7829, Time:2.8411\n","Step:169/100000, Loss:3.3383, Time:2.7316\n","Step:170/100000, Loss:1.5816, Time:2.9565\n","Step:171/100000, Loss:1.9181, Time:2.8061\n","Step:172/100000, Loss:2.8463, Time:3.0259\n","Step:173/100000, Loss:2.8224, Time:2.7497\n","Step:174/100000, Loss:2.5652, Time:2.9372\n","Step:175/100000, Loss:3.3881, Time:2.8683\n","Step:176/100000, Loss:2.5719, Time:2.7519\n","Step:177/100000, Loss:1.7526, Time:2.8302\n","Step:178/100000, Loss:2.4189, Time:2.9584\n","Step:179/100000, Loss:1.5285, Time:4.8336\n","Step:180/100000, Loss:2.1612, Time:3.4375\n","Step:181/100000, Loss:2.9457, Time:3.6998\n","Step:182/100000, Loss:2.6966, Time:3.0310\n","Step:183/100000, Loss:2.5200, Time:2.9858\n","Step:184/100000, Loss:2.9039, Time:3.0625\n","Step:185/100000, Loss:1.8511, Time:2.9945\n","Step:186/100000, Loss:2.9100, Time:3.0566\n","Step:187/100000, Loss:3.2797, Time:3.6092\n","Step:188/100000, Loss:3.4949, Time:3.1421\n","Step:189/100000, Loss:3.8459, Time:2.9844\n","Step:190/100000, Loss:1.7751, Time:2.8471\n","Step:191/100000, Loss:1.6129, Time:2.4540\n","Step:192/100000, Loss:1.5452, Time:2.4112\n","Step:193/100000, Loss:2.1973, Time:2.4171\n","Step:194/100000, Loss:2.5108, Time:2.4130\n","Step:195/100000, Loss:1.4575, Time:3.5104\n","Step:196/100000, Loss:3.1592, Time:3.8477\n","Step:197/100000, Loss:2.2742, Time:3.8332\n","Step:198/100000, Loss:1.8872, Time:3.4281\n","Step:199/100000, Loss:2.8375, Time:3.3585\n","Validation step:0, Loss:1.7379, Loss Reconstruction:0.0948\n","Validation step:1, Loss:2.4233, Loss Reconstruction:0.1242\n","Validation step:2, Loss:1.1080, Loss Reconstruction:0.0915\n","Validation step:3, Loss:2.8460, Loss Reconstruction:0.0640\n","Validation step:4, Loss:2.9220, Loss Reconstruction:0.1260\n","Validation step:5, Loss:1.4197, Loss Reconstruction:0.1241\n","Validation step:6, Loss:2.8832, Loss Reconstruction:0.1799\n","Validation step:7, Loss:2.5200, Loss Reconstruction:0.2264\n","Validation step:8, Loss:2.7134, Loss Reconstruction:0.2586\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.1433\n","Step:200/100000, Loss:2.5832, Time:2.7297\n","Step:201/100000, Loss:2.6918, Time:3.0237\n","Step:202/100000, Loss:2.5005, Time:2.9948\n","Step:203/100000, Loss:1.6843, Time:2.9343\n","Step:204/100000, Loss:2.5029, Time:2.9883\n","Step:205/100000, Loss:3.1091, Time:2.7245\n","Step:206/100000, Loss:3.1758, Time:2.6922\n","Step:207/100000, Loss:2.7157, Time:2.9253\n","Step:208/100000, Loss:2.2046, Time:2.8215\n","Step:209/100000, Loss:1.7513, Time:2.9594\n","Step:210/100000, Loss:2.9986, Time:3.0551\n","Step:211/100000, Loss:2.8815, Time:3.0864\n","Step:212/100000, Loss:1.5813, Time:2.7568\n","Step:213/100000, Loss:1.6372, Time:2.9123\n","Step:214/100000, Loss:2.6771, Time:2.7740\n","Step:215/100000, Loss:1.3397, Time:2.9154\n","Step:216/100000, Loss:2.6045, Time:2.7492\n","Step:217/100000, Loss:2.7265, Time:3.1453\n","Step:218/100000, Loss:3.0095, Time:3.5962\n","Step:219/100000, Loss:2.0639, Time:3.4892\n","Step:220/100000, Loss:3.2809, Time:3.9266\n","Step:221/100000, Loss:2.8046, Time:2.8037\n","Step:222/100000, Loss:2.3765, Time:2.9978\n","Step:223/100000, Loss:2.0350, Time:3.1111\n","Step:224/100000, Loss:2.0365, Time:3.2879\n","Step:225/100000, Loss:3.3311, Time:2.9966\n","Step:226/100000, Loss:3.1529, Time:3.6529\n","Step:227/100000, Loss:2.4092, Time:3.5906\n","Step:228/100000, Loss:2.2120, Time:3.1303\n","Step:229/100000, Loss:1.9949, Time:2.8902\n","Step:230/100000, Loss:2.9026, Time:2.5894\n","Step:231/100000, Loss:2.8471, Time:2.3766\n","Step:232/100000, Loss:2.7883, Time:2.3818\n","Step:233/100000, Loss:1.5578, Time:2.4473\n","Step:234/100000, Loss:1.6519, Time:3.8463\n","Step:235/100000, Loss:2.6084, Time:3.5081\n","Step:236/100000, Loss:2.4590, Time:3.4760\n","Step:237/100000, Loss:2.9431, Time:3.6280\n","Step:238/100000, Loss:2.8509, Time:3.3371\n","Step:239/100000, Loss:2.8129, Time:2.7282\n","Step:240/100000, Loss:2.2001, Time:2.8589\n","Step:241/100000, Loss:2.6121, Time:2.8461\n","Step:242/100000, Loss:2.3118, Time:2.8315\n","Step:243/100000, Loss:2.8047, Time:2.9031\n","Step:244/100000, Loss:2.3843, Time:2.7675\n","Step:245/100000, Loss:2.8255, Time:2.7733\n","Step:246/100000, Loss:3.1050, Time:2.7964\n","Step:247/100000, Loss:3.2453, Time:2.7427\n","Step:248/100000, Loss:3.4053, Time:2.9571\n","Step:249/100000, Loss:2.5798, Time:2.8283\n","Step:250/100000, Loss:2.7622, Time:2.9972\n","Step:251/100000, Loss:2.5001, Time:2.7674\n","Step:252/100000, Loss:2.9884, Time:2.9063\n","Step:253/100000, Loss:3.6274, Time:2.7638\n","Step:254/100000, Loss:3.1239, Time:2.7394\n","Step:255/100000, Loss:2.8886, Time:2.7795\n","Step:256/100000, Loss:2.4691, Time:3.0128\n","Step:257/100000, Loss:2.6878, Time:3.7884\n","Step:258/100000, Loss:2.8716, Time:3.3263\n","Step:259/100000, Loss:2.5016, Time:3.9381\n","Step:260/100000, Loss:3.0972, Time:2.9381\n","Step:261/100000, Loss:2.7959, Time:2.7947\n","Step:262/100000, Loss:2.7812, Time:3.0707\n","Step:263/100000, Loss:2.7625, Time:3.1312\n","Step:264/100000, Loss:2.7172, Time:3.0463\n","Step:265/100000, Loss:2.8683, Time:3.2487\n","Step:266/100000, Loss:2.7155, Time:3.7202\n","Step:267/100000, Loss:2.9041, Time:3.0882\n","Step:268/100000, Loss:3.0626, Time:2.7592\n","Step:269/100000, Loss:3.1117, Time:2.4592\n","Step:270/100000, Loss:2.6541, Time:2.4021\n","Step:271/100000, Loss:2.6841, Time:2.4053\n","Step:272/100000, Loss:3.0287, Time:2.4175\n","Step:273/100000, Loss:2.7659, Time:3.9198\n","Step:274/100000, Loss:2.8263, Time:3.9065\n","Step:275/100000, Loss:2.8251, Time:3.7864\n","Step:276/100000, Loss:3.1717, Time:3.2981\n","Step:277/100000, Loss:2.6454, Time:2.9180\n","Step:278/100000, Loss:2.9054, Time:2.8180\n","Step:279/100000, Loss:2.6682, Time:2.7360\n","Step:280/100000, Loss:2.7239, Time:2.7826\n","Step:281/100000, Loss:2.7694, Time:2.6891\n","Step:282/100000, Loss:2.8319, Time:2.9300\n","Step:283/100000, Loss:2.7884, Time:2.6908\n","Step:284/100000, Loss:2.7692, Time:2.7666\n","Step:285/100000, Loss:2.6830, Time:3.0081\n","Step:286/100000, Loss:2.4782, Time:2.7949\n","Step:287/100000, Loss:3.1065, Time:2.9693\n","Step:288/100000, Loss:2.5107, Time:2.8853\n","Step:289/100000, Loss:3.0067, Time:2.8262\n","Step:290/100000, Loss:2.6468, Time:2.7623\n","Step:291/100000, Loss:2.5026, Time:2.8639\n","Step:292/100000, Loss:2.2949, Time:2.7067\n","Step:293/100000, Loss:2.6411, Time:2.8296\n","Step:294/100000, Loss:3.9270, Time:2.7637\n","Step:295/100000, Loss:3.0425, Time:2.9938\n","Step:296/100000, Loss:3.3542, Time:4.3574\n","Step:297/100000, Loss:3.3175, Time:3.7725\n","Step:298/100000, Loss:2.9847, Time:3.9041\n","Step:299/100000, Loss:2.8605, Time:3.0483\n","Validation step:0, Loss:2.8634, Loss Reconstruction:0.2099\n","Validation step:1, Loss:2.4658, Loss Reconstruction:0.2696\n","Validation step:2, Loss:2.6438, Loss Reconstruction:0.0366\n","Validation step:3, Loss:2.7992, Loss Reconstruction:0.2289\n","Validation step:4, Loss:2.7272, Loss Reconstruction:0.1741\n","Validation step:5, Loss:2.8683, Loss Reconstruction:0.2618\n","Validation step:6, Loss:2.7626, Loss Reconstruction:0.2911\n","Validation step:7, Loss:2.4851, Loss Reconstruction:0.0379\n","Validation step:8, Loss:2.9261, Loss Reconstruction:0.4116\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2135\n","Step:300/100000, Loss:2.6276, Time:2.7976\n","Step:301/100000, Loss:2.9376, Time:3.2647\n","Step:302/100000, Loss:2.6071, Time:3.6368\n","Step:303/100000, Loss:3.3431, Time:2.9283\n","Step:304/100000, Loss:2.7374, Time:3.9102\n","Step:305/100000, Loss:2.8251, Time:3.3011\n","Step:306/100000, Loss:3.0425, Time:3.1370\n","Step:307/100000, Loss:2.9964, Time:2.8360\n","Step:308/100000, Loss:3.4429, Time:2.4975\n","Step:309/100000, Loss:2.4547, Time:2.4303\n","Step:310/100000, Loss:2.7452, Time:2.4396\n","Step:311/100000, Loss:2.8037, Time:2.4287\n","Step:312/100000, Loss:2.7644, Time:3.8416\n","Step:313/100000, Loss:2.3909, Time:3.5209\n","Step:314/100000, Loss:2.9207, Time:3.9424\n","Step:315/100000, Loss:2.7601, Time:3.4909\n","Step:316/100000, Loss:2.2044, Time:2.9638\n","Step:317/100000, Loss:2.9722, Time:2.7846\n","Step:318/100000, Loss:2.8832, Time:2.8812\n","Step:319/100000, Loss:2.7727, Time:2.7666\n","Step:320/100000, Loss:3.2411, Time:2.8248\n","Step:321/100000, Loss:3.0341, Time:3.0312\n","Step:322/100000, Loss:2.8839, Time:2.7132\n","Step:323/100000, Loss:2.5688, Time:2.7929\n","Step:324/100000, Loss:2.3769, Time:2.9581\n","Step:325/100000, Loss:2.9442, Time:2.7617\n","Step:326/100000, Loss:3.2067, Time:2.8597\n","Step:327/100000, Loss:2.6153, Time:2.8666\n","Step:328/100000, Loss:2.2430, Time:3.1258\n","Step:329/100000, Loss:3.0755, Time:2.7635\n","Step:330/100000, Loss:3.5266, Time:2.9875\n","Step:331/100000, Loss:2.8353, Time:2.7211\n","Step:332/100000, Loss:2.8960, Time:2.8635\n","Step:333/100000, Loss:2.9503, Time:2.7511\n","Step:334/100000, Loss:2.3916, Time:2.9915\n","Step:335/100000, Loss:2.4740, Time:3.9688\n","Step:336/100000, Loss:2.6068, Time:3.3698\n","Step:337/100000, Loss:2.5770, Time:3.5278\n","Step:338/100000, Loss:2.6675, Time:3.1556\n","Step:339/100000, Loss:2.7590, Time:2.7102\n","Step:340/100000, Loss:3.0067, Time:3.0251\n","Step:341/100000, Loss:2.9210, Time:3.1329\n","Step:342/100000, Loss:2.6749, Time:2.9012\n","Step:343/100000, Loss:2.7369, Time:3.5137\n","Step:344/100000, Loss:2.8202, Time:3.3888\n","Step:345/100000, Loss:2.5979, Time:2.9844\n","Step:346/100000, Loss:2.7315, Time:2.7338\n","Step:347/100000, Loss:2.5768, Time:2.4346\n","Step:348/100000, Loss:2.9734, Time:2.4216\n","Step:349/100000, Loss:2.8985, Time:2.4504\n","Step:350/100000, Loss:2.4650, Time:2.4121\n","Step:351/100000, Loss:2.5435, Time:4.9125\n","Step:352/100000, Loss:2.2981, Time:3.5903\n","Step:353/100000, Loss:2.9956, Time:3.8191\n","Step:354/100000, Loss:2.5868, Time:3.5082\n","Step:355/100000, Loss:2.7840, Time:3.2615\n","Step:356/100000, Loss:2.6708, Time:2.7154\n","Step:357/100000, Loss:2.8967, Time:2.7416\n","Step:358/100000, Loss:2.6676, Time:2.7857\n","Step:359/100000, Loss:2.6879, Time:2.7938\n","Step:360/100000, Loss:2.6590, Time:2.8735\n","Step:361/100000, Loss:2.6120, Time:2.7576\n","Step:362/100000, Loss:2.6765, Time:2.7907\n","Step:363/100000, Loss:2.5796, Time:2.8271\n","Step:364/100000, Loss:2.4864, Time:2.7862\n","Step:365/100000, Loss:2.9875, Time:2.8590\n","Step:366/100000, Loss:2.4524, Time:3.0107\n","Step:367/100000, Loss:2.6905, Time:2.9628\n","Step:368/100000, Loss:2.9376, Time:2.7438\n","Step:369/100000, Loss:2.3387, Time:2.7251\n","Step:370/100000, Loss:2.5573, Time:2.7612\n","Step:371/100000, Loss:2.5880, Time:2.7916\n","Step:372/100000, Loss:2.8288, Time:2.7352\n","Step:373/100000, Loss:2.8797, Time:2.9508\n","Step:374/100000, Loss:2.6428, Time:3.8332\n","Step:375/100000, Loss:2.2077, Time:3.0265\n","Step:376/100000, Loss:2.2894, Time:3.8277\n","Step:377/100000, Loss:2.2484, Time:2.9948\n","Step:378/100000, Loss:3.2327, Time:2.7659\n","Step:379/100000, Loss:2.5532, Time:2.9191\n","Step:380/100000, Loss:3.1758, Time:3.3958\n","Step:381/100000, Loss:2.7916, Time:2.8824\n","Step:382/100000, Loss:4.1741, Time:3.5414\n","Step:383/100000, Loss:3.1784, Time:3.3154\n","Step:384/100000, Loss:3.0751, Time:3.2340\n","Step:385/100000, Loss:2.9698, Time:2.7992\n","Step:386/100000, Loss:3.1775, Time:2.4746\n","Step:387/100000, Loss:2.6322, Time:2.4110\n","Step:388/100000, Loss:2.8472, Time:2.4120\n","Step:389/100000, Loss:2.6533, Time:2.3907\n","Step:390/100000, Loss:2.3858, Time:3.3045\n","Step:391/100000, Loss:2.5103, Time:3.5965\n","Step:392/100000, Loss:2.7534, Time:3.6860\n","Step:393/100000, Loss:2.7421, Time:3.7335\n","Step:394/100000, Loss:3.1748, Time:3.1846\n","Step:395/100000, Loss:2.8080, Time:2.7530\n","Step:396/100000, Loss:3.1354, Time:2.8527\n","Step:397/100000, Loss:2.6093, Time:2.7810\n","Step:398/100000, Loss:2.6325, Time:2.8001\n","Step:399/100000, Loss:2.5925, Time:2.8364\n","Validation step:0, Loss:2.3814, Loss Reconstruction:0.1201\n","Validation step:1, Loss:2.8724, Loss Reconstruction:0.2909\n","Validation step:2, Loss:2.8032, Loss Reconstruction:0.2234\n","Validation step:3, Loss:2.9055, Loss Reconstruction:0.1856\n","Validation step:4, Loss:2.6167, Loss Reconstruction:0.1161\n","Validation step:5, Loss:2.3461, Loss Reconstruction:0.1634\n","Validation step:6, Loss:2.6753, Loss Reconstruction:0.1141\n","Validation step:7, Loss:2.7059, Loss Reconstruction:0.2275\n","Validation step:8, Loss:2.7841, Loss Reconstruction:0.1737\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.1794\n","Step:400/100000, Loss:2.9427, Time:2.7176\n","Step:401/100000, Loss:2.6309, Time:2.7482\n","Step:402/100000, Loss:2.7545, Time:2.8635\n","Step:403/100000, Loss:2.7196, Time:2.7942\n","Step:404/100000, Loss:2.6616, Time:2.8924\n","Step:405/100000, Loss:2.6931, Time:2.9485\n","Step:406/100000, Loss:2.7689, Time:3.0953\n","Step:407/100000, Loss:2.6104, Time:3.3161\n","Step:408/100000, Loss:2.5400, Time:3.9785\n","Step:409/100000, Loss:2.6548, Time:2.6952\n","Step:410/100000, Loss:2.7350, Time:2.7549\n","Step:411/100000, Loss:2.6104, Time:2.8036\n","Step:412/100000, Loss:2.5135, Time:3.0181\n","Step:413/100000, Loss:2.7495, Time:3.6872\n","Step:414/100000, Loss:3.0413, Time:3.1327\n","Step:415/100000, Loss:2.8605, Time:3.8710\n","Step:416/100000, Loss:2.6460, Time:3.0441\n","Step:417/100000, Loss:2.9117, Time:2.8074\n","Step:418/100000, Loss:2.7670, Time:3.1203\n","Step:419/100000, Loss:2.7628, Time:3.2630\n","Step:420/100000, Loss:2.7225, Time:2.9357\n","Step:421/100000, Loss:2.7819, Time:3.4985\n","Step:422/100000, Loss:2.3547, Time:3.5730\n","Step:423/100000, Loss:3.0271, Time:3.0229\n","Step:424/100000, Loss:2.9645, Time:2.7872\n","Step:425/100000, Loss:2.8246, Time:2.4747\n","Step:426/100000, Loss:2.9150, Time:2.3945\n","Step:427/100000, Loss:2.9598, Time:2.3936\n","Step:428/100000, Loss:2.8403, Time:2.4400\n","Step:429/100000, Loss:2.8441, Time:3.6018\n","Step:430/100000, Loss:3.1044, Time:3.5222\n","Step:431/100000, Loss:2.5619, Time:3.9938\n","Step:432/100000, Loss:2.4946, Time:3.5718\n","Step:433/100000, Loss:2.6299, Time:3.3211\n","Step:434/100000, Loss:2.3091, Time:2.7351\n","Step:435/100000, Loss:2.9482, Time:2.8226\n","Step:436/100000, Loss:2.9260, Time:2.7228\n","Step:437/100000, Loss:2.8645, Time:2.8619\n","Step:438/100000, Loss:2.7462, Time:2.9217\n","Step:439/100000, Loss:2.8009, Time:2.8345\n","Step:440/100000, Loss:2.6560, Time:2.8007\n","Step:441/100000, Loss:2.6855, Time:2.8697\n","Step:442/100000, Loss:2.5709, Time:2.6859\n","Step:443/100000, Loss:2.7970, Time:3.0107\n","Step:444/100000, Loss:2.5219, Time:2.8358\n","Step:445/100000, Loss:2.4437, Time:3.1419\n","Step:446/100000, Loss:2.6032, Time:2.7235\n","Step:447/100000, Loss:2.8503, Time:2.9591\n","Step:448/100000, Loss:2.7303, Time:2.7435\n","Step:449/100000, Loss:2.7475, Time:2.7868\n","Step:450/100000, Loss:2.8776, Time:2.7515\n","Step:451/100000, Loss:2.7069, Time:2.9717\n","Step:452/100000, Loss:2.6588, Time:3.9501\n","Step:453/100000, Loss:2.4791, Time:3.1428\n","Step:454/100000, Loss:2.4746, Time:3.5178\n","Step:455/100000, Loss:3.0880, Time:3.2279\n","Step:456/100000, Loss:2.9276, Time:2.7463\n","Step:457/100000, Loss:3.4921, Time:3.2739\n","Step:458/100000, Loss:3.0189, Time:2.9813\n","Step:459/100000, Loss:2.8344, Time:2.9628\n","Step:460/100000, Loss:2.6941, Time:3.5713\n","Step:461/100000, Loss:2.7163, Time:3.2848\n","Step:462/100000, Loss:2.9124, Time:3.2332\n","Step:463/100000, Loss:3.0133, Time:2.7852\n","Step:464/100000, Loss:3.0626, Time:2.4643\n","Step:465/100000, Loss:2.7605, Time:2.4028\n","Step:466/100000, Loss:2.6303, Time:2.3999\n","Step:467/100000, Loss:2.3677, Time:2.4021\n","Step:468/100000, Loss:2.7095, Time:3.4967\n","Step:469/100000, Loss:2.8265, Time:4.6337\n","Step:470/100000, Loss:3.0586, Time:4.3618\n","Step:471/100000, Loss:2.7382, Time:3.5555\n","Step:472/100000, Loss:2.6530, Time:3.2947\n","Step:473/100000, Loss:2.7161, Time:2.7820\n","Step:474/100000, Loss:2.4621, Time:2.7635\n","Step:475/100000, Loss:2.5224, Time:2.7739\n","Step:476/100000, Loss:2.4901, Time:2.9028\n","Step:477/100000, Loss:2.3406, Time:2.8174\n","Step:478/100000, Loss:2.6749, Time:2.8415\n","Step:479/100000, Loss:2.4748, Time:2.7149\n","Step:480/100000, Loss:3.0190, Time:2.8619\n","Step:481/100000, Loss:2.9960, Time:2.7294\n","Step:482/100000, Loss:2.6102, Time:2.9164\n","Step:483/100000, Loss:3.1303, Time:2.7704\n","Step:484/100000, Loss:2.7253, Time:3.0676\n","Step:485/100000, Loss:2.7391, Time:2.7849\n","Step:486/100000, Loss:3.1354, Time:2.9114\n","Step:487/100000, Loss:2.8906, Time:2.7140\n","Step:488/100000, Loss:2.6741, Time:2.8086\n","Step:489/100000, Loss:2.5671, Time:2.7564\n","Step:490/100000, Loss:2.7085, Time:2.8718\n","Step:491/100000, Loss:2.9713, Time:3.6441\n","Step:492/100000, Loss:2.8390, Time:3.0744\n","Step:493/100000, Loss:2.7564, Time:3.6400\n","Step:494/100000, Loss:2.9014, Time:3.1102\n","Step:495/100000, Loss:2.4742, Time:2.7582\n","Step:496/100000, Loss:2.7299, Time:3.2292\n","Step:497/100000, Loss:2.8732, Time:3.3292\n","Step:498/100000, Loss:2.7894, Time:2.9078\n","Step:499/100000, Loss:2.9063, Time:3.2563\n","Validation step:0, Loss:2.6661, Loss Reconstruction:0.0926\n","Validation step:1, Loss:2.8731, Loss Reconstruction:0.2445\n","Validation step:2, Loss:2.8422, Loss Reconstruction:0.1677\n","Validation step:3, Loss:2.6669, Loss Reconstruction:0.1516\n","Validation step:4, Loss:2.8783, Loss Reconstruction:0.1332\n","Validation step:5, Loss:2.5373, Loss Reconstruction:0.0910\n","Validation step:6, Loss:2.9725, Loss Reconstruction:0.3997\n","Validation step:7, Loss:2.9062, Loss Reconstruction:0.3206\n","Validation step:8, Loss:2.7989, Loss Reconstruction:0.2836\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2094\n","Step:500/100000, Loss:2.9391, Time:2.7998\n","Step:501/100000, Loss:2.6809, Time:3.4063\n","Step:502/100000, Loss:2.6839, Time:2.9309\n","Step:503/100000, Loss:2.7156, Time:2.5033\n","Step:504/100000, Loss:2.8910, Time:2.4555\n","Step:505/100000, Loss:2.5682, Time:2.4148\n","Step:506/100000, Loss:2.7949, Time:2.4234\n","Step:507/100000, Loss:2.9903, Time:3.7912\n","Step:508/100000, Loss:2.5653, Time:3.7097\n","Step:509/100000, Loss:2.5498, Time:3.6390\n","Step:510/100000, Loss:2.9484, Time:3.4919\n","Step:511/100000, Loss:2.6658, Time:3.0013\n","Step:512/100000, Loss:2.9222, Time:2.7049\n","Step:513/100000, Loss:2.7946, Time:2.8090\n","Step:514/100000, Loss:2.9330, Time:2.7235\n","Step:515/100000, Loss:2.9636, Time:2.8938\n","Step:516/100000, Loss:2.6619, Time:2.8336\n","Step:517/100000, Loss:2.7258, Time:2.7687\n","Step:518/100000, Loss:2.7858, Time:2.7014\n","Step:519/100000, Loss:2.5884, Time:2.9204\n","Step:520/100000, Loss:2.6658, Time:2.7494\n","Step:521/100000, Loss:2.7014, Time:2.9157\n","Step:522/100000, Loss:2.6778, Time:2.8135\n","Step:523/100000, Loss:2.6258, Time:3.2457\n","Step:524/100000, Loss:2.8528, Time:2.7713\n","Step:525/100000, Loss:2.3055, Time:3.3387\n","Step:526/100000, Loss:2.7519, Time:3.4979\n","Step:527/100000, Loss:2.8497, Time:2.9041\n","Step:528/100000, Loss:2.4112, Time:2.7326\n","Step:529/100000, Loss:2.6781, Time:3.0390\n","Step:530/100000, Loss:2.8867, Time:3.9829\n","Step:531/100000, Loss:2.9691, Time:3.1052\n","Step:532/100000, Loss:2.5730, Time:3.6032\n","Step:533/100000, Loss:2.8675, Time:3.0418\n","Step:534/100000, Loss:2.4932, Time:2.7420\n","Step:535/100000, Loss:2.7883, Time:3.0646\n","Step:536/100000, Loss:2.7282, Time:3.1268\n","Step:537/100000, Loss:2.8991, Time:3.0210\n","Step:538/100000, Loss:3.0474, Time:3.7142\n","Step:539/100000, Loss:2.8960, Time:3.1641\n","Step:540/100000, Loss:2.7624, Time:2.8980\n","Step:541/100000, Loss:2.8274, Time:2.8933\n","Step:542/100000, Loss:2.6552, Time:2.4732\n","Step:543/100000, Loss:2.8589, Time:2.4048\n","Step:544/100000, Loss:2.5307, Time:2.4172\n","Step:545/100000, Loss:2.9280, Time:2.3870\n","Step:546/100000, Loss:2.8250, Time:3.5758\n","Step:547/100000, Loss:2.6879, Time:3.5737\n","Step:548/100000, Loss:2.7242, Time:3.8709\n","Step:549/100000, Loss:2.7002, Time:3.6221\n","Step:550/100000, Loss:2.6669, Time:3.2891\n","Step:551/100000, Loss:2.4984, Time:2.7525\n","Step:552/100000, Loss:2.9188, Time:2.8412\n","Step:553/100000, Loss:2.5384, Time:2.7759\n","Step:554/100000, Loss:2.6002, Time:2.8787\n","Step:555/100000, Loss:2.5691, Time:2.7310\n","Step:556/100000, Loss:2.6547, Time:2.7595\n","Step:557/100000, Loss:2.5717, Time:2.7987\n","Step:558/100000, Loss:2.5343, Time:2.8539\n","Step:559/100000, Loss:2.5819, Time:2.8110\n","Step:560/100000, Loss:2.4100, Time:2.8496\n","Step:561/100000, Loss:2.9617, Time:2.8437\n","Step:562/100000, Loss:2.6174, Time:3.1257\n","Step:563/100000, Loss:2.6711, Time:2.7790\n","Step:564/100000, Loss:2.8907, Time:2.8268\n","Step:565/100000, Loss:2.8605, Time:2.7066\n","Step:566/100000, Loss:2.8305, Time:2.8221\n","Step:567/100000, Loss:2.4149, Time:2.6884\n","Step:568/100000, Loss:2.6266, Time:2.8507\n","Step:569/100000, Loss:2.7898, Time:3.7189\n","Step:570/100000, Loss:2.8969, Time:2.9463\n","Step:571/100000, Loss:2.6314, Time:3.7515\n","Step:572/100000, Loss:3.0596, Time:3.1119\n","Step:573/100000, Loss:2.7970, Time:2.8378\n","Step:574/100000, Loss:2.9342, Time:3.1067\n","Step:575/100000, Loss:2.7049, Time:2.9612\n","Step:576/100000, Loss:2.7805, Time:3.0664\n","Step:577/100000, Loss:2.6867, Time:3.6732\n","Step:578/100000, Loss:2.9765, Time:3.0963\n","Step:579/100000, Loss:2.9386, Time:3.0202\n","Step:580/100000, Loss:2.5109, Time:2.7124\n","Step:581/100000, Loss:2.6268, Time:2.4451\n","Step:582/100000, Loss:2.7405, Time:2.4192\n","Step:583/100000, Loss:2.5321, Time:2.4161\n","Step:584/100000, Loss:2.9575, Time:2.3806\n","Step:585/100000, Loss:2.6375, Time:3.7998\n","Step:586/100000, Loss:2.6523, Time:3.7300\n","Step:587/100000, Loss:2.7497, Time:3.6950\n","Step:588/100000, Loss:2.8263, Time:3.8422\n","Step:589/100000, Loss:3.1766, Time:3.9481\n","Step:590/100000, Loss:2.5246, Time:2.7423\n","Step:591/100000, Loss:2.6759, Time:2.7427\n","Step:592/100000, Loss:2.6224, Time:2.7835\n","Step:593/100000, Loss:2.6092, Time:2.8730\n","Step:594/100000, Loss:2.7238, Time:2.9407\n","Step:595/100000, Loss:2.7122, Time:2.8173\n","Step:596/100000, Loss:3.0177, Time:2.7593\n","Step:597/100000, Loss:2.7941, Time:2.7808\n","Step:598/100000, Loss:2.7700, Time:2.7145\n","Step:599/100000, Loss:2.7989, Time:2.8475\n","Validation step:0, Loss:2.5646, Loss Reconstruction:0.1184\n","Validation step:1, Loss:2.7691, Loss Reconstruction:0.2235\n","Validation step:2, Loss:2.7087, Loss Reconstruction:0.2241\n","Validation step:3, Loss:2.7245, Loss Reconstruction:0.2787\n","Validation step:4, Loss:2.6028, Loss Reconstruction:0.1018\n","Validation step:5, Loss:2.9793, Loss Reconstruction:0.3621\n","Validation step:6, Loss:2.9813, Loss Reconstruction:0.3039\n","Validation step:7, Loss:2.7488, Loss Reconstruction:0.2578\n","Validation step:8, Loss:2.8211, Loss Reconstruction:0.3206\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2434\n","Step:600/100000, Loss:2.8650, Time:2.7800\n","Step:601/100000, Loss:2.6669, Time:3.2685\n","Step:602/100000, Loss:2.4199, Time:2.8248\n","Step:603/100000, Loss:2.5395, Time:3.0719\n","Step:604/100000, Loss:2.7271, Time:2.7998\n","Step:605/100000, Loss:2.6723, Time:2.7236\n","Step:606/100000, Loss:3.0982, Time:2.7713\n","Step:607/100000, Loss:2.3524, Time:2.8988\n","Step:608/100000, Loss:3.3103, Time:3.4759\n","Step:609/100000, Loss:3.2129, Time:3.3805\n","Step:610/100000, Loss:2.7429, Time:3.8129\n","Step:611/100000, Loss:2.9375, Time:3.0438\n","Step:612/100000, Loss:2.8035, Time:2.9917\n","Step:613/100000, Loss:2.9479, Time:3.1917\n","Step:614/100000, Loss:2.7325, Time:3.0235\n","Step:615/100000, Loss:2.6419, Time:3.0124\n","Step:616/100000, Loss:2.8973, Time:3.5328\n","Step:617/100000, Loss:2.7880, Time:3.2103\n","Step:618/100000, Loss:2.9566, Time:3.0502\n","Step:619/100000, Loss:3.0711, Time:2.7745\n","Step:620/100000, Loss:3.0201, Time:2.5156\n","Step:621/100000, Loss:2.5988, Time:2.3869\n","Step:622/100000, Loss:2.4922, Time:2.3672\n","Step:623/100000, Loss:2.8269, Time:2.4283\n","Step:624/100000, Loss:2.8278, Time:3.7697\n","Step:625/100000, Loss:2.8241, Time:3.8555\n","Step:626/100000, Loss:2.5156, Time:3.6670\n","Step:627/100000, Loss:2.5983, Time:3.4721\n","Step:628/100000, Loss:2.8927, Time:2.8805\n","Step:629/100000, Loss:2.6565, Time:2.7349\n","Step:630/100000, Loss:2.6531, Time:2.8075\n","Step:631/100000, Loss:2.9988, Time:2.9422\n","Step:632/100000, Loss:2.6518, Time:2.7742\n","Step:633/100000, Loss:2.8054, Time:2.8292\n","Step:634/100000, Loss:2.7749, Time:2.7970\n","Step:635/100000, Loss:2.8368, Time:2.7108\n","Step:636/100000, Loss:2.8625, Time:2.8965\n","Step:637/100000, Loss:2.6733, Time:2.7934\n","Step:638/100000, Loss:2.6327, Time:2.9150\n","Step:639/100000, Loss:2.6825, Time:2.8582\n","Step:640/100000, Loss:2.6540, Time:3.1211\n","Step:641/100000, Loss:3.0655, Time:2.7933\n","Step:642/100000, Loss:2.5759, Time:2.9355\n","Step:643/100000, Loss:2.6660, Time:2.7922\n","Step:644/100000, Loss:2.7341, Time:2.8041\n","Step:645/100000, Loss:2.5861, Time:3.2039\n","Step:646/100000, Loss:2.5190, Time:3.9662\n","Step:647/100000, Loss:2.7095, Time:3.4974\n","Step:648/100000, Loss:2.8271, Time:3.3010\n","Step:649/100000, Loss:2.6113, Time:3.9603\n","Step:650/100000, Loss:3.1905, Time:2.9806\n","Step:651/100000, Loss:2.5882, Time:2.7384\n","Step:652/100000, Loss:2.7015, Time:3.0818\n","Step:653/100000, Loss:2.6373, Time:3.0358\n","Step:654/100000, Loss:2.5130, Time:2.9987\n","Step:655/100000, Loss:2.7631, Time:3.5244\n","Step:656/100000, Loss:3.0314, Time:3.1192\n","Step:657/100000, Loss:2.8079, Time:2.9819\n","Step:658/100000, Loss:2.6501, Time:2.6914\n","Step:659/100000, Loss:2.9700, Time:2.4304\n","Step:660/100000, Loss:2.8391, Time:2.4127\n","Step:661/100000, Loss:2.8407, Time:2.3860\n","Step:662/100000, Loss:3.1260, Time:2.3680\n","Step:663/100000, Loss:2.6120, Time:3.7638\n","Step:664/100000, Loss:2.6269, Time:3.6841\n","Step:665/100000, Loss:2.5350, Time:3.7994\n","Step:666/100000, Loss:2.5408, Time:3.3494\n","Step:667/100000, Loss:2.6777, Time:3.1292\n","Step:668/100000, Loss:2.7323, Time:2.7137\n","Step:669/100000, Loss:3.1291, Time:2.9142\n","Step:670/100000, Loss:2.9060, Time:2.8068\n","Step:671/100000, Loss:2.8264, Time:2.9563\n","Step:672/100000, Loss:2.7308, Time:2.8403\n","Step:673/100000, Loss:2.5850, Time:2.7684\n","Step:674/100000, Loss:2.5698, Time:2.7029\n","Step:675/100000, Loss:2.7868, Time:2.7292\n","Step:676/100000, Loss:2.5995, Time:2.7494\n","Step:677/100000, Loss:2.8830, Time:2.8653\n","Step:678/100000, Loss:2.5911, Time:2.8953\n","Step:679/100000, Loss:2.6501, Time:3.4214\n","Step:680/100000, Loss:2.7029, Time:2.7053\n","Step:681/100000, Loss:2.6138, Time:2.7487\n","Step:682/100000, Loss:2.7933, Time:2.7980\n","Step:683/100000, Loss:2.7082, Time:2.8159\n","Step:684/100000, Loss:2.6061, Time:2.7442\n","Step:685/100000, Loss:2.6060, Time:2.9383\n","Step:686/100000, Loss:2.8110, Time:3.5739\n","Step:687/100000, Loss:2.7142, Time:3.1693\n","Step:688/100000, Loss:2.9144, Time:3.6806\n","Step:689/100000, Loss:2.7384, Time:3.1125\n","Step:690/100000, Loss:2.8764, Time:2.9221\n","Step:691/100000, Loss:2.8374, Time:3.0659\n","Step:692/100000, Loss:2.8511, Time:3.1917\n","Step:693/100000, Loss:2.7558, Time:2.9945\n","Step:694/100000, Loss:3.0360, Time:3.5498\n","Step:695/100000, Loss:2.6945, Time:3.3685\n","Step:696/100000, Loss:2.7236, Time:3.0580\n","Step:697/100000, Loss:2.6493, Time:2.8177\n","Step:698/100000, Loss:2.6445, Time:2.4523\n","Step:699/100000, Loss:2.7202, Time:2.3765\n","Validation step:0, Loss:2.5940, Loss Reconstruction:0.0896\n","Validation step:1, Loss:2.7166, Loss Reconstruction:0.1324\n","Validation step:2, Loss:2.5399, Loss Reconstruction:0.0383\n","Validation step:3, Loss:2.7145, Loss Reconstruction:0.0434\n","Validation step:4, Loss:2.7834, Loss Reconstruction:0.1226\n","Validation step:5, Loss:2.6170, Loss Reconstruction:0.1529\n","Validation step:6, Loss:2.6280, Loss Reconstruction:0.2123\n","Validation step:7, Loss:2.8012, Loss Reconstruction:0.3484\n","Validation step:8, Loss:2.7214, Loss Reconstruction:0.2192\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.1510\n","Step:700/100000, Loss:2.8623, Time:2.4006\n","Step:701/100000, Loss:3.1470, Time:2.4109\n","Step:702/100000, Loss:2.6094, Time:3.6689\n","Step:703/100000, Loss:2.5427, Time:3.8049\n","Step:704/100000, Loss:2.6845, Time:3.7058\n","Step:705/100000, Loss:2.7317, Time:3.3664\n","Step:706/100000, Loss:2.7324, Time:3.1171\n","Step:707/100000, Loss:2.6083, Time:2.7861\n","Step:708/100000, Loss:2.6199, Time:2.8478\n","Step:709/100000, Loss:2.7217, Time:2.9759\n","Step:710/100000, Loss:2.6800, Time:2.6795\n","Step:711/100000, Loss:2.9275, Time:2.7426\n","Step:712/100000, Loss:2.6828, Time:2.7508\n","Step:713/100000, Loss:2.6912, Time:2.7999\n","Step:714/100000, Loss:2.6987, Time:2.7855\n","Step:715/100000, Loss:2.7193, Time:2.7507\n","Step:716/100000, Loss:2.6276, Time:2.8516\n","Step:717/100000, Loss:2.7366, Time:2.7872\n","Step:718/100000, Loss:2.8047, Time:3.1074\n","Step:719/100000, Loss:2.7860, Time:3.0422\n","Step:720/100000, Loss:2.9305, Time:2.6722\n","Step:721/100000, Loss:2.5107, Time:2.7566\n","Step:722/100000, Loss:2.5978, Time:2.8611\n","Step:723/100000, Loss:2.5429, Time:2.7553\n","Step:724/100000, Loss:2.6138, Time:2.9986\n","Step:725/100000, Loss:2.5982, Time:4.0808\n","Step:726/100000, Loss:2.7862, Time:3.1687\n","Step:727/100000, Loss:2.5665, Time:3.5909\n","Step:728/100000, Loss:2.7590, Time:3.0903\n","Step:729/100000, Loss:2.6619, Time:2.8051\n","Step:730/100000, Loss:2.6154, Time:3.0928\n","Step:731/100000, Loss:3.2295, Time:3.0740\n","Step:732/100000, Loss:2.9964, Time:3.0659\n","Step:733/100000, Loss:2.6233, Time:3.3826\n","Step:734/100000, Loss:2.9296, Time:3.2505\n","Step:735/100000, Loss:2.3733, Time:3.1262\n","Step:736/100000, Loss:2.7145, Time:2.7625\n","Step:737/100000, Loss:3.3398, Time:2.4809\n","Step:738/100000, Loss:2.8541, Time:2.4476\n","Step:739/100000, Loss:2.8415, Time:2.4099\n","Step:740/100000, Loss:2.7455, Time:2.3938\n","Step:741/100000, Loss:3.0268, Time:3.7299\n","Step:742/100000, Loss:2.4629, Time:3.9663\n","Step:743/100000, Loss:2.5693, Time:3.4729\n","Step:744/100000, Loss:2.3027, Time:3.5174\n","Step:745/100000, Loss:2.3217, Time:3.2879\n","Step:746/100000, Loss:3.0466, Time:2.7936\n","Step:747/100000, Loss:2.2381, Time:2.8129\n","Step:748/100000, Loss:2.9420, Time:2.7040\n","Step:749/100000, Loss:2.7499, Time:2.7440\n","Step:750/100000, Loss:2.4404, Time:2.9084\n","Step:751/100000, Loss:3.0211, Time:2.7520\n","Step:752/100000, Loss:2.8939, Time:2.8153\n","Step:753/100000, Loss:2.6028, Time:2.7792\n","Step:754/100000, Loss:2.3306, Time:2.8794\n","Step:755/100000, Loss:2.6544, Time:3.0321\n","Step:756/100000, Loss:2.8140, Time:2.7657\n","Step:757/100000, Loss:2.7674, Time:3.0585\n","Step:758/100000, Loss:2.6249, Time:2.7962\n","Step:759/100000, Loss:2.7076, Time:2.8093\n","Step:760/100000, Loss:2.5354, Time:2.7162\n","Step:761/100000, Loss:2.6018, Time:2.8182\n","Step:762/100000, Loss:2.7079, Time:2.7245\n","Step:763/100000, Loss:2.7402, Time:2.9374\n","Step:764/100000, Loss:2.4165, Time:4.2097\n","Step:765/100000, Loss:2.6847, Time:3.9937\n","Step:766/100000, Loss:2.6016, Time:3.8127\n","Step:767/100000, Loss:2.6978, Time:2.9968\n","Step:768/100000, Loss:2.8898, Time:2.7273\n","Step:769/100000, Loss:2.7572, Time:3.1381\n","Step:770/100000, Loss:2.7903, Time:2.9741\n","Step:771/100000, Loss:2.7162, Time:2.9964\n","Step:772/100000, Loss:2.8591, Time:3.3009\n","Step:773/100000, Loss:2.6878, Time:3.5198\n","Step:774/100000, Loss:2.3777, Time:3.0425\n","Step:775/100000, Loss:3.0301, Time:2.7444\n","Step:776/100000, Loss:2.8315, Time:2.4673\n","Step:777/100000, Loss:2.9280, Time:2.3823\n","Step:778/100000, Loss:2.7030, Time:2.4374\n","Step:779/100000, Loss:2.6159, Time:2.4337\n","Step:780/100000, Loss:2.7748, Time:3.8533\n","Step:781/100000, Loss:2.7799, Time:4.0002\n","Step:782/100000, Loss:2.8029, Time:3.6173\n","Step:783/100000, Loss:2.5687, Time:3.6405\n","Step:784/100000, Loss:2.5634, Time:2.8461\n","Step:785/100000, Loss:2.7284, Time:2.7283\n","Step:786/100000, Loss:2.6402, Time:2.8714\n","Step:787/100000, Loss:2.7508, Time:2.7880\n","Step:788/100000, Loss:2.5643, Time:2.8075\n","Step:789/100000, Loss:2.7487, Time:2.8778\n","Step:790/100000, Loss:2.6545, Time:2.7280\n","Step:791/100000, Loss:2.6843, Time:2.7240\n","Step:792/100000, Loss:2.7710, Time:2.8121\n","Step:793/100000, Loss:2.5889, Time:2.8365\n","Step:794/100000, Loss:2.7185, Time:2.8102\n","Step:795/100000, Loss:2.9764, Time:2.8365\n","Step:796/100000, Loss:2.7974, Time:3.1996\n","Step:797/100000, Loss:2.6621, Time:2.7763\n","Step:798/100000, Loss:2.6379, Time:2.9045\n","Step:799/100000, Loss:2.6375, Time:2.7373\n","Validation step:0, Loss:2.4305, Loss Reconstruction:0.0868\n","Validation step:1, Loss:2.8290, Loss Reconstruction:0.2187\n","Validation step:2, Loss:2.6023, Loss Reconstruction:0.1741\n","Validation step:3, Loss:2.7388, Loss Reconstruction:0.2357\n","Validation step:4, Loss:2.6761, Loss Reconstruction:0.0853\n","Validation step:5, Loss:2.6139, Loss Reconstruction:0.1857\n","Validation step:6, Loss:2.6074, Loss Reconstruction:0.1909\n","Validation step:7, Loss:2.7848, Loss Reconstruction:0.3666\n","Validation step:8, Loss:2.8823, Loss Reconstruction:0.4402\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2204\n","Step:800/100000, Loss:2.5633, Time:2.6516\n","Step:801/100000, Loss:2.6402, Time:2.7880\n","Step:802/100000, Loss:2.4482, Time:3.0600\n","Step:803/100000, Loss:2.6210, Time:3.7745\n","Step:804/100000, Loss:2.6053, Time:3.1577\n","Step:805/100000, Loss:2.3678, Time:3.9756\n","Step:806/100000, Loss:2.9351, Time:2.9950\n","Step:807/100000, Loss:2.8890, Time:2.7709\n","Step:808/100000, Loss:2.9798, Time:3.0788\n","Step:809/100000, Loss:2.6027, Time:3.2145\n","Step:810/100000, Loss:3.0437, Time:3.3321\n","Step:811/100000, Loss:2.9258, Time:3.3767\n","Step:812/100000, Loss:2.9707, Time:3.3717\n","Step:813/100000, Loss:2.8168, Time:2.8909\n","Step:814/100000, Loss:2.6559, Time:2.8398\n","Step:815/100000, Loss:2.6113, Time:2.4756\n","Step:816/100000, Loss:2.5016, Time:2.4166\n","Step:817/100000, Loss:2.7337, Time:2.3851\n","Step:818/100000, Loss:2.7805, Time:2.4192\n","Step:819/100000, Loss:2.4000, Time:3.8926\n","Step:820/100000, Loss:2.5231, Time:4.5711\n","Step:821/100000, Loss:2.7143, Time:3.8630\n","Step:822/100000, Loss:2.4985, Time:3.6167\n","Step:823/100000, Loss:2.7478, Time:3.2860\n","Step:824/100000, Loss:2.8740, Time:2.7381\n","Step:825/100000, Loss:2.6973, Time:2.8517\n","Step:826/100000, Loss:3.3259, Time:2.7283\n","Step:827/100000, Loss:2.7906, Time:2.8485\n","Step:828/100000, Loss:2.8398, Time:2.8622\n","Step:829/100000, Loss:2.3089, Time:2.7348\n","Step:830/100000, Loss:2.9037, Time:2.7887\n","Step:831/100000, Loss:2.6383, Time:2.8888\n","Step:832/100000, Loss:2.6642, Time:2.7679\n","Step:833/100000, Loss:2.6441, Time:2.8968\n","Step:834/100000, Loss:2.7146, Time:2.8227\n","Step:835/100000, Loss:2.5911, Time:2.8931\n","Step:836/100000, Loss:2.7799, Time:2.7978\n","Step:837/100000, Loss:2.5184, Time:2.8569\n","Step:838/100000, Loss:2.7168, Time:2.7976\n","Step:839/100000, Loss:2.4946, Time:2.8176\n","Step:840/100000, Loss:2.4902, Time:2.7373\n","Step:841/100000, Loss:2.6669, Time:3.1052\n","Step:842/100000, Loss:2.6223, Time:3.9776\n","Step:843/100000, Loss:2.8871, Time:3.0326\n","Step:844/100000, Loss:2.9338, Time:3.6588\n","Step:845/100000, Loss:2.8598, Time:3.1030\n","Step:846/100000, Loss:2.6553, Time:2.7701\n","Step:847/100000, Loss:3.0567, Time:3.0643\n","Step:848/100000, Loss:2.8108, Time:3.0731\n","Step:849/100000, Loss:2.7089, Time:2.9498\n","Step:850/100000, Loss:2.5773, Time:3.5753\n","Step:851/100000, Loss:2.5457, Time:3.1846\n","Step:852/100000, Loss:2.8313, Time:3.0446\n","Step:853/100000, Loss:2.6282, Time:2.7122\n","Step:854/100000, Loss:3.1359, Time:2.4668\n","Step:855/100000, Loss:2.7286, Time:2.5589\n","Step:856/100000, Loss:2.5892, Time:2.4047\n","Step:857/100000, Loss:2.5955, Time:2.3948\n","Step:858/100000, Loss:2.6554, Time:3.7722\n","Step:859/100000, Loss:2.4941, Time:3.9177\n","Step:860/100000, Loss:2.6061, Time:3.6442\n","Step:861/100000, Loss:2.7911, Time:3.4783\n","Step:862/100000, Loss:2.6681, Time:3.1025\n","Step:863/100000, Loss:2.9628, Time:2.7637\n","Step:864/100000, Loss:2.6791, Time:2.8231\n","Step:865/100000, Loss:2.9126, Time:2.6957\n","Step:866/100000, Loss:2.6779, Time:2.8472\n","Step:867/100000, Loss:2.8866, Time:2.8308\n","Step:868/100000, Loss:2.6937, Time:2.6780\n","Step:869/100000, Loss:2.7513, Time:2.7890\n","Step:870/100000, Loss:2.7607, Time:2.8318\n","Step:871/100000, Loss:2.7867, Time:2.7482\n","Step:872/100000, Loss:2.6903, Time:2.8589\n","Step:873/100000, Loss:2.7272, Time:2.7301\n","Step:874/100000, Loss:2.6963, Time:3.1380\n","Step:875/100000, Loss:2.3059, Time:2.7168\n","Step:876/100000, Loss:2.7936, Time:2.9336\n","Step:877/100000, Loss:2.8138, Time:2.7707\n","Step:878/100000, Loss:2.9699, Time:2.7687\n","Step:879/100000, Loss:2.6708, Time:2.8029\n","Step:880/100000, Loss:2.5287, Time:2.9562\n","Step:881/100000, Loss:2.9828, Time:3.8292\n","Step:882/100000, Loss:2.7318, Time:2.9025\n","Step:883/100000, Loss:2.7153, Time:3.9591\n","Step:884/100000, Loss:3.1512, Time:4.1844\n","Step:885/100000, Loss:2.7758, Time:2.8660\n","Step:886/100000, Loss:2.9120, Time:2.9562\n","Step:887/100000, Loss:2.7658, Time:3.1588\n","Step:888/100000, Loss:2.8141, Time:2.8410\n","Step:889/100000, Loss:2.7444, Time:3.5887\n","Step:890/100000, Loss:2.7933, Time:3.2873\n","Step:891/100000, Loss:2.8330, Time:3.2021\n","Step:892/100000, Loss:2.8281, Time:2.7687\n","Step:893/100000, Loss:2.6626, Time:2.4615\n","Step:894/100000, Loss:2.3174, Time:2.3917\n","Step:895/100000, Loss:2.6573, Time:2.4074\n","Step:896/100000, Loss:2.5663, Time:2.4043\n","Step:897/100000, Loss:2.8465, Time:3.9437\n","Step:898/100000, Loss:2.9038, Time:3.7292\n","Step:899/100000, Loss:2.9567, Time:3.6736\n","Validation step:0, Loss:2.8981, Loss Reconstruction:0.3008\n","Validation step:1, Loss:2.5344, Loss Reconstruction:0.1430\n","Validation step:2, Loss:3.0247, Loss Reconstruction:0.2081\n","Validation step:3, Loss:2.6701, Loss Reconstruction:0.1922\n","Validation step:4, Loss:2.6682, Loss Reconstruction:0.0707\n","Validation step:5, Loss:2.7876, Loss Reconstruction:0.1896\n","Validation step:6, Loss:2.9134, Loss Reconstruction:0.3164\n","Validation step:7, Loss:3.0795, Loss Reconstruction:0.1689\n","Validation step:8, Loss:3.4925, Loss Reconstruction:0.4767\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2296\n","Step:900/100000, Loss:2.4535, Time:2.7555\n","Step:901/100000, Loss:2.8354, Time:2.8990\n","Step:902/100000, Loss:2.4319, Time:2.9371\n","Step:903/100000, Loss:2.7012, Time:2.8411\n","Step:904/100000, Loss:2.7175, Time:2.8944\n","Step:905/100000, Loss:2.9262, Time:2.8460\n","Step:906/100000, Loss:2.7427, Time:2.7984\n","Step:907/100000, Loss:2.4717, Time:2.7055\n","Step:908/100000, Loss:2.5241, Time:2.7650\n","Step:909/100000, Loss:2.7353, Time:2.9523\n","Step:910/100000, Loss:2.7537, Time:2.7964\n","Step:911/100000, Loss:2.8552, Time:2.8812\n","Step:912/100000, Loss:2.8133, Time:2.9063\n","Step:913/100000, Loss:2.7031, Time:3.0591\n","Step:914/100000, Loss:2.6726, Time:2.8246\n","Step:915/100000, Loss:3.0378, Time:2.8800\n","Step:916/100000, Loss:2.3785, Time:2.7529\n","Step:917/100000, Loss:2.6270, Time:2.8141\n","Step:918/100000, Loss:2.6632, Time:2.7002\n","Step:919/100000, Loss:2.6772, Time:3.0562\n","Step:920/100000, Loss:2.9602, Time:3.9743\n","Step:921/100000, Loss:2.7641, Time:3.0016\n","Step:922/100000, Loss:2.6146, Time:3.5468\n","Step:923/100000, Loss:2.9320, Time:3.3707\n","Step:924/100000, Loss:2.6319, Time:2.7799\n","Step:925/100000, Loss:2.8973, Time:3.1016\n","Step:926/100000, Loss:2.9011, Time:3.2053\n","Step:927/100000, Loss:2.7646, Time:2.9546\n","Step:928/100000, Loss:2.7630, Time:3.4314\n","Step:929/100000, Loss:2.9879, Time:3.2793\n","Step:930/100000, Loss:2.8700, Time:3.0423\n","Step:931/100000, Loss:2.7663, Time:2.8355\n","Step:932/100000, Loss:2.7086, Time:2.4641\n","Step:933/100000, Loss:2.7740, Time:2.3850\n","Step:934/100000, Loss:2.9689, Time:2.4241\n","Step:935/100000, Loss:2.5360, Time:2.3819\n","Step:936/100000, Loss:2.6457, Time:3.6537\n","Step:937/100000, Loss:2.8390, Time:3.5410\n","Step:938/100000, Loss:2.6197, Time:4.9508\n","Step:939/100000, Loss:2.7470, Time:3.4021\n","Step:940/100000, Loss:2.5964, Time:3.4825\n","Step:941/100000, Loss:2.6310, Time:2.8152\n","Step:942/100000, Loss:2.6068, Time:2.8092\n","Step:943/100000, Loss:2.6062, Time:2.7029\n","Step:944/100000, Loss:2.4829, Time:3.0689\n","Step:945/100000, Loss:2.7001, Time:2.7107\n","Step:946/100000, Loss:2.7910, Time:2.6862\n","Step:947/100000, Loss:2.9619, Time:2.7548\n","Step:948/100000, Loss:2.7072, Time:2.8538\n","Step:949/100000, Loss:2.8289, Time:2.7758\n","Step:950/100000, Loss:2.4292, Time:2.9043\n","Step:951/100000, Loss:2.7301, Time:2.7870\n","Step:952/100000, Loss:2.6961, Time:3.1734\n","Step:953/100000, Loss:2.4661, Time:2.7359\n","Step:954/100000, Loss:2.6031, Time:2.7474\n","Step:955/100000, Loss:2.8007, Time:2.8049\n","Step:956/100000, Loss:2.2897, Time:2.8118\n","Step:957/100000, Loss:2.5248, Time:2.7590\n","Step:958/100000, Loss:2.5670, Time:3.1129\n","Step:959/100000, Loss:2.7946, Time:3.8546\n","Step:960/100000, Loss:2.7805, Time:3.2045\n","Step:961/100000, Loss:2.7117, Time:3.6068\n","Step:962/100000, Loss:2.5130, Time:2.9801\n","Step:963/100000, Loss:2.7072, Time:2.7559\n","Step:964/100000, Loss:3.0395, Time:3.0162\n","Step:965/100000, Loss:3.1105, Time:3.0969\n","Step:966/100000, Loss:2.7743, Time:3.0530\n","Step:967/100000, Loss:2.9302, Time:3.6897\n","Step:968/100000, Loss:3.2623, Time:3.1012\n","Step:969/100000, Loss:2.9635, Time:2.9049\n","Step:970/100000, Loss:2.6111, Time:2.8154\n","Step:971/100000, Loss:3.0106, Time:2.4687\n","Step:972/100000, Loss:2.4926, Time:2.3758\n","Step:973/100000, Loss:2.7731, Time:2.3920\n","Step:974/100000, Loss:2.7269, Time:2.4129\n","Step:975/100000, Loss:2.5565, Time:3.8059\n","Step:976/100000, Loss:2.7400, Time:3.5932\n","Step:977/100000, Loss:2.7816, Time:3.5806\n","Step:978/100000, Loss:2.7187, Time:3.3412\n","Step:979/100000, Loss:2.5920, Time:3.5465\n","Step:980/100000, Loss:2.5643, Time:2.7024\n","Step:981/100000, Loss:2.7141, Time:2.9235\n","Step:982/100000, Loss:2.7299, Time:2.7699\n","Step:983/100000, Loss:2.6516, Time:2.8067\n","Step:984/100000, Loss:2.8561, Time:2.8244\n","Step:985/100000, Loss:2.6767, Time:2.7632\n","Step:986/100000, Loss:2.8187, Time:2.7639\n","Step:987/100000, Loss:2.6028, Time:2.7329\n","Step:988/100000, Loss:2.6323, Time:2.9950\n","Step:989/100000, Loss:2.4562, Time:2.8283\n","Step:990/100000, Loss:2.7754, Time:2.7808\n","Step:991/100000, Loss:2.6210, Time:3.1174\n","Step:992/100000, Loss:2.5174, Time:2.7486\n","Step:993/100000, Loss:2.7163, Time:2.7479\n","Step:994/100000, Loss:2.5143, Time:2.7841\n","Step:995/100000, Loss:2.6141, Time:2.8216\n","Step:996/100000, Loss:2.7316, Time:2.7748\n","Step:997/100000, Loss:2.7276, Time:2.8480\n","Step:998/100000, Loss:2.6377, Time:3.9593\n","Step:999/100000, Loss:2.7276, Time:3.0054\n","Validation step:0, Loss:2.5459, Loss Reconstruction:0.0273\n","Validation step:1, Loss:2.9494, Loss Reconstruction:0.4723\n","Validation step:2, Loss:2.4871, Loss Reconstruction:0.0672\n","Validation step:3, Loss:2.6207, Loss Reconstruction:0.0512\n","Validation step:4, Loss:2.6470, Loss Reconstruction:0.2335\n","Validation step:5, Loss:2.4582, Loss Reconstruction:0.0205\n","Validation step:6, Loss:2.9732, Loss Reconstruction:0.4440\n","Validation step:7, Loss:2.8395, Loss Reconstruction:0.3447\n","Validation step:8, Loss:2.8193, Loss Reconstruction:0.3066\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2186\n","Step:1000/100000, Loss:2.6340, Time:2.7640\n","Step:1001/100000, Loss:2.6016, Time:3.1244\n","Step:1002/100000, Loss:2.7864, Time:2.7420\n","Step:1003/100000, Loss:2.7352, Time:3.2857\n","Step:1004/100000, Loss:2.8437, Time:3.2438\n","Step:1005/100000, Loss:2.9086, Time:3.1352\n","Step:1006/100000, Loss:2.5816, Time:3.5381\n","Step:1007/100000, Loss:2.8022, Time:3.5180\n","Step:1008/100000, Loss:2.8558, Time:3.1312\n","Step:1009/100000, Loss:2.6507, Time:2.7597\n","Step:1010/100000, Loss:2.7268, Time:2.4658\n","Step:1011/100000, Loss:3.0343, Time:2.4232\n","Step:1012/100000, Loss:2.9346, Time:2.4157\n","Step:1013/100000, Loss:2.7699, Time:2.3780\n","Step:1014/100000, Loss:2.6564, Time:4.0370\n","Step:1015/100000, Loss:2.9294, Time:3.9400\n","Step:1016/100000, Loss:2.6477, Time:3.5778\n","Step:1017/100000, Loss:2.4513, Time:3.5743\n","Step:1018/100000, Loss:2.5799, Time:2.7810\n","Step:1019/100000, Loss:2.6874, Time:2.6685\n","Step:1020/100000, Loss:2.9289, Time:2.9018\n","Step:1021/100000, Loss:2.7200, Time:2.6915\n","Step:1022/100000, Loss:2.4785, Time:2.9633\n","Step:1023/100000, Loss:2.5508, Time:2.7503\n","Step:1024/100000, Loss:2.2636, Time:2.7344\n","Step:1025/100000, Loss:3.0838, Time:2.7473\n","Step:1026/100000, Loss:2.8906, Time:2.8055\n","Step:1027/100000, Loss:2.6967, Time:2.7364\n","Step:1028/100000, Loss:2.6136, Time:2.8863\n","Step:1029/100000, Loss:2.7393, Time:2.8300\n","Step:1030/100000, Loss:2.5830, Time:2.9857\n","Step:1031/100000, Loss:2.6637, Time:3.0227\n","Step:1032/100000, Loss:2.5243, Time:2.8016\n","Step:1033/100000, Loss:2.5520, Time:2.7399\n","Step:1034/100000, Loss:2.7446, Time:2.7188\n","Step:1035/100000, Loss:2.6875, Time:2.7912\n","Step:1036/100000, Loss:2.5484, Time:2.9846\n","Step:1037/100000, Loss:2.6941, Time:3.8051\n","Step:1038/100000, Loss:2.6599, Time:3.2426\n","Step:1039/100000, Loss:2.5550, Time:3.4401\n","Step:1040/100000, Loss:2.6782, Time:3.2307\n","Step:1041/100000, Loss:2.6002, Time:2.7880\n","Step:1042/100000, Loss:2.8236, Time:3.1093\n","Step:1043/100000, Loss:2.6044, Time:3.0490\n","Step:1044/100000, Loss:2.9164, Time:3.0093\n","Step:1045/100000, Loss:2.9167, Time:3.3877\n","Step:1046/100000, Loss:2.7324, Time:3.1862\n","Step:1047/100000, Loss:2.7877, Time:3.1263\n","Step:1048/100000, Loss:2.9933, Time:2.8116\n","Step:1049/100000, Loss:2.8836, Time:2.4882\n","Step:1050/100000, Loss:2.4674, Time:2.4522\n","Step:1051/100000, Loss:2.8896, Time:2.4517\n","Step:1052/100000, Loss:3.0122, Time:2.4286\n","Step:1053/100000, Loss:2.7204, Time:3.6726\n","Step:1054/100000, Loss:3.0126, Time:3.4969\n","Step:1055/100000, Loss:2.5654, Time:4.8989\n","Step:1056/100000, Loss:2.5804, Time:3.6477\n","Step:1057/100000, Loss:2.4989, Time:3.6715\n","Step:1058/100000, Loss:2.6470, Time:2.7723\n","Step:1059/100000, Loss:2.6705, Time:2.9154\n","Step:1060/100000, Loss:2.4995, Time:2.6851\n","Step:1061/100000, Loss:2.6871, Time:2.8953\n","Step:1062/100000, Loss:2.7285, Time:2.7550\n","Step:1063/100000, Loss:2.7223, Time:2.7948\n","Step:1064/100000, Loss:2.5256, Time:2.7671\n","Step:1065/100000, Loss:2.8044, Time:2.8930\n","Step:1066/100000, Loss:2.6492, Time:2.7665\n","Step:1067/100000, Loss:2.5646, Time:2.9409\n","Step:1068/100000, Loss:2.6777, Time:2.9085\n","Step:1069/100000, Loss:2.8402, Time:3.1480\n","Step:1070/100000, Loss:2.7206, Time:2.7615\n","Step:1071/100000, Loss:2.5570, Time:2.8639\n","Step:1072/100000, Loss:2.5708, Time:2.6880\n","Step:1073/100000, Loss:2.7665, Time:2.7858\n","Step:1074/100000, Loss:2.8491, Time:2.7201\n","Step:1075/100000, Loss:2.6331, Time:2.8596\n","Step:1076/100000, Loss:2.5505, Time:4.0134\n","Step:1077/100000, Loss:2.7703, Time:3.2309\n","Step:1078/100000, Loss:2.5860, Time:3.7193\n","Step:1079/100000, Loss:2.6609, Time:3.2139\n","Step:1080/100000, Loss:2.6310, Time:2.8447\n","Step:1081/100000, Loss:2.6067, Time:2.9411\n","Step:1082/100000, Loss:2.8646, Time:3.2611\n","Step:1083/100000, Loss:2.7573, Time:2.9238\n","Step:1084/100000, Loss:2.9389, Time:3.5137\n","Step:1085/100000, Loss:2.7965, Time:3.2478\n","Step:1086/100000, Loss:2.8444, Time:3.1820\n","Step:1087/100000, Loss:2.5921, Time:2.7638\n","Step:1088/100000, Loss:2.8733, Time:2.4980\n","Step:1089/100000, Loss:2.8520, Time:2.4204\n","Step:1090/100000, Loss:2.6663, Time:2.3993\n","Step:1091/100000, Loss:2.7497, Time:2.4069\n","Step:1092/100000, Loss:2.6711, Time:3.4663\n","Step:1093/100000, Loss:2.3884, Time:3.8747\n","Step:1094/100000, Loss:2.7395, Time:3.7985\n","Step:1095/100000, Loss:2.5451, Time:3.8359\n","Step:1096/100000, Loss:2.7512, Time:3.0015\n","Step:1097/100000, Loss:2.8187, Time:2.8053\n","Step:1098/100000, Loss:2.5592, Time:2.8516\n","Step:1099/100000, Loss:2.5033, Time:2.7913\n","Validation step:0, Loss:2.8082, Loss Reconstruction:0.0904\n","Validation step:1, Loss:2.6089, Loss Reconstruction:0.2401\n","Validation step:2, Loss:2.6015, Loss Reconstruction:0.2339\n","Validation step:3, Loss:2.8943, Loss Reconstruction:0.3511\n","Validation step:4, Loss:2.7118, Loss Reconstruction:0.2060\n","Validation step:5, Loss:2.6264, Loss Reconstruction:0.0942\n","Validation step:6, Loss:2.6758, Loss Reconstruction:0.3084\n","Validation step:7, Loss:2.9155, Loss Reconstruction:0.1975\n","Validation step:8, Loss:2.6467, Loss Reconstruction:0.0666\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.1987\n","Step:1100/100000, Loss:2.6492, Time:2.7796\n","Step:1101/100000, Loss:2.6525, Time:2.8543\n","Step:1102/100000, Loss:2.4426, Time:2.7605\n","Step:1103/100000, Loss:2.7010, Time:2.8582\n","Step:1104/100000, Loss:2.4193, Time:2.8010\n","Step:1105/100000, Loss:2.8156, Time:2.8118\n","Step:1106/100000, Loss:2.5715, Time:2.9528\n","Step:1107/100000, Loss:2.4853, Time:2.8955\n","Step:1108/100000, Loss:2.4186, Time:3.0972\n","Step:1109/100000, Loss:2.8132, Time:2.7610\n","Step:1110/100000, Loss:2.9504, Time:3.4379\n","Step:1111/100000, Loss:2.5923, Time:3.4997\n","Step:1112/100000, Loss:2.4404, Time:2.8337\n","Step:1113/100000, Loss:2.7550, Time:2.8052\n","Step:1114/100000, Loss:3.0497, Time:3.0565\n","Step:1115/100000, Loss:2.7110, Time:3.9040\n","Step:1116/100000, Loss:3.0191, Time:3.1731\n","Step:1117/100000, Loss:2.5506, Time:4.0654\n","Step:1118/100000, Loss:2.8602, Time:2.8673\n","Step:1119/100000, Loss:2.9057, Time:2.7539\n","Step:1120/100000, Loss:2.8559, Time:3.0842\n","Step:1121/100000, Loss:2.6424, Time:3.2068\n","Step:1122/100000, Loss:2.7081, Time:3.2494\n","Step:1123/100000, Loss:2.6515, Time:3.3674\n","Step:1124/100000, Loss:2.7163, Time:3.3563\n","Step:1125/100000, Loss:2.8642, Time:3.0856\n","Step:1126/100000, Loss:3.0136, Time:2.8334\n","Step:1127/100000, Loss:2.7444, Time:2.5039\n","Step:1128/100000, Loss:3.2505, Time:2.4216\n","Step:1129/100000, Loss:2.9057, Time:2.4370\n","Step:1130/100000, Loss:2.7521, Time:2.4253\n","Step:1131/100000, Loss:2.9521, Time:3.6641\n","Step:1132/100000, Loss:2.6457, Time:3.8616\n","Step:1133/100000, Loss:2.7029, Time:3.7008\n","Step:1134/100000, Loss:2.7327, Time:3.6442\n","Step:1135/100000, Loss:2.7397, Time:3.4221\n","Step:1136/100000, Loss:2.7728, Time:2.8224\n","Step:1137/100000, Loss:2.8772, Time:2.8262\n","Step:1138/100000, Loss:2.4104, Time:2.7370\n","Step:1139/100000, Loss:2.7333, Time:2.9268\n","Step:1140/100000, Loss:3.1385, Time:2.8658\n","Step:1141/100000, Loss:2.9768, Time:2.7642\n","Step:1142/100000, Loss:2.7143, Time:2.8036\n","Step:1143/100000, Loss:2.9188, Time:2.9181\n","Step:1144/100000, Loss:3.1007, Time:2.7959\n","Step:1145/100000, Loss:2.5607, Time:2.9667\n","Step:1146/100000, Loss:2.6124, Time:2.7797\n","Step:1147/100000, Loss:2.4772, Time:3.0491\n","Step:1148/100000, Loss:2.7250, Time:2.8382\n","Step:1149/100000, Loss:2.5907, Time:2.9103\n","Step:1150/100000, Loss:2.7255, Time:2.7410\n","Step:1151/100000, Loss:2.7442, Time:2.8286\n","Step:1152/100000, Loss:2.6875, Time:2.7818\n","Step:1153/100000, Loss:2.6759, Time:2.9170\n","Step:1154/100000, Loss:2.7545, Time:3.6337\n","Step:1155/100000, Loss:2.8267, Time:3.3871\n","Step:1156/100000, Loss:2.5761, Time:3.7205\n","Step:1157/100000, Loss:2.9524, Time:3.2157\n","Step:1158/100000, Loss:2.7753, Time:2.7406\n","Step:1159/100000, Loss:3.1554, Time:3.2555\n","Step:1160/100000, Loss:2.6726, Time:3.1668\n","Step:1161/100000, Loss:2.8063, Time:2.9560\n","Step:1162/100000, Loss:2.7894, Time:3.6793\n","Step:1163/100000, Loss:2.9162, Time:3.3940\n","Step:1164/100000, Loss:2.8293, Time:3.0702\n","Step:1165/100000, Loss:2.6784, Time:2.8361\n","Step:1166/100000, Loss:2.8935, Time:2.4890\n","Step:1167/100000, Loss:2.5708, Time:2.5539\n","Step:1168/100000, Loss:2.6247, Time:2.3920\n","Step:1169/100000, Loss:2.8364, Time:2.4274\n","Step:1170/100000, Loss:2.7891, Time:3.6401\n","Step:1171/100000, Loss:2.5712, Time:3.9010\n","Step:1172/100000, Loss:2.4150, Time:5.1474\n","Step:1173/100000, Loss:2.7364, Time:3.5367\n","Step:1174/100000, Loss:2.7377, Time:3.4150\n","Step:1175/100000, Loss:2.6248, Time:2.6863\n","Step:1176/100000, Loss:2.4517, Time:2.7941\n","Step:1177/100000, Loss:2.3950, Time:2.7419\n","Step:1178/100000, Loss:2.4710, Time:2.7527\n","Step:1179/100000, Loss:2.9145, Time:2.7724\n","Step:1180/100000, Loss:2.7793, Time:2.7216\n","Step:1181/100000, Loss:2.8589, Time:2.7328\n","Step:1182/100000, Loss:2.7788, Time:2.7333\n","Step:1183/100000, Loss:2.6030, Time:2.6882\n","Step:1184/100000, Loss:2.6862, Time:2.9735\n","Step:1185/100000, Loss:2.7289, Time:2.8017\n","Step:1186/100000, Loss:2.4330, Time:3.1164\n","Step:1187/100000, Loss:2.7581, Time:2.8007\n","Step:1188/100000, Loss:2.6392, Time:2.9934\n","Step:1189/100000, Loss:2.4928, Time:2.7989\n","Step:1190/100000, Loss:2.8381, Time:2.7928\n","Step:1191/100000, Loss:2.4432, Time:2.7612\n","Step:1192/100000, Loss:2.8036, Time:2.9707\n","Step:1193/100000, Loss:2.6456, Time:3.8046\n","Step:1194/100000, Loss:2.6177, Time:3.2948\n","Step:1195/100000, Loss:2.7820, Time:3.8374\n","Step:1196/100000, Loss:3.0775, Time:2.9625\n","Step:1197/100000, Loss:2.6075, Time:2.7707\n","Step:1198/100000, Loss:3.1096, Time:2.8960\n","Step:1199/100000, Loss:2.7398, Time:3.1637\n","Validation step:0, Loss:2.4572, Loss Reconstruction:0.1228\n","Validation step:1, Loss:2.7935, Loss Reconstruction:0.2493\n","Validation step:2, Loss:3.0049, Loss Reconstruction:0.2373\n","Validation step:3, Loss:2.5304, Loss Reconstruction:0.0206\n","Validation step:4, Loss:2.6663, Loss Reconstruction:0.1871\n","Validation step:5, Loss:2.4504, Loss Reconstruction:0.1172\n","Validation step:6, Loss:2.7742, Loss Reconstruction:0.2628\n","Validation step:7, Loss:2.8211, Loss Reconstruction:0.3434\n","Validation step:8, Loss:2.6130, Loss Reconstruction:0.1816\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.1913\n","Step:1200/100000, Loss:2.7639, Time:2.6804\n","Step:1201/100000, Loss:2.5686, Time:3.6436\n","Step:1202/100000, Loss:2.7412, Time:3.7876\n","Step:1203/100000, Loss:2.9415, Time:3.1558\n","Step:1204/100000, Loss:3.0661, Time:2.7774\n","Step:1205/100000, Loss:2.8901, Time:2.4640\n","Step:1206/100000, Loss:2.4981, Time:2.4327\n","Step:1207/100000, Loss:2.8624, Time:2.3936\n","Step:1208/100000, Loss:2.6068, Time:2.4110\n","Step:1209/100000, Loss:2.6124, Time:3.8335\n","Step:1210/100000, Loss:2.5383, Time:3.6995\n","Step:1211/100000, Loss:2.6093, Time:3.8082\n","Step:1212/100000, Loss:2.8654, Time:3.5378\n","Step:1213/100000, Loss:3.0785, Time:2.9255\n","Step:1214/100000, Loss:2.7317, Time:2.7604\n","Step:1215/100000, Loss:2.9176, Time:2.8935\n","Step:1216/100000, Loss:2.3609, Time:2.7636\n","Step:1217/100000, Loss:2.6219, Time:2.8741\n","Step:1218/100000, Loss:2.6043, Time:2.7774\n","Step:1219/100000, Loss:2.5844, Time:2.8035\n","Step:1220/100000, Loss:2.7693, Time:2.6963\n","Step:1221/100000, Loss:2.7757, Time:2.8218\n","Step:1222/100000, Loss:2.5681, Time:2.7598\n","Step:1223/100000, Loss:2.6779, Time:2.9436\n","Step:1224/100000, Loss:2.5084, Time:2.8232\n","Step:1225/100000, Loss:2.5475, Time:3.0725\n","Step:1226/100000, Loss:2.6841, Time:2.7306\n","Step:1227/100000, Loss:2.6061, Time:3.7975\n","Step:1228/100000, Loss:2.7091, Time:2.9627\n","Step:1229/100000, Loss:2.6525, Time:2.8681\n","Step:1230/100000, Loss:2.4484, Time:2.8592\n","Step:1231/100000, Loss:2.6388, Time:3.1184\n","Step:1232/100000, Loss:2.7550, Time:3.8174\n","Step:1233/100000, Loss:2.6830, Time:3.1805\n","Step:1234/100000, Loss:2.5906, Time:3.4357\n","Step:1235/100000, Loss:3.0754, Time:3.0107\n","Step:1236/100000, Loss:2.7086, Time:2.7538\n","Step:1237/100000, Loss:2.9960, Time:3.1117\n","Step:1238/100000, Loss:2.8627, Time:2.9757\n","Step:1239/100000, Loss:2.8119, Time:2.9585\n","Step:1240/100000, Loss:2.6335, Time:3.6354\n","Step:1241/100000, Loss:2.8173, Time:3.2253\n","Step:1242/100000, Loss:2.9428, Time:3.0693\n","Step:1243/100000, Loss:2.6546, Time:2.7176\n","Step:1244/100000, Loss:3.0220, Time:2.4342\n","Step:1245/100000, Loss:2.8183, Time:2.3937\n","Step:1246/100000, Loss:2.7189, Time:2.4129\n","Step:1247/100000, Loss:2.7186, Time:2.3722\n","Step:1248/100000, Loss:2.6479, Time:3.8173\n","Step:1249/100000, Loss:2.6785, Time:3.6583\n","Step:1250/100000, Loss:2.5831, Time:3.5032\n","Step:1251/100000, Loss:2.6598, Time:3.4702\n","Step:1252/100000, Loss:2.6722, Time:3.3683\n","Step:1253/100000, Loss:2.5731, Time:2.6893\n","Step:1254/100000, Loss:2.6087, Time:2.8242\n","Step:1255/100000, Loss:2.8275, Time:2.8055\n","Step:1256/100000, Loss:2.6696, Time:2.7143\n","Step:1257/100000, Loss:2.7136, Time:2.8348\n","Step:1258/100000, Loss:2.7775, Time:2.7387\n","Step:1259/100000, Loss:2.6489, Time:2.7265\n","Step:1260/100000, Loss:2.6536, Time:2.8606\n","Step:1261/100000, Loss:2.7046, Time:2.6985\n","Step:1262/100000, Loss:2.5819, Time:2.8017\n","Step:1263/100000, Loss:2.7826, Time:2.7962\n","Step:1264/100000, Loss:2.6015, Time:3.0153\n","Step:1265/100000, Loss:2.6425, Time:2.7785\n","Step:1266/100000, Loss:2.4593, Time:2.8981\n","Step:1267/100000, Loss:2.6596, Time:2.7508\n","Step:1268/100000, Loss:2.6595, Time:2.7529\n","Step:1269/100000, Loss:2.6586, Time:2.7741\n","Step:1270/100000, Loss:2.4887, Time:2.9821\n","Step:1271/100000, Loss:2.5847, Time:3.6968\n","Step:1272/100000, Loss:2.5711, Time:3.2283\n","Step:1273/100000, Loss:2.6481, Time:3.6331\n","Step:1274/100000, Loss:2.5944, Time:3.1921\n","Step:1275/100000, Loss:2.8258, Time:2.7465\n","Step:1276/100000, Loss:2.5998, Time:3.0985\n","Step:1277/100000, Loss:2.3850, Time:3.0867\n","Step:1278/100000, Loss:2.9204, Time:2.9790\n","Step:1279/100000, Loss:2.7948, Time:3.4146\n","Step:1280/100000, Loss:2.8962, Time:3.2789\n","Step:1281/100000, Loss:2.7830, Time:3.1585\n","Step:1282/100000, Loss:2.6225, Time:2.8642\n","Step:1283/100000, Loss:2.7890, Time:2.5050\n","Step:1284/100000, Loss:2.7792, Time:2.3892\n","Step:1285/100000, Loss:2.9837, Time:2.4158\n","Step:1286/100000, Loss:2.8424, Time:2.4193\n","Step:1287/100000, Loss:2.6959, Time:3.6862\n","Step:1288/100000, Loss:2.7356, Time:3.9287\n","Step:1289/100000, Loss:2.4615, Time:4.3400\n","Step:1290/100000, Loss:2.7169, Time:4.0947\n","Step:1291/100000, Loss:2.4352, Time:2.9532\n","Step:1292/100000, Loss:2.8472, Time:2.7345\n","Step:1293/100000, Loss:2.6783, Time:2.8327\n","Step:1294/100000, Loss:2.5912, Time:2.6782\n","Step:1295/100000, Loss:2.7148, Time:2.8356\n","Step:1296/100000, Loss:2.7011, Time:2.6386\n","Step:1297/100000, Loss:2.6628, Time:2.7544\n","Step:1298/100000, Loss:2.5759, Time:2.7677\n","Step:1299/100000, Loss:2.7726, Time:2.8538\n","Validation step:0, Loss:2.5370, Loss Reconstruction:0.0883\n","Validation step:1, Loss:2.9067, Loss Reconstruction:0.3638\n","Validation step:2, Loss:2.7251, Loss Reconstruction:0.1851\n","Validation step:3, Loss:2.8130, Loss Reconstruction:0.3372\n","Validation step:4, Loss:2.5191, Loss Reconstruction:0.0806\n","Validation step:5, Loss:2.5888, Loss Reconstruction:0.0998\n","Validation step:6, Loss:2.6839, Loss Reconstruction:0.2565\n","Validation step:7, Loss:2.6378, Loss Reconstruction:0.1490\n","Validation step:8, Loss:2.9399, Loss Reconstruction:0.4419\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2225\n","Step:1300/100000, Loss:2.7279, Time:2.7720\n","Step:1301/100000, Loss:2.5237, Time:3.0180\n","Step:1302/100000, Loss:2.7413, Time:3.0959\n","Step:1303/100000, Loss:2.5317, Time:3.0270\n","Step:1304/100000, Loss:2.6390, Time:2.8429\n","Step:1305/100000, Loss:2.5500, Time:2.8906\n","Step:1306/100000, Loss:2.6353, Time:2.7711\n","Step:1307/100000, Loss:2.4634, Time:2.7419\n","Step:1308/100000, Loss:2.8015, Time:2.8264\n","Step:1309/100000, Loss:2.6561, Time:2.8101\n","Step:1310/100000, Loss:2.7967, Time:3.8220\n","Step:1311/100000, Loss:2.8948, Time:3.1507\n","Step:1312/100000, Loss:2.5774, Time:3.8800\n","Step:1313/100000, Loss:2.8667, Time:2.9243\n","Step:1314/100000, Loss:2.4716, Time:2.8022\n","Step:1315/100000, Loss:2.7933, Time:3.0761\n","Step:1316/100000, Loss:2.8994, Time:3.0812\n","Step:1317/100000, Loss:2.6862, Time:2.9279\n","Step:1318/100000, Loss:2.8974, Time:3.2899\n","Step:1319/100000, Loss:2.7058, Time:3.6055\n","Step:1320/100000, Loss:2.6815, Time:3.2109\n","Step:1321/100000, Loss:2.8713, Time:2.7350\n","Step:1322/100000, Loss:2.8740, Time:2.4665\n","Step:1323/100000, Loss:2.6777, Time:2.4214\n","Step:1324/100000, Loss:2.8869, Time:2.3968\n","Step:1325/100000, Loss:2.6007, Time:2.4059\n","Step:1326/100000, Loss:2.8242, Time:3.8949\n","Step:1327/100000, Loss:2.7211, Time:3.8358\n","Step:1328/100000, Loss:2.7878, Time:3.5267\n","Step:1329/100000, Loss:2.8157, Time:3.4661\n","Step:1330/100000, Loss:2.6697, Time:3.2797\n","Step:1331/100000, Loss:2.9014, Time:2.7116\n","Step:1332/100000, Loss:2.8146, Time:2.8251\n","Step:1333/100000, Loss:2.5027, Time:2.7142\n","Step:1334/100000, Loss:2.4761, Time:2.8157\n","Step:1335/100000, Loss:2.8011, Time:2.8379\n","Step:1336/100000, Loss:2.6896, Time:2.7859\n","Step:1337/100000, Loss:2.5303, Time:2.7690\n","Step:1338/100000, Loss:2.6748, Time:2.9580\n","Step:1339/100000, Loss:2.3771, Time:2.7033\n","Step:1340/100000, Loss:2.6037, Time:2.9049\n","Step:1341/100000, Loss:2.8406, Time:2.8200\n","Step:1342/100000, Loss:2.6819, Time:3.1556\n","Step:1343/100000, Loss:2.6764, Time:2.9826\n","Step:1344/100000, Loss:2.5315, Time:2.7194\n","Step:1345/100000, Loss:2.3950, Time:3.0301\n","Step:1346/100000, Loss:2.7452, Time:3.9211\n","Step:1347/100000, Loss:2.7971, Time:2.7834\n","Step:1348/100000, Loss:2.8749, Time:3.2238\n","Step:1349/100000, Loss:2.5764, Time:3.7567\n","Step:1350/100000, Loss:2.7460, Time:3.2814\n","Step:1351/100000, Loss:2.7284, Time:3.8526\n","Step:1352/100000, Loss:2.6327, Time:2.8597\n","Step:1353/100000, Loss:2.7259, Time:2.7555\n","Step:1354/100000, Loss:2.8152, Time:2.9169\n","Step:1355/100000, Loss:2.8026, Time:3.1971\n","Step:1356/100000, Loss:2.4814, Time:3.1371\n","Step:1357/100000, Loss:2.9272, Time:3.2535\n","Step:1358/100000, Loss:2.9877, Time:3.5044\n","Step:1359/100000, Loss:2.9089, Time:2.9613\n","Step:1360/100000, Loss:2.9920, Time:2.8189\n","Step:1361/100000, Loss:2.8423, Time:2.4483\n","Step:1362/100000, Loss:2.6039, Time:2.4188\n","Step:1363/100000, Loss:2.6858, Time:2.3831\n","Step:1364/100000, Loss:2.5672, Time:2.4120\n","Step:1365/100000, Loss:2.6026, Time:3.7468\n","Step:1366/100000, Loss:2.6737, Time:3.6638\n","Step:1367/100000, Loss:2.5184, Time:3.5285\n","Step:1368/100000, Loss:2.7206, Time:3.3772\n","Step:1369/100000, Loss:2.7118, Time:3.5008\n","Step:1370/100000, Loss:2.6152, Time:2.7229\n","Step:1371/100000, Loss:2.7269, Time:2.7912\n","Step:1372/100000, Loss:2.5496, Time:2.7467\n","Step:1373/100000, Loss:2.5585, Time:2.8516\n","Step:1374/100000, Loss:2.6316, Time:2.8577\n","Step:1375/100000, Loss:2.7246, Time:2.7903\n","Step:1376/100000, Loss:2.6265, Time:2.7355\n","Step:1377/100000, Loss:2.5993, Time:2.8280\n","Step:1378/100000, Loss:2.6856, Time:2.7289\n","Step:1379/100000, Loss:2.5903, Time:3.0006\n","Step:1380/100000, Loss:2.7869, Time:2.7409\n","Step:1381/100000, Loss:2.5913, Time:3.0565\n","Step:1382/100000, Loss:2.6157, Time:2.7995\n","Step:1383/100000, Loss:2.6102, Time:3.0193\n","Step:1384/100000, Loss:2.7986, Time:2.7948\n","Step:1385/100000, Loss:2.8734, Time:2.7565\n","Step:1386/100000, Loss:2.5809, Time:2.7591\n","Step:1387/100000, Loss:2.4024, Time:2.9111\n","Step:1388/100000, Loss:2.8244, Time:3.9007\n","Step:1389/100000, Loss:2.6909, Time:2.9767\n","Step:1390/100000, Loss:2.6167, Time:3.9112\n","Step:1391/100000, Loss:2.9797, Time:2.9981\n","Step:1392/100000, Loss:2.7117, Time:2.7873\n","Step:1393/100000, Loss:2.7788, Time:3.1237\n","Step:1394/100000, Loss:2.8227, Time:3.1570\n","Step:1395/100000, Loss:2.7595, Time:2.8817\n","Step:1396/100000, Loss:2.8654, Time:3.5158\n","Step:1397/100000, Loss:2.8216, Time:3.2325\n","Step:1398/100000, Loss:2.9633, Time:3.2443\n","Step:1399/100000, Loss:2.8873, Time:2.7415\n","Validation step:0, Loss:2.8325, Loss Reconstruction:0.2659\n","Validation step:1, Loss:2.6660, Loss Reconstruction:0.1878\n","Validation step:2, Loss:2.7795, Loss Reconstruction:0.2842\n","Validation step:3, Loss:2.4926, Loss Reconstruction:0.0265\n","Validation step:4, Loss:2.6535, Loss Reconstruction:0.1887\n","Validation step:5, Loss:2.5867, Loss Reconstruction:0.1380\n","Validation step:6, Loss:2.7950, Loss Reconstruction:0.3014\n","Validation step:7, Loss:2.5607, Loss Reconstruction:0.1115\n","Validation step:8, Loss:2.7570, Loss Reconstruction:0.3359\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.2044\n","Step:1400/100000, Loss:2.8305, Time:2.3921\n","Step:1401/100000, Loss:2.6209, Time:2.4305\n","Step:1402/100000, Loss:2.7232, Time:2.5848\n","Step:1403/100000, Loss:2.4126, Time:2.4178\n","Step:1404/100000, Loss:2.5173, Time:3.6874\n","Step:1405/100000, Loss:2.8886, Time:3.9857\n","Step:1406/100000, Loss:2.7486, Time:3.6000\n","Step:1407/100000, Loss:2.6346, Time:3.5818\n","Step:1408/100000, Loss:2.2591, Time:2.8796\n","Step:1409/100000, Loss:2.6166, Time:2.6247\n","Step:1410/100000, Loss:2.8441, Time:2.9105\n","Step:1411/100000, Loss:2.8846, Time:2.6739\n","Step:1412/100000, Loss:2.4118, Time:2.8220\n","Step:1413/100000, Loss:2.5569, Time:2.8468\n","Step:1414/100000, Loss:2.8570, Time:2.7479\n","Step:1415/100000, Loss:2.9318, Time:2.7892\n","Step:1416/100000, Loss:2.6440, Time:2.7312\n","Step:1417/100000, Loss:2.3700, Time:2.7991\n","Step:1418/100000, Loss:2.4369, Time:3.0455\n","Step:1419/100000, Loss:2.9157, Time:2.7279\n","Step:1420/100000, Loss:2.3553, Time:3.1028\n","Step:1421/100000, Loss:2.6150, Time:2.7140\n","Step:1422/100000, Loss:2.5909, Time:2.8094\n","Step:1423/100000, Loss:2.3975, Time:2.7525\n","Step:1424/100000, Loss:2.6698, Time:2.7643\n","Step:1425/100000, Loss:2.7901, Time:2.7425\n","Step:1426/100000, Loss:2.8215, Time:2.9722\n","Step:1427/100000, Loss:2.7748, Time:3.8249\n","Step:1428/100000, Loss:2.5785, Time:3.1175\n","Step:1429/100000, Loss:2.5261, Time:3.6089\n","Step:1430/100000, Loss:2.9844, Time:3.2109\n","Step:1431/100000, Loss:2.7246, Time:2.7441\n","Step:1432/100000, Loss:2.7350, Time:3.2491\n","Step:1433/100000, Loss:2.8656, Time:2.8804\n","Step:1434/100000, Loss:2.6838, Time:3.2370\n","Step:1435/100000, Loss:2.8428, Time:3.4304\n","Step:1436/100000, Loss:2.6009, Time:2.9857\n","Step:1437/100000, Loss:2.8075, Time:3.2589\n","Step:1438/100000, Loss:2.6879, Time:2.8289\n","Step:1439/100000, Loss:2.8748, Time:2.4353\n","Step:1440/100000, Loss:2.8375, Time:2.3922\n","Step:1441/100000, Loss:2.6428, Time:2.3659\n","Step:1442/100000, Loss:2.7819, Time:2.3985\n","Step:1443/100000, Loss:2.5598, Time:3.7471\n","Step:1444/100000, Loss:2.4818, Time:3.7988\n","Step:1445/100000, Loss:2.8166, Time:3.9312\n","Step:1446/100000, Loss:2.7509, Time:3.5246\n","Step:1447/100000, Loss:2.9209, Time:2.9598\n","Step:1448/100000, Loss:2.6482, Time:2.7310\n","Step:1449/100000, Loss:2.7930, Time:2.8714\n","Step:1450/100000, Loss:2.8005, Time:2.7803\n","Step:1451/100000, Loss:2.6081, Time:2.8972\n","Step:1452/100000, Loss:2.5795, Time:2.8758\n","Step:1453/100000, Loss:2.6847, Time:2.7913\n","Step:1454/100000, Loss:2.6082, Time:2.7456\n","Step:1455/100000, Loss:2.6384, Time:2.9271\n","Step:1456/100000, Loss:2.4853, Time:2.7193\n","Step:1457/100000, Loss:2.6117, Time:2.8836\n","Step:1458/100000, Loss:2.8257, Time:2.8143\n","Step:1459/100000, Loss:2.7174, Time:3.0461\n","Step:1460/100000, Loss:2.7784, Time:2.7423\n","Step:1461/100000, Loss:2.9027, Time:2.8967\n","Step:1462/100000, Loss:2.6739, Time:2.7852\n","Step:1463/100000, Loss:2.3606, Time:2.8063\n","Step:1464/100000, Loss:2.7283, Time:3.9042\n","Step:1465/100000, Loss:2.6488, Time:3.2228\n","Step:1466/100000, Loss:2.5683, Time:3.7252\n","Step:1467/100000, Loss:2.7537, Time:2.9968\n","Step:1468/100000, Loss:2.7161, Time:3.9248\n","Step:1469/100000, Loss:3.0324, Time:3.0773\n","Step:1470/100000, Loss:2.7084, Time:2.8342\n","Step:1471/100000, Loss:3.1475, Time:3.1827\n","Step:1472/100000, Loss:2.8266, Time:3.2253\n","Step:1473/100000, Loss:2.7679, Time:2.8310\n","Step:1474/100000, Loss:2.7326, Time:3.6889\n","Step:1475/100000, Loss:2.8676, Time:3.2510\n","Step:1476/100000, Loss:3.0891, Time:3.2057\n","Step:1477/100000, Loss:2.9820, Time:2.7503\n","Step:1478/100000, Loss:2.6520, Time:2.4718\n","Step:1479/100000, Loss:2.7563, Time:2.4460\n","Step:1480/100000, Loss:2.5262, Time:2.4166\n","Step:1481/100000, Loss:2.6734, Time:2.4225\n","Step:1482/100000, Loss:2.5172, Time:4.0802\n","Step:1483/100000, Loss:2.6762, Time:3.6392\n","Step:1484/100000, Loss:2.7281, Time:3.9857\n","Step:1485/100000, Loss:2.5645, Time:3.4014\n","Step:1486/100000, Loss:2.6870, Time:2.9809\n","Step:1487/100000, Loss:2.7249, Time:2.7393\n","Step:1488/100000, Loss:2.7990, Time:2.8327\n","Step:1489/100000, Loss:2.5781, Time:2.7656\n","Step:1490/100000, Loss:2.5939, Time:2.9035\n","Step:1491/100000, Loss:2.7924, Time:2.8090\n","Step:1492/100000, Loss:2.5566, Time:2.7376\n","Step:1493/100000, Loss:2.6316, Time:2.7781\n","Step:1494/100000, Loss:2.5331, Time:2.8381\n","Step:1495/100000, Loss:2.6146, Time:2.7304\n","Step:1496/100000, Loss:2.4744, Time:2.9572\n","Step:1497/100000, Loss:2.5584, Time:2.8906\n","Step:1498/100000, Loss:2.7003, Time:3.0715\n","Step:1499/100000, Loss:3.1146, Time:2.7186\n","Validation step:0, Loss:2.6010, Loss Reconstruction:0.0803\n","Validation step:1, Loss:2.7188, Loss Reconstruction:0.0872\n","Validation step:2, Loss:2.8602, Loss Reconstruction:0.1525\n","Validation step:3, Loss:2.6393, Loss Reconstruction:0.1185\n","Validation step:4, Loss:2.7959, Loss Reconstruction:0.2762\n","Validation step:5, Loss:2.6083, Loss Reconstruction:0.1276\n","Validation step:6, Loss:2.5863, Loss Reconstruction:0.2211\n","Validation step:7, Loss:2.9727, Loss Reconstruction:0.2662\n","Validation step:8, Loss:2.9155, Loss Reconstruction:0.2085\n","Model was not saved ! Best Recon. Val Loss: 0.1404 Recon. Val Loss: 0.1709\n","Step:1500/100000, Loss:2.5930, Time:2.6933\n","Step:1501/100000, Loss:2.9122, Time:2.8578\n","Step:1502/100000, Loss:2.7405, Time:2.8121\n","Step:1503/100000, Loss:2.5527, Time:2.7301\n","Step:1504/100000, Loss:2.6699, Time:3.0784\n","Step:1505/100000, Loss:2.6105, Time:3.7957\n","Step:1506/100000, Loss:2.4787, Time:3.1538\n","Step:1507/100000, Loss:2.6601, Time:3.8251\n","Step:1508/100000, Loss:2.9233, Time:3.0104\n","Step:1509/100000, Loss:2.7648, Time:2.8113\n","Step:1510/100000, Loss:2.8469, Time:3.0799\n","Step:1511/100000, Loss:2.7765, Time:3.2419\n","Step:1512/100000, Loss:2.8720, Time:2.8723\n","Step:1513/100000, Loss:2.8810, Time:3.6993\n","Step:1514/100000, Loss:2.8080, Time:3.2198\n","Step:1515/100000, Loss:2.7797, Time:3.2072\n","Step:1516/100000, Loss:2.8050, Time:2.7848\n","Step:1517/100000, Loss:2.5696, Time:2.4980\n","Step:1518/100000, Loss:3.0444, Time:2.5462\n","Step:1519/100000, Loss:2.4652, Time:2.4053\n","Step:1520/100000, Loss:2.5903, Time:2.4353\n","Step:1521/100000, Loss:2.7054, Time:3.5709\n","Step:1522/100000, Loss:2.5593, Time:3.7811\n","Step:1523/100000, Loss:2.7143, Time:3.9076\n","Step:1524/100000, Loss:2.6978, Time:3.6704\n","Step:1525/100000, Loss:2.7606, Time:2.9302\n","Step:1526/100000, Loss:2.7175, Time:2.7328\n","Step:1527/100000, Loss:2.7101, Time:2.7968\n","Step:1528/100000, Loss:2.6164, Time:2.7501\n","Step:1529/100000, Loss:2.6572, Time:2.8032\n","Step:1530/100000, Loss:2.5921, Time:2.8474\n","Step:1531/100000, Loss:2.6036, Time:2.8176\n","Step:1532/100000, Loss:2.4877, Time:2.7426\n","Step:1533/100000, Loss:2.6292, Time:2.8412\n","Step:1534/100000, Loss:2.6933, Time:2.7980\n","Step:1535/100000, Loss:3.0204, Time:2.9330\n","Step:1536/100000, Loss:2.5677, Time:2.8988\n","Step:1537/100000, Loss:2.6639, Time:3.0741\n","Step:1538/100000, Loss:2.5215, Time:2.7617\n","Step:1539/100000, Loss:2.6320, Time:2.8953\n","Step:1540/100000, Loss:2.5071, Time:2.7301\n","Step:1541/100000, Loss:2.8276, Time:2.7728\n","Step:1542/100000, Loss:2.6169, Time:2.7965\n","Step:1543/100000, Loss:2.5623, Time:2.9896\n","Step:1544/100000, Loss:2.8550, Time:3.6522\n","Step:1545/100000, Loss:2.6045, Time:3.2150\n","Step:1546/100000, Loss:2.6137, Time:3.5993\n","Step:1547/100000, Loss:3.1036, Time:3.1543\n","Step:1548/100000, Loss:2.8248, Time:2.9901\n","Step:1549/100000, Loss:2.8056, Time:3.0816\n","Step:1550/100000, Loss:2.8088, Time:3.0311\n","Step:1551/100000, Loss:2.6834, Time:3.0072\n","Step:1552/100000, Loss:2.8461, Time:3.5958\n","Step:1553/100000, Loss:3.0162, Time:3.4642\n","Step:1554/100000, Loss:2.7553, Time:3.3395\n","Step:1555/100000, Loss:2.9138, Time:2.7404\n","Step:1556/100000, Loss:2.7263, Time:2.4230\n","Step:1557/100000, Loss:2.6382, Time:2.4101\n","Step:1558/100000, Loss:2.6296, Time:2.3935\n","Step:1559/100000, Loss:2.5933, Time:2.3696\n","Step:1560/100000, Loss:2.8435, Time:3.9487\n","Step:1561/100000, Loss:2.6791, Time:3.9202\n","Step:1562/100000, Loss:2.5101, Time:3.5990\n","Step:1563/100000, Loss:2.7844, Time:3.5001\n","Step:1564/100000, Loss:2.6933, Time:2.9900\n","Step:1565/100000, Loss:2.6708, Time:2.7684\n","Step:1566/100000, Loss:2.4343, Time:2.8413\n","Step:1567/100000, Loss:2.5867, Time:2.6882\n","Step:1568/100000, Loss:2.5367, Time:2.8822\n","Step:1569/100000, Loss:2.5126, Time:2.8545\n","Step:1570/100000, Loss:2.7310, Time:2.8138\n","Step:1571/100000, Loss:2.7039, Time:2.8019\n","Step:1572/100000, Loss:2.6433, Time:3.1245\n","Step:1573/100000, Loss:2.7231, Time:2.8190\n","Step:1574/100000, Loss:2.6623, Time:2.9708\n","Step:1575/100000, Loss:2.6446, Time:2.7782\n","Step:1576/100000, Loss:2.5162, Time:3.0207\n","Step:1577/100000, Loss:2.6045, Time:2.7637\n","Step:1578/100000, Loss:2.8002, Time:2.7906\n","Step:1579/100000, Loss:2.6177, Time:2.9776\n","Step:1580/100000, Loss:2.6746, Time:3.9444\n","Step:1581/100000, Loss:2.5228, Time:2.7703\n","Step:1582/100000, Loss:2.7294, Time:2.9919\n","Step:1583/100000, Loss:2.5071, Time:3.9117\n","Step:1584/100000, Loss:2.5929, Time:3.2517\n","Step:1585/100000, Loss:2.4436, Time:3.4315\n","Step:1586/100000, Loss:2.7330, Time:3.0937\n","Step:1587/100000, Loss:2.7004, Time:2.8422\n","Step:1588/100000, Loss:2.6741, Time:3.1308\n","Step:1589/100000, Loss:2.5664, Time:3.0566\n","Step:1590/100000, Loss:2.8300, Time:3.1250\n","Step:1591/100000, Loss:2.8309, Time:3.4517\n","Step:1592/100000, Loss:2.7413, Time:3.3501\n","Step:1593/100000, Loss:3.1215, Time:3.0349\n","Step:1594/100000, Loss:2.9108, Time:2.6547\n","Step:1595/100000, Loss:2.7295, Time:2.5132\n","Step:1596/100000, Loss:2.7580, Time:2.4428\n","Step:1597/100000, Loss:2.7521, Time:2.4404\n","Step:1598/100000, Loss:2.7684, Time:2.4405\n","Step:1599/100000, Loss:2.5831, Time:3.7869\n","Validation step:0, Loss:2.4944, Loss Reconstruction:0.0352\n","Validation step:1, Loss:2.6260, Loss Reconstruction:0.1599\n","Validation step:2, Loss:2.7036, Loss Reconstruction:0.2135\n","Validation step:3, Loss:2.6278, Loss Reconstruction:0.1065\n","Validation step:4, Loss:2.5988, Loss Reconstruction:0.0429\n","Validation step:5, Loss:2.4739, Loss Reconstruction:0.0389\n","Validation step:6, Loss:2.7408, Loss Reconstruction:0.1842\n","Validation step:7, Loss:2.6924, Loss Reconstruction:0.1958\n","Validation step:8, Loss:2.5874, Loss Reconstruction:0.1107\n","Model was saved ! Best Recon. Val Loss: 0.1208, Recon. Val Loss: 0.1208\n","Step:1600/100000, Loss:2.5003, Time:2.8485\n","Step:1601/100000, Loss:2.4409, Time:3.0953\n","Step:1602/100000, Loss:2.5736, Time:2.7266\n","Step:1603/100000, Loss:2.7691, Time:2.9880\n","Step:1604/100000, Loss:2.6080, Time:2.9380\n","Step:1605/100000, Loss:2.7806, Time:2.8686\n","Step:1606/100000, Loss:2.4597, Time:2.7340\n","Step:1607/100000, Loss:2.8370, Time:2.8704\n","Step:1608/100000, Loss:2.4214, Time:2.8203\n","Step:1609/100000, Loss:2.5242, Time:2.7304\n","Step:1610/100000, Loss:2.9662, Time:2.7491\n","Step:1611/100000, Loss:2.7790, Time:2.7910\n","Step:1612/100000, Loss:3.1056, Time:2.7487\n","Step:1613/100000, Loss:2.5667, Time:2.9087\n","Step:1614/100000, Loss:3.1930, Time:2.8607\n","Step:1615/100000, Loss:2.5650, Time:3.1692\n","Step:1616/100000, Loss:2.6934, Time:2.7247\n","Step:1617/100000, Loss:2.6830, Time:2.8654\n","Step:1618/100000, Loss:2.6233, Time:2.6713\n","Step:1619/100000, Loss:2.8001, Time:2.7513\n","Step:1620/100000, Loss:2.5665, Time:2.8473\n","Step:1621/100000, Loss:2.7700, Time:3.1075\n","Step:1622/100000, Loss:2.5511, Time:3.9096\n","Step:1623/100000, Loss:2.5296, Time:3.1734\n","Step:1624/100000, Loss:2.5384, Time:3.6737\n","Step:1625/100000, Loss:2.8737, Time:3.0564\n","Step:1626/100000, Loss:2.8428, Time:2.7289\n","Step:1627/100000, Loss:2.5574, Time:3.0305\n","Step:1628/100000, Loss:2.8766, Time:3.1762\n","Step:1629/100000, Loss:2.6685, Time:3.2761\n","Step:1630/100000, Loss:2.7037, Time:3.4993\n","Step:1631/100000, Loss:2.8823, Time:3.7108\n","Step:1632/100000, Loss:2.7481, Time:3.0799\n","Step:1633/100000, Loss:2.7419, Time:3.1249\n","Step:1634/100000, Loss:2.7352, Time:3.3671\n","Step:1635/100000, Loss:2.8616, Time:2.4191\n","Step:1636/100000, Loss:2.5716, Time:2.3979\n","Step:1637/100000, Loss:2.7328, Time:2.3883\n","Step:1638/100000, Loss:2.5700, Time:3.8609\n","Step:1639/100000, Loss:2.6395, Time:3.8276\n","Step:1640/100000, Loss:2.6970, Time:3.8340\n","Step:1641/100000, Loss:2.6274, Time:3.5464\n","Step:1642/100000, Loss:2.5930, Time:2.8679\n","Step:1643/100000, Loss:2.5990, Time:2.7412\n","Step:1644/100000, Loss:2.7423, Time:2.7728\n","Step:1645/100000, Loss:2.5206, Time:2.7335\n","Step:1646/100000, Loss:2.5803, Time:3.0110\n","Step:1647/100000, Loss:2.6020, Time:2.7906\n","Step:1648/100000, Loss:2.7040, Time:2.7363\n","Step:1649/100000, Loss:2.5694, Time:2.7358\n","Step:1650/100000, Loss:2.7622, Time:2.8573\n","Step:1651/100000, Loss:2.7665, Time:2.8138\n","Step:1652/100000, Loss:2.5539, Time:2.9637\n","Step:1653/100000, Loss:2.5251, Time:2.7991\n","Step:1654/100000, Loss:2.5463, Time:3.0705\n","Step:1655/100000, Loss:2.6482, Time:2.8315\n","Step:1656/100000, Loss:2.9700, Time:2.8352\n","Step:1657/100000, Loss:2.8056, Time:2.7182\n","Step:1658/100000, Loss:2.9843, Time:2.7950\n","Step:1659/100000, Loss:2.5286, Time:2.9633\n","Step:1660/100000, Loss:2.7822, Time:2.7994\n","Step:1661/100000, Loss:2.5642, Time:3.9040\n","Step:1662/100000, Loss:2.6597, Time:3.2926\n","Step:1663/100000, Loss:2.7690, Time:3.7505\n","Step:1664/100000, Loss:2.7878, Time:3.0999\n","Step:1665/100000, Loss:2.5918, Time:2.7211\n","Step:1666/100000, Loss:2.4637, Time:3.0583\n","Step:1667/100000, Loss:2.8621, Time:3.3057\n","Step:1668/100000, Loss:2.9984, Time:2.8746\n","Step:1669/100000, Loss:2.9343, Time:3.5443\n","Step:1670/100000, Loss:2.9993, Time:3.1598\n","Step:1671/100000, Loss:2.7722, Time:3.2024\n","Step:1672/100000, Loss:2.7313, Time:2.7279\n","Step:1673/100000, Loss:2.9605, Time:2.4522\n","Step:1674/100000, Loss:3.1037, Time:2.4530\n","Step:1675/100000, Loss:2.7086, Time:2.4020\n","Step:1676/100000, Loss:2.6298, Time:2.4283\n","Step:1677/100000, Loss:2.6357, Time:3.9483\n","Step:1678/100000, Loss:2.6646, Time:3.5407\n","Step:1679/100000, Loss:2.7097, Time:3.5397\n","Step:1680/100000, Loss:2.6546, Time:3.4328\n","Step:1681/100000, Loss:2.7600, Time:3.6579\n","Step:1682/100000, Loss:2.6605, Time:2.9714\n","Step:1683/100000, Loss:2.6951, Time:2.9686\n","Step:1684/100000, Loss:2.7927, Time:2.8147\n","Step:1685/100000, Loss:2.5727, Time:2.8449\n","Step:1686/100000, Loss:2.7234, Time:2.8739\n","Step:1687/100000, Loss:2.5953, Time:2.7960\n","Step:1688/100000, Loss:2.6827, Time:2.7305\n","Step:1689/100000, Loss:2.6770, Time:2.9077\n","Step:1690/100000, Loss:2.6891, Time:2.7577\n","Step:1691/100000, Loss:2.5856, Time:3.0401\n","Step:1692/100000, Loss:2.4327, Time:2.6851\n","Step:1693/100000, Loss:2.5645, Time:3.0586\n","Step:1694/100000, Loss:2.9704, Time:2.7357\n","Step:1695/100000, Loss:2.5899, Time:3.7333\n","Step:1696/100000, Loss:2.8276, Time:3.0970\n","Step:1697/100000, Loss:2.9571, Time:2.7710\n","Step:1698/100000, Loss:2.7805, Time:2.7043\n","Step:1699/100000, Loss:2.6029, Time:3.0132\n","Validation step:0, Loss:2.6704, Loss Reconstruction:0.0874\n","Validation step:1, Loss:2.8689, Loss Reconstruction:0.2557\n","Validation step:2, Loss:2.6757, Loss Reconstruction:0.3293\n","Validation step:3, Loss:2.8629, Loss Reconstruction:0.2150\n","Validation step:4, Loss:2.4207, Loss Reconstruction:0.1424\n","Validation step:5, Loss:2.7966, Loss Reconstruction:0.2486\n","Validation step:6, Loss:2.6322, Loss Reconstruction:0.1516\n","Validation step:7, Loss:2.8106, Loss Reconstruction:0.0946\n","Validation step:8, Loss:2.5501, Loss Reconstruction:0.1703\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.1883\n","Step:1700/100000, Loss:3.0157, Time:2.8086\n","Step:1701/100000, Loss:2.6555, Time:3.2639\n","Step:1702/100000, Loss:2.5890, Time:3.8234\n","Step:1703/100000, Loss:2.8470, Time:3.2537\n","Step:1704/100000, Loss:3.0080, Time:2.7223\n","Step:1705/100000, Loss:2.6550, Time:3.6729\n","Step:1706/100000, Loss:2.6776, Time:3.0356\n","Step:1707/100000, Loss:2.4296, Time:3.0307\n","Step:1708/100000, Loss:2.6200, Time:3.6512\n","Step:1709/100000, Loss:2.6710, Time:3.6554\n","Step:1710/100000, Loss:2.9499, Time:3.1761\n","Step:1711/100000, Loss:2.8015, Time:2.7740\n","Step:1712/100000, Loss:2.7590, Time:2.4693\n","Step:1713/100000, Loss:2.9463, Time:2.3732\n","Step:1714/100000, Loss:2.7056, Time:2.3935\n","Step:1715/100000, Loss:2.7821, Time:2.3961\n","Step:1716/100000, Loss:2.5907, Time:3.3721\n","Step:1717/100000, Loss:2.7508, Time:3.5568\n","Step:1718/100000, Loss:2.7773, Time:3.6103\n","Step:1719/100000, Loss:2.6503, Time:3.6720\n","Step:1720/100000, Loss:2.5485, Time:3.6930\n","Step:1721/100000, Loss:2.5817, Time:2.8882\n","Step:1722/100000, Loss:2.8224, Time:2.7627\n","Step:1723/100000, Loss:2.6983, Time:2.7200\n","Step:1724/100000, Loss:2.7478, Time:2.7998\n","Step:1725/100000, Loss:2.7978, Time:2.7003\n","Step:1726/100000, Loss:2.6894, Time:2.7164\n","Step:1727/100000, Loss:2.5751, Time:2.7762\n","Step:1728/100000, Loss:2.7185, Time:2.8840\n","Step:1729/100000, Loss:2.6901, Time:2.7640\n","Step:1730/100000, Loss:2.7044, Time:2.9291\n","Step:1731/100000, Loss:2.6128, Time:2.7936\n","Step:1732/100000, Loss:2.4766, Time:3.1183\n","Step:1733/100000, Loss:2.7214, Time:2.7671\n","Step:1734/100000, Loss:2.5587, Time:2.8934\n","Step:1735/100000, Loss:2.9628, Time:2.7455\n","Step:1736/100000, Loss:2.6557, Time:2.8713\n","Step:1737/100000, Loss:2.8140, Time:2.6869\n","Step:1738/100000, Loss:2.5629, Time:3.0414\n","Step:1739/100000, Loss:2.8567, Time:3.6592\n","Step:1740/100000, Loss:2.5234, Time:3.2503\n","Step:1741/100000, Loss:2.7601, Time:3.8937\n","Step:1742/100000, Loss:2.7975, Time:3.0054\n","Step:1743/100000, Loss:2.7017, Time:2.7144\n","Step:1744/100000, Loss:2.7503, Time:3.1568\n","Step:1745/100000, Loss:2.7671, Time:3.0741\n","Step:1746/100000, Loss:2.5878, Time:2.9733\n","Step:1747/100000, Loss:2.6684, Time:3.6130\n","Step:1748/100000, Loss:2.7429, Time:3.2380\n","Step:1749/100000, Loss:2.8566, Time:4.4726\n","Step:1750/100000, Loss:2.8224, Time:2.9694\n","Step:1751/100000, Loss:2.5787, Time:2.4445\n","Step:1752/100000, Loss:2.7343, Time:2.3826\n","Step:1753/100000, Loss:2.8277, Time:2.5359\n","Step:1754/100000, Loss:2.5474, Time:2.3838\n","Step:1755/100000, Loss:2.6048, Time:3.8447\n","Step:1756/100000, Loss:2.5998, Time:3.5617\n","Step:1757/100000, Loss:2.8646, Time:3.5465\n","Step:1758/100000, Loss:2.8386, Time:3.6321\n","Step:1759/100000, Loss:2.4774, Time:3.5903\n","Step:1760/100000, Loss:2.6926, Time:2.7535\n","Step:1761/100000, Loss:2.4932, Time:2.8531\n","Step:1762/100000, Loss:2.4065, Time:2.7429\n","Step:1763/100000, Loss:2.7730, Time:2.7714\n","Step:1764/100000, Loss:2.6270, Time:2.8750\n","Step:1765/100000, Loss:2.4850, Time:2.8016\n","Step:1766/100000, Loss:2.6068, Time:2.7558\n","Step:1767/100000, Loss:2.8196, Time:2.9377\n","Step:1768/100000, Loss:2.6482, Time:2.8454\n","Step:1769/100000, Loss:2.6826, Time:2.9885\n","Step:1770/100000, Loss:2.5289, Time:2.7978\n","Step:1771/100000, Loss:2.7125, Time:3.0180\n","Step:1772/100000, Loss:2.5689, Time:2.7729\n","Step:1773/100000, Loss:2.5897, Time:2.8824\n","Step:1774/100000, Loss:2.7501, Time:2.7628\n","Step:1775/100000, Loss:2.7039, Time:2.7711\n","Step:1776/100000, Loss:2.4280, Time:2.8381\n","Step:1777/100000, Loss:2.6567, Time:3.0137\n","Step:1778/100000, Loss:2.7417, Time:4.0396\n","Step:1779/100000, Loss:2.8053, Time:3.0996\n","Step:1780/100000, Loss:2.8291, Time:4.0989\n","Step:1781/100000, Loss:3.0409, Time:2.8395\n","Step:1782/100000, Loss:2.8727, Time:2.7752\n","Step:1783/100000, Loss:2.6534, Time:3.0701\n","Step:1784/100000, Loss:2.8722, Time:3.0368\n","Step:1785/100000, Loss:2.5885, Time:3.1392\n","Step:1786/100000, Loss:2.8046, Time:3.4534\n","Step:1787/100000, Loss:2.6698, Time:3.1637\n","Step:1788/100000, Loss:2.7837, Time:3.1216\n","Step:1789/100000, Loss:3.0193, Time:2.7572\n","Step:1790/100000, Loss:2.7182, Time:2.4502\n","Step:1791/100000, Loss:2.7092, Time:2.4080\n","Step:1792/100000, Loss:2.5755, Time:2.3679\n","Step:1793/100000, Loss:2.6301, Time:2.4058\n","Step:1794/100000, Loss:2.4688, Time:3.7643\n","Step:1795/100000, Loss:2.8983, Time:4.0607\n","Step:1796/100000, Loss:2.5851, Time:3.6062\n","Step:1797/100000, Loss:2.5368, Time:3.4128\n","Step:1798/100000, Loss:2.7452, Time:3.1631\n","Step:1799/100000, Loss:2.6151, Time:2.8418\n","Validation step:0, Loss:2.6022, Loss Reconstruction:0.0539\n","Validation step:1, Loss:2.7161, Loss Reconstruction:0.3109\n","Validation step:2, Loss:2.5657, Loss Reconstruction:0.0484\n","Validation step:3, Loss:2.5740, Loss Reconstruction:0.0855\n","Validation step:4, Loss:2.8505, Loss Reconstruction:0.1894\n","Validation step:5, Loss:2.8567, Loss Reconstruction:0.3382\n","Validation step:6, Loss:2.9237, Loss Reconstruction:0.2927\n","Validation step:7, Loss:2.9179, Loss Reconstruction:0.2248\n","Validation step:8, Loss:2.8008, Loss Reconstruction:0.3143\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.2064\n","Step:1800/100000, Loss:2.8987, Time:2.7834\n","Step:1801/100000, Loss:2.8439, Time:2.8614\n","Step:1802/100000, Loss:2.6855, Time:4.2066\n","Step:1803/100000, Loss:2.7161, Time:2.9280\n","Step:1804/100000, Loss:2.4432, Time:2.7934\n","Step:1805/100000, Loss:2.5548, Time:2.7724\n","Step:1806/100000, Loss:2.8537, Time:2.8418\n","Step:1807/100000, Loss:2.5847, Time:2.8766\n","Step:1808/100000, Loss:2.7237, Time:2.8369\n","Step:1809/100000, Loss:2.7818, Time:2.9932\n","Step:1810/100000, Loss:2.4658, Time:2.9589\n","Step:1811/100000, Loss:2.6588, Time:2.8791\n","Step:1812/100000, Loss:2.7086, Time:2.9062\n","Step:1813/100000, Loss:2.4981, Time:2.7593\n","Step:1814/100000, Loss:2.7758, Time:2.8436\n","Step:1815/100000, Loss:2.6398, Time:2.7136\n","Step:1816/100000, Loss:2.7478, Time:2.9262\n","Step:1817/100000, Loss:2.6702, Time:3.6308\n","Step:1818/100000, Loss:2.7112, Time:3.2083\n","Step:1819/100000, Loss:2.7790, Time:3.8423\n","Step:1820/100000, Loss:2.7030, Time:3.1783\n","Step:1821/100000, Loss:2.6806, Time:2.7015\n","Step:1822/100000, Loss:2.8694, Time:3.1639\n","Step:1823/100000, Loss:2.8909, Time:3.0625\n","Step:1824/100000, Loss:2.6898, Time:3.0113\n","Step:1825/100000, Loss:2.8426, Time:3.5825\n","Step:1826/100000, Loss:2.8625, Time:3.1018\n","Step:1827/100000, Loss:2.6282, Time:3.3080\n","Step:1828/100000, Loss:2.8676, Time:2.7401\n","Step:1829/100000, Loss:2.7679, Time:2.4274\n","Step:1830/100000, Loss:2.5712, Time:2.3759\n","Step:1831/100000, Loss:2.8066, Time:2.4301\n","Step:1832/100000, Loss:2.8114, Time:2.4170\n","Step:1833/100000, Loss:2.6543, Time:3.8469\n","Step:1834/100000, Loss:2.6859, Time:3.8520\n","Step:1835/100000, Loss:2.5487, Time:3.6279\n","Step:1836/100000, Loss:2.6935, Time:3.4990\n","Step:1837/100000, Loss:2.6945, Time:3.4752\n","Step:1838/100000, Loss:2.6261, Time:2.7195\n","Step:1839/100000, Loss:2.6578, Time:2.8304\n","Step:1840/100000, Loss:2.7535, Time:2.7715\n","Step:1841/100000, Loss:2.7273, Time:2.8067\n","Step:1842/100000, Loss:2.7247, Time:2.8488\n","Step:1843/100000, Loss:2.4418, Time:2.8669\n","Step:1844/100000, Loss:2.8522, Time:2.7273\n","Step:1845/100000, Loss:2.7788, Time:2.7872\n","Step:1846/100000, Loss:2.6134, Time:2.7365\n","Step:1847/100000, Loss:2.7103, Time:2.9853\n","Step:1848/100000, Loss:2.8837, Time:2.7156\n","Step:1849/100000, Loss:2.6549, Time:3.1489\n","Step:1850/100000, Loss:2.5744, Time:2.7160\n","Step:1851/100000, Loss:2.6434, Time:3.0018\n","Step:1852/100000, Loss:2.7169, Time:2.7057\n","Step:1853/100000, Loss:2.5958, Time:2.8035\n","Step:1854/100000, Loss:2.8501, Time:2.7849\n","Step:1855/100000, Loss:2.5424, Time:2.8928\n","Step:1856/100000, Loss:2.6094, Time:3.4728\n","Step:1857/100000, Loss:2.6890, Time:3.4626\n","Step:1858/100000, Loss:2.7421, Time:4.0733\n","Step:1859/100000, Loss:2.9137, Time:2.9072\n","Step:1860/100000, Loss:2.5465, Time:2.7934\n","Step:1861/100000, Loss:2.6575, Time:2.9663\n","Step:1862/100000, Loss:2.5985, Time:3.1586\n","Step:1863/100000, Loss:2.8372, Time:3.4806\n","Step:1864/100000, Loss:2.7671, Time:4.6865\n","Step:1865/100000, Loss:2.5379, Time:3.0971\n","Step:1866/100000, Loss:2.6390, Time:3.0740\n","Step:1867/100000, Loss:2.8061, Time:2.7298\n","Step:1868/100000, Loss:2.6961, Time:2.4897\n","Step:1869/100000, Loss:2.9407, Time:2.3714\n","Step:1870/100000, Loss:2.7780, Time:2.4075\n","Step:1871/100000, Loss:2.7265, Time:2.4039\n","Step:1872/100000, Loss:2.6893, Time:3.9320\n","Step:1873/100000, Loss:2.7021, Time:3.5958\n","Step:1874/100000, Loss:2.5212, Time:3.4832\n","Step:1875/100000, Loss:2.5286, Time:3.3267\n","Step:1876/100000, Loss:2.5663, Time:3.2031\n","Step:1877/100000, Loss:2.5550, Time:2.9809\n","Step:1878/100000, Loss:2.6778, Time:2.7068\n","Step:1879/100000, Loss:2.7233, Time:2.7490\n","Step:1880/100000, Loss:2.6290, Time:2.8083\n","Step:1881/100000, Loss:2.6894, Time:2.9113\n","Step:1882/100000, Loss:2.6532, Time:2.8763\n","Step:1883/100000, Loss:2.6156, Time:2.7394\n","Step:1884/100000, Loss:2.6957, Time:2.7947\n","Step:1885/100000, Loss:2.7055, Time:2.8548\n","Step:1886/100000, Loss:2.4858, Time:2.9387\n","Step:1887/100000, Loss:2.5915, Time:2.8276\n","Step:1888/100000, Loss:2.5931, Time:3.0805\n","Step:1889/100000, Loss:2.5407, Time:2.6893\n","Step:1890/100000, Loss:2.4857, Time:2.9025\n","Step:1891/100000, Loss:2.5280, Time:2.7111\n","Step:1892/100000, Loss:3.0410, Time:2.8168\n","Step:1893/100000, Loss:2.6191, Time:2.8586\n","Step:1894/100000, Loss:2.4598, Time:3.0505\n","Step:1895/100000, Loss:2.5661, Time:3.5680\n","Step:1896/100000, Loss:2.5354, Time:3.2908\n","Step:1897/100000, Loss:2.9084, Time:3.9885\n","Step:1898/100000, Loss:3.0593, Time:2.8335\n","Step:1899/100000, Loss:2.7218, Time:2.6941\n","Validation step:0, Loss:2.9587, Loss Reconstruction:0.2032\n","Validation step:1, Loss:2.8146, Loss Reconstruction:0.2422\n","Validation step:2, Loss:3.2087, Loss Reconstruction:0.2691\n","Validation step:3, Loss:2.4242, Loss Reconstruction:0.0722\n","Validation step:4, Loss:2.7559, Loss Reconstruction:0.1623\n","Validation step:5, Loss:3.0196, Loss Reconstruction:0.1388\n","Validation step:6, Loss:2.9103, Loss Reconstruction:0.1537\n","Validation step:7, Loss:2.4889, Loss Reconstruction:0.1530\n","Validation step:8, Loss:2.9717, Loss Reconstruction:0.5411\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.2151\n","Step:1900/100000, Loss:2.5993, Time:2.7534\n","Step:1901/100000, Loss:2.7960, Time:3.3634\n","Step:1902/100000, Loss:2.6745, Time:3.2499\n","Step:1903/100000, Loss:3.0877, Time:3.5115\n","Step:1904/100000, Loss:2.7064, Time:3.5655\n","Step:1905/100000, Loss:2.8972, Time:3.1773\n","Step:1906/100000, Loss:2.7094, Time:2.7929\n","Step:1907/100000, Loss:2.6466, Time:2.5107\n","Step:1908/100000, Loss:3.0788, Time:2.4290\n","Step:1909/100000, Loss:2.9375, Time:2.4102\n","Step:1910/100000, Loss:2.9620, Time:2.4101\n","Step:1911/100000, Loss:2.5691, Time:3.6482\n","Step:1912/100000, Loss:2.7288, Time:3.4919\n","Step:1913/100000, Loss:2.5283, Time:3.5372\n","Step:1914/100000, Loss:2.4090, Time:3.7088\n","Step:1915/100000, Loss:2.6261, Time:3.4315\n","Step:1916/100000, Loss:2.6285, Time:4.0437\n","Step:1917/100000, Loss:2.7156, Time:3.0607\n","Step:1918/100000, Loss:2.6086, Time:2.7420\n","Step:1919/100000, Loss:2.7873, Time:2.8703\n","Step:1920/100000, Loss:2.7180, Time:2.8237\n","Step:1921/100000, Loss:2.6836, Time:2.6981\n","Step:1922/100000, Loss:2.6611, Time:2.7591\n","Step:1923/100000, Loss:2.6239, Time:2.8726\n","Step:1924/100000, Loss:2.5881, Time:2.7543\n","Step:1925/100000, Loss:2.5887, Time:3.1502\n","Step:1926/100000, Loss:2.6316, Time:2.6942\n","Step:1927/100000, Loss:2.7162, Time:3.1306\n","Step:1928/100000, Loss:2.5868, Time:2.7813\n","Step:1929/100000, Loss:2.7016, Time:2.8229\n","Step:1930/100000, Loss:2.6783, Time:2.7788\n","Step:1931/100000, Loss:2.6373, Time:2.7974\n","Step:1932/100000, Loss:2.5915, Time:2.8220\n","Step:1933/100000, Loss:2.7383, Time:3.0135\n","Step:1934/100000, Loss:2.4129, Time:3.8737\n","Step:1935/100000, Loss:2.5219, Time:3.0671\n","Step:1936/100000, Loss:2.5741, Time:3.8158\n","Step:1937/100000, Loss:2.6930, Time:3.0225\n","Step:1938/100000, Loss:2.6113, Time:2.7489\n","Step:1939/100000, Loss:2.7669, Time:3.0749\n","Step:1940/100000, Loss:2.9815, Time:3.0895\n","Step:1941/100000, Loss:3.1908, Time:3.0211\n","Step:1942/100000, Loss:2.7632, Time:3.2902\n","Step:1943/100000, Loss:2.8279, Time:3.3386\n","Step:1944/100000, Loss:2.7700, Time:3.2285\n","Step:1945/100000, Loss:2.9028, Time:2.7121\n","Step:1946/100000, Loss:3.1965, Time:2.4529\n","Step:1947/100000, Loss:2.8446, Time:2.3823\n","Step:1948/100000, Loss:2.8720, Time:2.4099\n","Step:1949/100000, Loss:2.7052, Time:2.4150\n","Step:1950/100000, Loss:2.5722, Time:3.6758\n","Step:1951/100000, Loss:2.6380, Time:3.6757\n","Step:1952/100000, Loss:2.6406, Time:3.4274\n","Step:1953/100000, Loss:2.6546, Time:3.5934\n","Step:1954/100000, Loss:2.5815, Time:3.7570\n","Step:1955/100000, Loss:2.5814, Time:2.7105\n","Step:1956/100000, Loss:2.4619, Time:2.7769\n","Step:1957/100000, Loss:2.6529, Time:2.7855\n","Step:1958/100000, Loss:2.6114, Time:2.9232\n","Step:1959/100000, Loss:2.8119, Time:2.8433\n","Step:1960/100000, Loss:2.7248, Time:2.8218\n","Step:1961/100000, Loss:2.8091, Time:2.8235\n","Step:1962/100000, Loss:2.5488, Time:2.8246\n","Step:1963/100000, Loss:2.6366, Time:2.6834\n","Step:1964/100000, Loss:2.4560, Time:2.9222\n","Step:1965/100000, Loss:2.9028, Time:2.8039\n","Step:1966/100000, Loss:2.7398, Time:3.0311\n","Step:1967/100000, Loss:2.7455, Time:2.6688\n","Step:1968/100000, Loss:2.7520, Time:2.8557\n","Step:1969/100000, Loss:2.3755, Time:2.7420\n","Step:1970/100000, Loss:2.8006, Time:2.7920\n","Step:1971/100000, Loss:2.6719, Time:2.7191\n","Step:1972/100000, Loss:2.6026, Time:3.0080\n","Step:1973/100000, Loss:2.4999, Time:3.8286\n","Step:1974/100000, Loss:2.6421, Time:3.0402\n","Step:1975/100000, Loss:2.4240, Time:3.6195\n","Step:1976/100000, Loss:2.6795, Time:3.1723\n","Step:1977/100000, Loss:2.5534, Time:2.9860\n","Step:1978/100000, Loss:2.9173, Time:4.2308\n","Step:1979/100000, Loss:2.4582, Time:3.1918\n","Step:1980/100000, Loss:2.6525, Time:2.9303\n","Step:1981/100000, Loss:2.7324, Time:3.3937\n","Step:1982/100000, Loss:3.0352, Time:3.5131\n","Step:1983/100000, Loss:2.7694, Time:3.0313\n","Step:1984/100000, Loss:2.8245, Time:2.7321\n","Step:1985/100000, Loss:2.8782, Time:2.4252\n","Step:1986/100000, Loss:2.4346, Time:2.4127\n","Step:1987/100000, Loss:2.9313, Time:2.4464\n","Step:1988/100000, Loss:2.6965, Time:2.3976\n","Step:1989/100000, Loss:2.7624, Time:3.5636\n","Step:1990/100000, Loss:2.6555, Time:3.5910\n","Step:1991/100000, Loss:2.6336, Time:3.6022\n","Step:1992/100000, Loss:2.6968, Time:3.5409\n","Step:1993/100000, Loss:2.6558, Time:3.4314\n","Step:1994/100000, Loss:2.8036, Time:2.7557\n","Step:1995/100000, Loss:2.6965, Time:2.8234\n","Step:1996/100000, Loss:2.6008, Time:2.6997\n","Step:1997/100000, Loss:2.6367, Time:2.8069\n","Step:1998/100000, Loss:2.7760, Time:2.7506\n","Step:1999/100000, Loss:2.5218, Time:2.7155\n","Validation step:0, Loss:2.5669, Loss Reconstruction:0.0842\n","Validation step:1, Loss:2.7553, Loss Reconstruction:0.2920\n","Validation step:2, Loss:2.7394, Loss Reconstruction:0.1775\n","Validation step:3, Loss:2.8511, Loss Reconstruction:0.2969\n","Validation step:4, Loss:2.5893, Loss Reconstruction:0.1526\n","Validation step:5, Loss:2.7851, Loss Reconstruction:0.2939\n","Validation step:6, Loss:2.5797, Loss Reconstruction:0.0986\n","Validation step:7, Loss:2.9090, Loss Reconstruction:0.3654\n","Validation step:8, Loss:2.7972, Loss Reconstruction:0.2429\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.2226\n","Step:2000/100000, Loss:2.7767, Time:2.6767\n","Step:2001/100000, Loss:2.6639, Time:2.7575\n","Step:2002/100000, Loss:2.6218, Time:2.9266\n","Step:2003/100000, Loss:2.5615, Time:3.0150\n","Step:2004/100000, Loss:2.6296, Time:3.0492\n","Step:2005/100000, Loss:2.5840, Time:3.0768\n","Step:2006/100000, Loss:2.6313, Time:2.9243\n","Step:2007/100000, Loss:2.6567, Time:2.9114\n","Step:2008/100000, Loss:2.6492, Time:2.7688\n","Step:2009/100000, Loss:2.5809, Time:2.7901\n","Step:2010/100000, Loss:2.6656, Time:2.7898\n","Step:2011/100000, Loss:2.5105, Time:2.9932\n","Step:2012/100000, Loss:2.6539, Time:3.7082\n","Step:2013/100000, Loss:2.7093, Time:3.1489\n","Step:2014/100000, Loss:2.5367, Time:3.8063\n","Step:2015/100000, Loss:3.0841, Time:2.9661\n","Step:2016/100000, Loss:2.9033, Time:2.7876\n","Step:2017/100000, Loss:2.6738, Time:2.9636\n","Step:2018/100000, Loss:2.7622, Time:3.1492\n","Step:2019/100000, Loss:2.5725, Time:3.2144\n","Step:2020/100000, Loss:3.0940, Time:3.3803\n","Step:2021/100000, Loss:2.8740, Time:3.3291\n","Step:2022/100000, Loss:2.7863, Time:3.0699\n","Step:2023/100000, Loss:2.7857, Time:2.7265\n","Step:2024/100000, Loss:2.8420, Time:2.4571\n","Step:2025/100000, Loss:2.4219, Time:2.3617\n","Step:2026/100000, Loss:2.5145, Time:2.3735\n","Step:2027/100000, Loss:2.9543, Time:2.3761\n","Step:2028/100000, Loss:2.7634, Time:3.7988\n","Step:2029/100000, Loss:2.8188, Time:3.7570\n","Step:2030/100000, Loss:2.8399, Time:4.7622\n","Step:2031/100000, Loss:2.6694, Time:3.6570\n","Step:2032/100000, Loss:2.5905, Time:3.0865\n","Step:2033/100000, Loss:2.9955, Time:2.8574\n","Step:2034/100000, Loss:2.7763, Time:2.9411\n","Step:2035/100000, Loss:2.7191, Time:2.8253\n","Step:2036/100000, Loss:2.7127, Time:3.0326\n","Step:2037/100000, Loss:2.5596, Time:2.7047\n","Step:2038/100000, Loss:2.7704, Time:2.7460\n","Step:2039/100000, Loss:2.8817, Time:2.7158\n","Step:2040/100000, Loss:2.7112, Time:2.7100\n","Step:2041/100000, Loss:2.5519, Time:2.8313\n","Step:2042/100000, Loss:2.5258, Time:2.8882\n","Step:2043/100000, Loss:2.6736, Time:2.8356\n","Step:2044/100000, Loss:2.4345, Time:3.3248\n","Step:2045/100000, Loss:2.5334, Time:2.8255\n","Step:2046/100000, Loss:2.7314, Time:2.8277\n","Step:2047/100000, Loss:2.4763, Time:2.7554\n","Step:2048/100000, Loss:2.7074, Time:2.8660\n","Step:2049/100000, Loss:2.6088, Time:2.7801\n","Step:2050/100000, Loss:2.6757, Time:3.0790\n","Step:2051/100000, Loss:2.6962, Time:3.7525\n","Step:2052/100000, Loss:2.6469, Time:3.1828\n","Step:2053/100000, Loss:2.7132, Time:3.8093\n","Step:2054/100000, Loss:2.6793, Time:3.0553\n","Step:2055/100000, Loss:2.5714, Time:2.7910\n","Step:2056/100000, Loss:2.6392, Time:3.1661\n","Step:2057/100000, Loss:2.7646, Time:3.0783\n","Step:2058/100000, Loss:2.8082, Time:3.0808\n","Step:2059/100000, Loss:2.8308, Time:3.5378\n","Step:2060/100000, Loss:2.8122, Time:3.2124\n","Step:2061/100000, Loss:2.9438, Time:3.0312\n","Step:2062/100000, Loss:2.9818, Time:2.7058\n","Step:2063/100000, Loss:2.8157, Time:2.5697\n","Step:2064/100000, Loss:2.7328, Time:2.4093\n","Step:2065/100000, Loss:2.7646, Time:2.3960\n","Step:2066/100000, Loss:2.7491, Time:2.3761\n","Step:2067/100000, Loss:2.5935, Time:3.6562\n","Step:2068/100000, Loss:2.6012, Time:3.6053\n","Step:2069/100000, Loss:2.7710, Time:3.6945\n","Step:2070/100000, Loss:2.4580, Time:3.6847\n","Step:2071/100000, Loss:2.7049, Time:3.2324\n","Step:2072/100000, Loss:2.7834, Time:2.7710\n","Step:2073/100000, Loss:2.8190, Time:2.8991\n","Step:2074/100000, Loss:2.7019, Time:2.7489\n","Step:2075/100000, Loss:2.8299, Time:2.7949\n","Step:2076/100000, Loss:2.7275, Time:2.9300\n","Step:2077/100000, Loss:2.6715, Time:2.6926\n","Step:2078/100000, Loss:2.6181, Time:2.8099\n","Step:2079/100000, Loss:2.6054, Time:2.8463\n","Step:2080/100000, Loss:2.6040, Time:2.7668\n","Step:2081/100000, Loss:2.6636, Time:2.7922\n","Step:2082/100000, Loss:2.6366, Time:2.8765\n","Step:2083/100000, Loss:2.5747, Time:3.1558\n","Step:2084/100000, Loss:2.5448, Time:2.7140\n","Step:2085/100000, Loss:2.6868, Time:2.8816\n","Step:2086/100000, Loss:2.6770, Time:2.6985\n","Step:2087/100000, Loss:2.6875, Time:2.8596\n","Step:2088/100000, Loss:2.8396, Time:2.7912\n","Step:2089/100000, Loss:2.6288, Time:3.0108\n","Step:2090/100000, Loss:2.7100, Time:3.7753\n","Step:2091/100000, Loss:2.6690, Time:4.0476\n","Step:2092/100000, Loss:2.7381, Time:4.4186\n","Step:2093/100000, Loss:2.9567, Time:3.0194\n","Step:2094/100000, Loss:2.7569, Time:2.7892\n","Step:2095/100000, Loss:2.9199, Time:3.1187\n","Step:2096/100000, Loss:2.6229, Time:3.1220\n","Step:2097/100000, Loss:2.7845, Time:2.9238\n","Step:2098/100000, Loss:2.4670, Time:3.3588\n","Step:2099/100000, Loss:2.8870, Time:3.3694\n","Validation step:0, Loss:2.6122, Loss Reconstruction:0.2010\n","Validation step:1, Loss:2.9766, Loss Reconstruction:0.4024\n","Validation step:2, Loss:2.7018, Loss Reconstruction:0.2885\n","Validation step:3, Loss:2.7447, Loss Reconstruction:0.1882\n","Validation step:4, Loss:2.4794, Loss Reconstruction:0.0686\n","Validation step:5, Loss:2.6065, Loss Reconstruction:0.0638\n","Validation step:6, Loss:2.5584, Loss Reconstruction:0.0811\n","Validation step:7, Loss:2.7044, Loss Reconstruction:0.0811\n","Validation step:8, Loss:2.6674, Loss Reconstruction:0.2387\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.1793\n","Step:2100/100000, Loss:2.8751, Time:2.6826\n","Step:2101/100000, Loss:2.6404, Time:2.8239\n","Step:2102/100000, Loss:2.5875, Time:2.4651\n","Step:2103/100000, Loss:2.6058, Time:2.4198\n","Step:2104/100000, Loss:2.9196, Time:2.3897\n","Step:2105/100000, Loss:2.6513, Time:2.4041\n","Step:2106/100000, Loss:2.5753, Time:3.4054\n","Step:2107/100000, Loss:2.9113, Time:3.5896\n","Step:2108/100000, Loss:2.3401, Time:3.6529\n","Step:2109/100000, Loss:2.6602, Time:3.8038\n","Step:2110/100000, Loss:2.6012, Time:3.5113\n","Step:2111/100000, Loss:2.7091, Time:2.8177\n","Step:2112/100000, Loss:2.5753, Time:2.7930\n","Step:2113/100000, Loss:2.5513, Time:2.6930\n","Step:2114/100000, Loss:2.7627, Time:2.8944\n","Step:2115/100000, Loss:2.7236, Time:2.7880\n","Step:2116/100000, Loss:2.6188, Time:2.7437\n","Step:2117/100000, Loss:2.5448, Time:2.6685\n","Step:2118/100000, Loss:2.6394, Time:2.7555\n","Step:2119/100000, Loss:2.6399, Time:2.7812\n","Step:2120/100000, Loss:2.8353, Time:2.9173\n","Step:2121/100000, Loss:2.6121, Time:2.7668\n","Step:2122/100000, Loss:2.6335, Time:3.0523\n","Step:2123/100000, Loss:2.9184, Time:2.7641\n","Step:2124/100000, Loss:2.7267, Time:2.9046\n","Step:2125/100000, Loss:2.6346, Time:2.7349\n","Step:2126/100000, Loss:2.6954, Time:2.8378\n","Step:2127/100000, Loss:2.5127, Time:2.7471\n","Step:2128/100000, Loss:2.8532, Time:3.0956\n","Step:2129/100000, Loss:2.8490, Time:3.8869\n","Step:2130/100000, Loss:2.6375, Time:3.2145\n","Step:2131/100000, Loss:2.7254, Time:3.5000\n","Step:2132/100000, Loss:2.7056, Time:2.9256\n","Step:2133/100000, Loss:2.6219, Time:2.7682\n","Step:2134/100000, Loss:2.8556, Time:3.1282\n","Step:2135/100000, Loss:2.6420, Time:3.2041\n","Step:2136/100000, Loss:2.7453, Time:3.0667\n","Step:2137/100000, Loss:2.7006, Time:3.4735\n","Step:2138/100000, Loss:3.0928, Time:3.3683\n","Step:2139/100000, Loss:2.8500, Time:3.0118\n","Step:2140/100000, Loss:2.7063, Time:2.7259\n","Step:2141/100000, Loss:2.7945, Time:2.4806\n","Step:2142/100000, Loss:3.0217, Time:2.3921\n","Step:2143/100000, Loss:2.8314, Time:2.3814\n","Step:2144/100000, Loss:2.8152, Time:2.4238\n","Step:2145/100000, Loss:2.5889, Time:4.5943\n","Step:2146/100000, Loss:2.6107, Time:4.1185\n","Step:2147/100000, Loss:2.8232, Time:3.5348\n","Step:2148/100000, Loss:2.8552, Time:3.5396\n","Step:2149/100000, Loss:2.7672, Time:2.9875\n","Step:2150/100000, Loss:2.4942, Time:2.7702\n","Step:2151/100000, Loss:2.7323, Time:3.0298\n","Step:2152/100000, Loss:2.7431, Time:2.7578\n","Step:2153/100000, Loss:2.7872, Time:2.8876\n","Step:2154/100000, Loss:3.0055, Time:2.9513\n","Step:2155/100000, Loss:2.7435, Time:2.7449\n","Step:2156/100000, Loss:2.7243, Time:2.7943\n","Step:2157/100000, Loss:2.5984, Time:2.8243\n","Step:2158/100000, Loss:2.5990, Time:2.7661\n","Step:2159/100000, Loss:2.5615, Time:2.8757\n","Step:2160/100000, Loss:2.6552, Time:2.9496\n","Step:2161/100000, Loss:2.5697, Time:2.9135\n","Step:2162/100000, Loss:2.6497, Time:2.7313\n","Step:2163/100000, Loss:2.5760, Time:2.8685\n","Step:2164/100000, Loss:2.6941, Time:2.7421\n","Step:2165/100000, Loss:2.7007, Time:2.7249\n","Step:2166/100000, Loss:2.8091, Time:2.7906\n","Step:2167/100000, Loss:2.6220, Time:3.0937\n","Step:2168/100000, Loss:2.7169, Time:3.9195\n","Step:2169/100000, Loss:2.6716, Time:3.0495\n","Step:2170/100000, Loss:2.6723, Time:3.7694\n","Step:2171/100000, Loss:2.7683, Time:2.8958\n","Step:2172/100000, Loss:2.6594, Time:2.6910\n","Step:2173/100000, Loss:2.8628, Time:3.0322\n","Step:2174/100000, Loss:2.6823, Time:3.1896\n","Step:2175/100000, Loss:2.5594, Time:2.9178\n","Step:2176/100000, Loss:2.8676, Time:3.5578\n","Step:2177/100000, Loss:2.8952, Time:3.2163\n","Step:2178/100000, Loss:2.6299, Time:2.9894\n","Step:2179/100000, Loss:2.6612, Time:2.7657\n","Step:2180/100000, Loss:2.8127, Time:2.4755\n","Step:2181/100000, Loss:2.8925, Time:2.4098\n","Step:2182/100000, Loss:2.7150, Time:2.3833\n","Step:2183/100000, Loss:2.8234, Time:2.4153\n","Step:2184/100000, Loss:2.6795, Time:3.4809\n","Step:2185/100000, Loss:2.5315, Time:3.6591\n","Step:2186/100000, Loss:2.7493, Time:3.7947\n","Step:2187/100000, Loss:2.5917, Time:3.5860\n","Step:2188/100000, Loss:2.7627, Time:3.0745\n","Step:2189/100000, Loss:2.6545, Time:2.7865\n","Step:2190/100000, Loss:2.5880, Time:2.7067\n","Step:2191/100000, Loss:2.7220, Time:2.7749\n","Step:2192/100000, Loss:2.5908, Time:2.9434\n","Step:2193/100000, Loss:2.8463, Time:2.6879\n","Step:2194/100000, Loss:2.4986, Time:2.7229\n","Step:2195/100000, Loss:2.5113, Time:2.7919\n","Step:2196/100000, Loss:2.6904, Time:2.7721\n","Step:2197/100000, Loss:2.7777, Time:2.8301\n","Step:2198/100000, Loss:2.5956, Time:2.9651\n","Step:2199/100000, Loss:2.5829, Time:2.9580\n","Validation step:0, Loss:2.4660, Loss Reconstruction:0.1130\n","Validation step:1, Loss:2.9419, Loss Reconstruction:0.4337\n","Validation step:2, Loss:2.7436, Loss Reconstruction:0.0871\n","Validation step:3, Loss:2.6554, Loss Reconstruction:0.1593\n","Validation step:4, Loss:2.5397, Loss Reconstruction:0.1164\n","Validation step:5, Loss:2.5584, Loss Reconstruction:0.0604\n","Validation step:6, Loss:2.6394, Loss Reconstruction:0.1453\n","Validation step:7, Loss:2.8214, Loss Reconstruction:0.3261\n","Validation step:8, Loss:2.7978, Loss Reconstruction:0.2951\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.1929\n","Step:2200/100000, Loss:2.7191, Time:2.7368\n","Step:2201/100000, Loss:2.7538, Time:2.8800\n","Step:2202/100000, Loss:2.6672, Time:2.8877\n","Step:2203/100000, Loss:2.6233, Time:2.7655\n","Step:2204/100000, Loss:2.5327, Time:2.7977\n","Step:2205/100000, Loss:2.5252, Time:2.7700\n","Step:2206/100000, Loss:2.6213, Time:2.8957\n","Step:2207/100000, Loss:2.7133, Time:3.8528\n","Step:2208/100000, Loss:2.5318, Time:3.0618\n","Step:2209/100000, Loss:2.4691, Time:3.9443\n","Step:2210/100000, Loss:2.6859, Time:2.8784\n","Step:2211/100000, Loss:2.6654, Time:2.8764\n","Step:2212/100000, Loss:3.0200, Time:3.0950\n","Step:2213/100000, Loss:2.7506, Time:3.1375\n","Step:2214/100000, Loss:2.7393, Time:2.8662\n","Step:2215/100000, Loss:2.6787, Time:3.5828\n","Step:2216/100000, Loss:2.4426, Time:3.1689\n","Step:2217/100000, Loss:2.9335, Time:3.1848\n","Step:2218/100000, Loss:2.6122, Time:2.6995\n","Step:2219/100000, Loss:2.6925, Time:2.5332\n","Step:2220/100000, Loss:2.6939, Time:2.4159\n","Step:2221/100000, Loss:3.0438, Time:2.4309\n","Step:2222/100000, Loss:2.5198, Time:2.4334\n","Step:2223/100000, Loss:2.7478, Time:3.7677\n","Step:2224/100000, Loss:2.6118, Time:3.9691\n","Step:2225/100000, Loss:2.4533, Time:3.6597\n","Step:2226/100000, Loss:3.1513, Time:3.3357\n","Step:2227/100000, Loss:2.6495, Time:2.9750\n","Step:2228/100000, Loss:2.5309, Time:2.7936\n","Step:2229/100000, Loss:2.8634, Time:2.8826\n","Step:2230/100000, Loss:2.7714, Time:2.7576\n","Step:2231/100000, Loss:2.6232, Time:2.8681\n","Step:2232/100000, Loss:2.7580, Time:2.8298\n","Step:2233/100000, Loss:2.6136, Time:2.7486\n","Step:2234/100000, Loss:2.7706, Time:2.7303\n","Step:2235/100000, Loss:2.5704, Time:2.8893\n","Step:2236/100000, Loss:2.6174, Time:2.8126\n","Step:2237/100000, Loss:2.4748, Time:2.9558\n","Step:2238/100000, Loss:2.6414, Time:2.8682\n","Step:2239/100000, Loss:2.4061, Time:3.0548\n","Step:2240/100000, Loss:2.5013, Time:2.7087\n","Step:2241/100000, Loss:2.5740, Time:2.8973\n","Step:2242/100000, Loss:2.7427, Time:2.8304\n","Step:2243/100000, Loss:2.8972, Time:2.9882\n","Step:2244/100000, Loss:2.6766, Time:2.7892\n","Step:2245/100000, Loss:2.7642, Time:3.0640\n","Step:2246/100000, Loss:2.7472, Time:3.3943\n","Step:2247/100000, Loss:2.5391, Time:3.2730\n","Step:2248/100000, Loss:2.6682, Time:3.8822\n","Step:2249/100000, Loss:2.8003, Time:2.9917\n","Step:2250/100000, Loss:2.7459, Time:2.8061\n","Step:2251/100000, Loss:2.7504, Time:3.0363\n","Step:2252/100000, Loss:2.8456, Time:3.1910\n","Step:2253/100000, Loss:2.5593, Time:2.9577\n","Step:2254/100000, Loss:2.7226, Time:3.4316\n","Step:2255/100000, Loss:2.8622, Time:3.3744\n","Step:2256/100000, Loss:2.8243, Time:2.9215\n","Step:2257/100000, Loss:2.6374, Time:2.8210\n","Step:2258/100000, Loss:2.8789, Time:2.5618\n","Step:2259/100000, Loss:2.7745, Time:2.5062\n","Step:2260/100000, Loss:2.5330, Time:2.3804\n","Step:2261/100000, Loss:2.5126, Time:2.4383\n","Step:2262/100000, Loss:2.6941, Time:3.5402\n","Step:2263/100000, Loss:2.6412, Time:3.6190\n","Step:2264/100000, Loss:2.6344, Time:3.8269\n","Step:2265/100000, Loss:2.7922, Time:3.7500\n","Step:2266/100000, Loss:2.8080, Time:2.9984\n","Step:2267/100000, Loss:2.5222, Time:2.8173\n","Step:2268/100000, Loss:2.6655, Time:2.7658\n","Step:2269/100000, Loss:2.5316, Time:2.6945\n","Step:2270/100000, Loss:2.6539, Time:2.9427\n","Step:2271/100000, Loss:2.7413, Time:2.7381\n","Step:2272/100000, Loss:2.5211, Time:2.7130\n","Step:2273/100000, Loss:2.7660, Time:2.7509\n","Step:2274/100000, Loss:2.6449, Time:2.8054\n","Step:2275/100000, Loss:2.2259, Time:2.8095\n","Step:2276/100000, Loss:3.6118, Time:2.9548\n","Step:2277/100000, Loss:2.6969, Time:2.8353\n","Step:2278/100000, Loss:2.5673, Time:3.0468\n","Step:2279/100000, Loss:2.7589, Time:2.7927\n","Step:2280/100000, Loss:2.5023, Time:2.8793\n","Step:2281/100000, Loss:2.5952, Time:2.7528\n","Step:2282/100000, Loss:2.5802, Time:2.7437\n","Step:2283/100000, Loss:2.5273, Time:2.8188\n","Step:2284/100000, Loss:2.8008, Time:3.1254\n","Step:2285/100000, Loss:2.8285, Time:4.3608\n","Step:2286/100000, Loss:2.6468, Time:2.9682\n","Step:2287/100000, Loss:2.5437, Time:3.5926\n","Step:2288/100000, Loss:2.8537, Time:2.7589\n","Step:2289/100000, Loss:2.9269, Time:2.7237\n","Step:2290/100000, Loss:3.0415, Time:3.0794\n","Step:2291/100000, Loss:2.9945, Time:3.2219\n","Step:2292/100000, Loss:2.7714, Time:3.0330\n","Step:2293/100000, Loss:2.6063, Time:3.5251\n","Step:2294/100000, Loss:2.7886, Time:3.1347\n","Step:2295/100000, Loss:2.7404, Time:3.0909\n","Step:2296/100000, Loss:2.8534, Time:2.8491\n","Step:2297/100000, Loss:2.9201, Time:2.4206\n","Step:2298/100000, Loss:2.8995, Time:2.3612\n","Step:2299/100000, Loss:2.7220, Time:2.4095\n","Validation step:0, Loss:2.6777, Loss Reconstruction:0.1823\n","Validation step:1, Loss:2.7749, Loss Reconstruction:0.3318\n","Validation step:2, Loss:2.8565, Loss Reconstruction:0.3277\n","Validation step:3, Loss:2.8219, Loss Reconstruction:0.2643\n","Validation step:4, Loss:2.7559, Loss Reconstruction:0.1854\n","Validation step:5, Loss:2.7659, Loss Reconstruction:0.1666\n","Validation step:6, Loss:2.5430, Loss Reconstruction:0.1129\n","Validation step:7, Loss:2.7124, Loss Reconstruction:0.1836\n","Validation step:8, Loss:2.8474, Loss Reconstruction:0.3549\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.2344\n","Step:2300/100000, Loss:2.6578, Time:2.3937\n","Step:2301/100000, Loss:2.7878, Time:3.8052\n","Step:2302/100000, Loss:2.8896, Time:3.6421\n","Step:2303/100000, Loss:2.6601, Time:3.8037\n","Step:2304/100000, Loss:2.6415, Time:3.5201\n","Step:2305/100000, Loss:2.6239, Time:3.0386\n","Step:2306/100000, Loss:2.5981, Time:2.7266\n","Step:2307/100000, Loss:2.6777, Time:2.8368\n","Step:2308/100000, Loss:2.6388, Time:2.6903\n","Step:2309/100000, Loss:2.5845, Time:2.7391\n","Step:2310/100000, Loss:2.7009, Time:3.7153\n","Step:2311/100000, Loss:2.5840, Time:3.1478\n","Step:2312/100000, Loss:2.6122, Time:2.6982\n","Step:2313/100000, Loss:2.7169, Time:2.7426\n","Step:2314/100000, Loss:2.6253, Time:2.7690\n","Step:2315/100000, Loss:2.7314, Time:2.9010\n","Step:2316/100000, Loss:2.7422, Time:2.7870\n","Step:2317/100000, Loss:2.7411, Time:3.0867\n","Step:2318/100000, Loss:2.6558, Time:2.7046\n","Step:2319/100000, Loss:2.5936, Time:2.8670\n","Step:2320/100000, Loss:2.5904, Time:2.8211\n","Step:2321/100000, Loss:2.6255, Time:2.7548\n","Step:2322/100000, Loss:2.6477, Time:2.7156\n","Step:2323/100000, Loss:2.7244, Time:2.8847\n","Step:2324/100000, Loss:2.5599, Time:3.6210\n","Step:2325/100000, Loss:2.6472, Time:3.0729\n","Step:2326/100000, Loss:2.8643, Time:3.5911\n","Step:2327/100000, Loss:2.9019, Time:3.2177\n","Step:2328/100000, Loss:2.6862, Time:2.7632\n","Step:2329/100000, Loss:2.7646, Time:3.0591\n","Step:2330/100000, Loss:2.5233, Time:3.0554\n","Step:2331/100000, Loss:2.5957, Time:3.0194\n","Step:2332/100000, Loss:2.9678, Time:3.3796\n","Step:2333/100000, Loss:2.7551, Time:3.2259\n","Step:2334/100000, Loss:2.9549, Time:3.1262\n","Step:2335/100000, Loss:2.8832, Time:2.7128\n","Step:2336/100000, Loss:2.6481, Time:2.4755\n","Step:2337/100000, Loss:2.8502, Time:2.4009\n","Step:2338/100000, Loss:2.7798, Time:2.4050\n","Step:2339/100000, Loss:2.5552, Time:2.4047\n","Step:2340/100000, Loss:2.6315, Time:3.9211\n","Step:2341/100000, Loss:2.8113, Time:3.7773\n","Step:2342/100000, Loss:2.6375, Time:3.6930\n","Step:2343/100000, Loss:2.8279, Time:3.5761\n","Step:2344/100000, Loss:2.6798, Time:2.9280\n","Step:2345/100000, Loss:2.5231, Time:2.7852\n","Step:2346/100000, Loss:2.6379, Time:2.7205\n","Step:2347/100000, Loss:2.6184, Time:2.7416\n","Step:2348/100000, Loss:2.7903, Time:2.7898\n","Step:2349/100000, Loss:2.6299, Time:2.8049\n","Step:2350/100000, Loss:2.7165, Time:2.7722\n","Step:2351/100000, Loss:2.6886, Time:2.7596\n","Step:2352/100000, Loss:2.5145, Time:2.7847\n","Step:2353/100000, Loss:2.5733, Time:2.7714\n","Step:2354/100000, Loss:2.5538, Time:2.9549\n","Step:2355/100000, Loss:2.7905, Time:2.8190\n","Step:2356/100000, Loss:2.6323, Time:3.0889\n","Step:2357/100000, Loss:2.7492, Time:2.6975\n","Step:2358/100000, Loss:2.6245, Time:2.8684\n","Step:2359/100000, Loss:2.4776, Time:2.8358\n","Step:2360/100000, Loss:2.5663, Time:2.7430\n","Step:2361/100000, Loss:2.5605, Time:2.7358\n","Step:2362/100000, Loss:2.5725, Time:2.9592\n","Step:2363/100000, Loss:2.8659, Time:3.6334\n","Step:2364/100000, Loss:2.7648, Time:3.4371\n","Step:2365/100000, Loss:2.8439, Time:3.8285\n","Step:2366/100000, Loss:2.8453, Time:3.0451\n","Step:2367/100000, Loss:2.5639, Time:3.0041\n","Step:2368/100000, Loss:2.8530, Time:3.0829\n","Step:2369/100000, Loss:2.6708, Time:3.1496\n","Step:2370/100000, Loss:2.8117, Time:2.7989\n","Step:2371/100000, Loss:2.6200, Time:4.5665\n","Step:2372/100000, Loss:2.7121, Time:3.7737\n","Step:2373/100000, Loss:2.8874, Time:3.2871\n","Step:2374/100000, Loss:2.6208, Time:2.7338\n","Step:2375/100000, Loss:2.6644, Time:2.4836\n","Step:2376/100000, Loss:2.5808, Time:2.4003\n","Step:2377/100000, Loss:2.6013, Time:2.4129\n","Step:2378/100000, Loss:2.5484, Time:2.3788\n","Step:2379/100000, Loss:2.6783, Time:3.7898\n","Step:2380/100000, Loss:2.6348, Time:3.7182\n","Step:2381/100000, Loss:2.7747, Time:3.9859\n","Step:2382/100000, Loss:2.5888, Time:3.5387\n","Step:2383/100000, Loss:2.6321, Time:2.7885\n","Step:2384/100000, Loss:2.7669, Time:2.7319\n","Step:2385/100000, Loss:2.6679, Time:2.7978\n","Step:2386/100000, Loss:2.7116, Time:2.8307\n","Step:2387/100000, Loss:2.5823, Time:2.8160\n","Step:2388/100000, Loss:2.6876, Time:2.9891\n","Step:2389/100000, Loss:2.5644, Time:2.8509\n","Step:2390/100000, Loss:2.6142, Time:2.7968\n","Step:2391/100000, Loss:2.5736, Time:2.7971\n","Step:2392/100000, Loss:2.6559, Time:2.8208\n","Step:2393/100000, Loss:2.5924, Time:2.9404\n","Step:2394/100000, Loss:2.7671, Time:2.8974\n","Step:2395/100000, Loss:2.5433, Time:3.2025\n","Step:2396/100000, Loss:2.4712, Time:2.8622\n","Step:2397/100000, Loss:2.6498, Time:2.8882\n","Step:2398/100000, Loss:2.5335, Time:2.8040\n","Step:2399/100000, Loss:2.6412, Time:2.8592\n","Validation step:0, Loss:2.6685, Loss Reconstruction:0.0513\n","Validation step:1, Loss:2.4912, Loss Reconstruction:0.1104\n","Validation step:2, Loss:2.5373, Loss Reconstruction:0.0935\n","Validation step:3, Loss:2.7326, Loss Reconstruction:0.2326\n","Validation step:4, Loss:2.5387, Loss Reconstruction:0.0465\n","Validation step:5, Loss:2.6818, Loss Reconstruction:0.2448\n","Validation step:6, Loss:2.5574, Loss Reconstruction:0.0584\n","Validation step:7, Loss:2.7415, Loss Reconstruction:0.1864\n","Validation step:8, Loss:3.0211, Loss Reconstruction:0.4601\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.1649\n","Step:2400/100000, Loss:2.5504, Time:2.7528\n","Step:2401/100000, Loss:2.6872, Time:3.0671\n","Step:2402/100000, Loss:2.6206, Time:3.7195\n","Step:2403/100000, Loss:2.8995, Time:3.0283\n","Step:2404/100000, Loss:2.6461, Time:3.8705\n","Step:2405/100000, Loss:2.6814, Time:3.1160\n","Step:2406/100000, Loss:2.4568, Time:2.9147\n","Step:2407/100000, Loss:2.6940, Time:3.2114\n","Step:2408/100000, Loss:3.0432, Time:3.2608\n","Step:2409/100000, Loss:2.5365, Time:2.9297\n","Step:2410/100000, Loss:2.7291, Time:3.4798\n","Step:2411/100000, Loss:3.0367, Time:3.4018\n","Step:2412/100000, Loss:2.4885, Time:3.0179\n","Step:2413/100000, Loss:2.6026, Time:2.7533\n","Step:2414/100000, Loss:3.0117, Time:2.4228\n","Step:2415/100000, Loss:2.8590, Time:2.3855\n","Step:2416/100000, Loss:2.7560, Time:2.4073\n","Step:2417/100000, Loss:2.8099, Time:2.3706\n","Step:2418/100000, Loss:2.5526, Time:3.5652\n","Step:2419/100000, Loss:2.5967, Time:3.6390\n","Step:2420/100000, Loss:2.5591, Time:3.7706\n","Step:2421/100000, Loss:2.5789, Time:3.9267\n","Step:2422/100000, Loss:2.6494, Time:4.0663\n","Step:2423/100000, Loss:2.8135, Time:2.6978\n","Step:2424/100000, Loss:2.6519, Time:3.0748\n","Step:2425/100000, Loss:2.4363, Time:2.7071\n","Step:2426/100000, Loss:2.4889, Time:2.8502\n","Step:2427/100000, Loss:2.7122, Time:2.7397\n","Step:2428/100000, Loss:2.5060, Time:2.6838\n","Step:2429/100000, Loss:2.5850, Time:2.7165\n","Step:2430/100000, Loss:2.7000, Time:2.7988\n","Step:2431/100000, Loss:2.5376, Time:2.8014\n","Step:2432/100000, Loss:2.5248, Time:2.9245\n","Step:2433/100000, Loss:2.6670, Time:2.8878\n","Step:2434/100000, Loss:2.6718, Time:3.1581\n","Step:2435/100000, Loss:2.7212, Time:2.7898\n","Step:2436/100000, Loss:2.6674, Time:2.8796\n","Step:2437/100000, Loss:2.6961, Time:2.7583\n","Step:2438/100000, Loss:2.5814, Time:2.8231\n","Step:2439/100000, Loss:2.4681, Time:2.7233\n","Step:2440/100000, Loss:2.5842, Time:2.8655\n","Step:2441/100000, Loss:2.6527, Time:3.9292\n","Step:2442/100000, Loss:2.6508, Time:3.2464\n","Step:2443/100000, Loss:2.5255, Time:3.5319\n","Step:2444/100000, Loss:2.7246, Time:3.2125\n","Step:2445/100000, Loss:2.6554, Time:2.8350\n","Step:2446/100000, Loss:2.9172, Time:3.1096\n","Step:2447/100000, Loss:2.8519, Time:3.1146\n","Step:2448/100000, Loss:2.7044, Time:2.9816\n","Step:2449/100000, Loss:2.8166, Time:3.6760\n","Step:2450/100000, Loss:3.0024, Time:3.0601\n","Step:2451/100000, Loss:3.0004, Time:3.3954\n","Step:2452/100000, Loss:2.6012, Time:2.7059\n","Step:2453/100000, Loss:2.8929, Time:2.4619\n","Step:2454/100000, Loss:2.6178, Time:2.4126\n","Step:2455/100000, Loss:2.4941, Time:2.3845\n","Step:2456/100000, Loss:2.6254, Time:2.4104\n","Step:2457/100000, Loss:2.8389, Time:3.6784\n","Step:2458/100000, Loss:2.6409, Time:3.7554\n","Step:2459/100000, Loss:2.7233, Time:3.8717\n","Step:2460/100000, Loss:2.6470, Time:3.4828\n","Step:2461/100000, Loss:2.7140, Time:3.2483\n","Step:2462/100000, Loss:2.4649, Time:2.8346\n","Step:2463/100000, Loss:2.5797, Time:2.8649\n","Step:2464/100000, Loss:2.6150, Time:2.7838\n","Step:2465/100000, Loss:2.7257, Time:2.7869\n","Step:2466/100000, Loss:2.8855, Time:2.8377\n","Step:2467/100000, Loss:2.6339, Time:2.7093\n","Step:2468/100000, Loss:2.4519, Time:2.7486\n","Step:2469/100000, Loss:2.5789, Time:2.9167\n","Step:2470/100000, Loss:2.6776, Time:2.7279\n","Step:2471/100000, Loss:2.5380, Time:2.9242\n","Step:2472/100000, Loss:2.6286, Time:3.1036\n","Step:2473/100000, Loss:2.4466, Time:2.9150\n","Step:2474/100000, Loss:2.8045, Time:2.7870\n","Step:2475/100000, Loss:2.6338, Time:2.8230\n","Step:2476/100000, Loss:2.5674, Time:2.8243\n","Step:2477/100000, Loss:2.7427, Time:2.8013\n","Step:2478/100000, Loss:2.5061, Time:2.7819\n","Step:2479/100000, Loss:2.6908, Time:2.9752\n","Step:2480/100000, Loss:2.6018, Time:3.8262\n","Step:2481/100000, Loss:2.4378, Time:3.1925\n","Step:2482/100000, Loss:2.8466, Time:4.9093\n","Step:2483/100000, Loss:2.6568, Time:3.3253\n","Step:2484/100000, Loss:2.6436, Time:2.8777\n","Step:2485/100000, Loss:2.7826, Time:2.9869\n","Step:2486/100000, Loss:2.8253, Time:3.1544\n","Step:2487/100000, Loss:2.9940, Time:2.9672\n","Step:2488/100000, Loss:2.8470, Time:3.5939\n","Step:2489/100000, Loss:2.9442, Time:3.3896\n","Step:2490/100000, Loss:2.7233, Time:3.2768\n","Step:2491/100000, Loss:2.9321, Time:2.7784\n","Step:2492/100000, Loss:2.8731, Time:2.5126\n","Step:2493/100000, Loss:2.6152, Time:2.4072\n","Step:2494/100000, Loss:2.7340, Time:2.4032\n","Step:2495/100000, Loss:2.9192, Time:2.4271\n","Step:2496/100000, Loss:2.6661, Time:3.7803\n","Step:2497/100000, Loss:2.5578, Time:3.5003\n","Step:2498/100000, Loss:2.6547, Time:3.5868\n","Step:2499/100000, Loss:2.8388, Time:3.3547\n","Validation step:0, Loss:2.5890, Loss Reconstruction:0.0729\n","Validation step:1, Loss:2.7328, Loss Reconstruction:0.2634\n","Validation step:2, Loss:2.6952, Loss Reconstruction:0.2094\n","Validation step:3, Loss:2.6070, Loss Reconstruction:0.0695\n","Validation step:4, Loss:2.6733, Loss Reconstruction:0.1684\n","Validation step:5, Loss:2.6862, Loss Reconstruction:0.1677\n","Validation step:6, Loss:2.9313, Loss Reconstruction:0.4265\n","Validation step:7, Loss:2.6746, Loss Reconstruction:0.1724\n","Validation step:8, Loss:2.7428, Loss Reconstruction:0.2594\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.2011\n","Step:2500/100000, Loss:2.5456, Time:2.7376\n","Step:2501/100000, Loss:2.7153, Time:2.7613\n","Step:2502/100000, Loss:2.6284, Time:2.8890\n","Step:2503/100000, Loss:2.5521, Time:2.7218\n","Step:2504/100000, Loss:2.5161, Time:2.8708\n","Step:2505/100000, Loss:2.6394, Time:2.9146\n","Step:2506/100000, Loss:2.6867, Time:2.7662\n","Step:2507/100000, Loss:2.6579, Time:2.8052\n","Step:2508/100000, Loss:2.5363, Time:2.9074\n","Step:2509/100000, Loss:2.5093, Time:2.7913\n","Step:2510/100000, Loss:2.7796, Time:2.9824\n","Step:2511/100000, Loss:2.6255, Time:2.7946\n","Step:2512/100000, Loss:2.5928, Time:3.0568\n","Step:2513/100000, Loss:2.7052, Time:2.7935\n","Step:2514/100000, Loss:2.6142, Time:2.8015\n","Step:2515/100000, Loss:2.3483, Time:2.7987\n","Step:2516/100000, Loss:2.5524, Time:2.8629\n","Step:2517/100000, Loss:2.4830, Time:3.0396\n","Step:2518/100000, Loss:2.6994, Time:2.7845\n","Step:2519/100000, Loss:2.8152, Time:3.7984\n","Step:2520/100000, Loss:2.4684, Time:3.1767\n","Step:2521/100000, Loss:2.5404, Time:3.5551\n","Step:2522/100000, Loss:2.4781, Time:3.0596\n","Step:2523/100000, Loss:2.6975, Time:2.7690\n","Step:2524/100000, Loss:2.9827, Time:3.0350\n","Step:2525/100000, Loss:2.6141, Time:3.1570\n","Step:2526/100000, Loss:2.6047, Time:2.9150\n","Step:2527/100000, Loss:2.9292, Time:3.4626\n","Step:2528/100000, Loss:2.9926, Time:3.2938\n","Step:2529/100000, Loss:2.8987, Time:3.1732\n","Step:2530/100000, Loss:3.2772, Time:2.7517\n","Step:2531/100000, Loss:2.5888, Time:2.4705\n","Step:2532/100000, Loss:2.9290, Time:2.4313\n","Step:2533/100000, Loss:2.7234, Time:2.4268\n","Step:2534/100000, Loss:2.6959, Time:2.4313\n","Step:2535/100000, Loss:2.6642, Time:3.6393\n","Step:2536/100000, Loss:2.8403, Time:3.8994\n","Step:2537/100000, Loss:2.5959, Time:3.4748\n","Step:2538/100000, Loss:2.7225, Time:3.5973\n","Step:2539/100000, Loss:2.4387, Time:3.2590\n","Step:2540/100000, Loss:2.6733, Time:2.6644\n","Step:2541/100000, Loss:2.6874, Time:2.7923\n","Step:2542/100000, Loss:2.5345, Time:2.7728\n","Step:2543/100000, Loss:2.4827, Time:2.8993\n","Step:2544/100000, Loss:2.7520, Time:2.7970\n","Step:2545/100000, Loss:2.5519, Time:2.7488\n","Step:2546/100000, Loss:2.5365, Time:2.7132\n","Step:2547/100000, Loss:2.6508, Time:2.8178\n","Step:2548/100000, Loss:2.4576, Time:2.7557\n","Step:2549/100000, Loss:2.5682, Time:2.8433\n","Step:2550/100000, Loss:2.7644, Time:2.7814\n","Step:2551/100000, Loss:2.4752, Time:2.9602\n","Step:2552/100000, Loss:2.6628, Time:2.6970\n","Step:2553/100000, Loss:2.5303, Time:2.7418\n","Step:2554/100000, Loss:2.4238, Time:2.7655\n","Step:2555/100000, Loss:2.6675, Time:2.6692\n","Step:2556/100000, Loss:2.7294, Time:2.7537\n","Step:2557/100000, Loss:2.7395, Time:2.8916\n","Step:2558/100000, Loss:2.8223, Time:3.7524\n","Step:2559/100000, Loss:2.7447, Time:3.1306\n","Step:2560/100000, Loss:2.8513, Time:3.8029\n","Step:2561/100000, Loss:2.6977, Time:2.9582\n","Step:2562/100000, Loss:2.6275, Time:3.0217\n","Step:2563/100000, Loss:2.9495, Time:2.9636\n","Step:2564/100000, Loss:2.9443, Time:3.0314\n","Step:2565/100000, Loss:2.5256, Time:3.0802\n","Step:2566/100000, Loss:2.6515, Time:3.5265\n","Step:2567/100000, Loss:2.9038, Time:3.3026\n","Step:2568/100000, Loss:2.7950, Time:2.9262\n","Step:2569/100000, Loss:3.1176, Time:2.7505\n","Step:2570/100000, Loss:2.8412, Time:2.4955\n","Step:2571/100000, Loss:2.8336, Time:2.3524\n","Step:2572/100000, Loss:2.8327, Time:2.3683\n","Step:2573/100000, Loss:2.6728, Time:2.4087\n","Step:2574/100000, Loss:2.6045, Time:3.7735\n","Step:2575/100000, Loss:2.6379, Time:3.6807\n","Step:2576/100000, Loss:2.6415, Time:3.8059\n","Step:2577/100000, Loss:2.6401, Time:3.4652\n","Step:2578/100000, Loss:2.6500, Time:2.9858\n","Step:2579/100000, Loss:2.6147, Time:2.7331\n","Step:2580/100000, Loss:2.6399, Time:2.8127\n","Step:2581/100000, Loss:2.7111, Time:2.7464\n","Step:2582/100000, Loss:2.5045, Time:2.8436\n","Step:2583/100000, Loss:2.8832, Time:2.7163\n","Step:2584/100000, Loss:2.6351, Time:2.7410\n","Step:2585/100000, Loss:2.5855, Time:2.7753\n","Step:2586/100000, Loss:2.6147, Time:2.8051\n","Step:2587/100000, Loss:2.6975, Time:2.7132\n","Step:2588/100000, Loss:2.7119, Time:2.9138\n","Step:2589/100000, Loss:2.6712, Time:2.8337\n","Step:2590/100000, Loss:2.6386, Time:3.0944\n","Step:2591/100000, Loss:2.7294, Time:2.7921\n","Step:2592/100000, Loss:2.6521, Time:2.9701\n","Step:2593/100000, Loss:2.5827, Time:2.8865\n","Step:2594/100000, Loss:2.6078, Time:3.9042\n","Step:2595/100000, Loss:2.4595, Time:2.7162\n","Step:2596/100000, Loss:2.7287, Time:3.0793\n","Step:2597/100000, Loss:2.6604, Time:3.8414\n","Step:2598/100000, Loss:2.7269, Time:3.0142\n","Step:2599/100000, Loss:2.6391, Time:3.9603\n","Validation step:0, Loss:2.5761, Loss Reconstruction:0.0744\n","Validation step:1, Loss:2.8679, Loss Reconstruction:0.3994\n","Validation step:2, Loss:2.4601, Loss Reconstruction:0.0499\n","Validation step:3, Loss:2.6540, Loss Reconstruction:0.1161\n","Validation step:4, Loss:2.5351, Loss Reconstruction:0.0485\n","Validation step:5, Loss:2.8262, Loss Reconstruction:0.3411\n","Validation step:6, Loss:2.9282, Loss Reconstruction:0.3904\n","Validation step:7, Loss:2.6197, Loss Reconstruction:0.0999\n","Validation step:8, Loss:3.0381, Loss Reconstruction:0.4238\n","Model was not saved ! Best Recon. Val Loss: 0.1208 Recon. Val Loss: 0.2160\n","Step:2600/100000, Loss:2.7270, Time:2.7114\n","Step:2601/100000, Loss:2.6799, Time:2.6857\n","Step:2602/100000, Loss:2.7469, Time:3.4576\n","Step:2603/100000, Loss:2.5860, Time:3.3145\n","Step:2604/100000, Loss:3.0078, Time:2.9422\n","Step:2605/100000, Loss:3.0122, Time:3.7038\n","Step:2606/100000, Loss:2.5323, Time:3.4995\n","Step:2607/100000, Loss:2.7432, Time:3.2207\n","Step:2608/100000, Loss:2.5731, Time:3.0339\n","Step:2609/100000, Loss:2.8794, Time:2.4358\n","Step:2610/100000, Loss:2.5925, Time:2.3859\n","Step:2611/100000, Loss:2.6944, Time:2.3888\n","Step:2612/100000, Loss:2.5845, Time:2.3949\n","Step:2613/100000, Loss:2.7384, Time:3.8281\n","Step:2614/100000, Loss:2.7296, Time:3.5284\n","Step:2615/100000, Loss:2.6820, Time:3.7092\n","Step:2616/100000, Loss:2.5072, Time:3.5138\n","Step:2617/100000, Loss:2.6825, Time:3.0930\n","Step:2618/100000, Loss:2.7032, Time:2.7892\n","Step:2619/100000, Loss:2.6554, Time:2.8755\n","Step:2620/100000, Loss:2.7848, Time:2.7821\n","Step:2621/100000, Loss:2.5516, Time:2.8414\n","Step:2622/100000, Loss:2.6511, Time:2.7001\n","Step:2623/100000, Loss:2.7685, Time:2.8242\n","Step:2624/100000, Loss:2.7762, Time:2.7404\n","Step:2625/100000, Loss:2.5916, Time:2.7188\n","Step:2626/100000, Loss:2.5517, Time:2.7926\n","Step:2627/100000, Loss:2.9026, Time:2.9553\n","Step:2628/100000, Loss:2.8115, Time:2.7870\n","Step:2629/100000, Loss:2.5032, Time:3.1341\n","Step:2630/100000, Loss:2.4163, Time:2.7625\n","Step:2631/100000, Loss:2.6711, Time:2.9049\n","Step:2632/100000, Loss:2.5183, Time:2.7332\n","Step:2633/100000, Loss:2.5463, Time:2.7866\n","Step:2634/100000, Loss:2.5700, Time:2.7798\n","Step:2635/100000, Loss:2.7453, Time:2.9204\n","Step:2636/100000, Loss:2.4931, Time:3.5542\n","Step:2637/100000, Loss:2.6406, Time:3.1618\n","Step:2638/100000, Loss:2.3470, Time:3.6729\n","Step:2639/100000, Loss:2.7376, Time:3.0892\n","Step:2640/100000, Loss:2.7775, Time:2.9002\n","Step:2641/100000, Loss:2.9926, Time:3.0304\n","Step:2642/100000, Loss:2.7617, Time:3.0210\n","Step:2643/100000, Loss:2.8430, Time:3.0841\n","Step:2644/100000, Loss:2.7368, Time:3.4766\n","Step:2645/100000, Loss:2.7658, Time:4.9450\n","Step:2646/100000, Loss:2.8367, Time:3.0826\n","Step:2647/100000, Loss:2.6558, Time:2.6902\n","Step:2648/100000, Loss:2.8043, Time:2.4394\n","Step:2649/100000, Loss:2.8788, Time:2.4262\n","Step:2650/100000, Loss:2.5683, Time:2.3892\n","Step:2651/100000, Loss:2.8853, Time:2.4111\n","Step:2652/100000, Loss:2.8269, Time:3.8825\n","Step:2653/100000, Loss:2.6027, Time:3.9985\n","Step:2654/100000, Loss:2.7711, Time:3.7709\n","Step:2655/100000, Loss:2.5333, Time:3.3946\n","Step:2656/100000, Loss:2.5366, Time:2.9242\n","Step:2657/100000, Loss:2.7169, Time:2.8115\n","Step:2658/100000, Loss:2.5709, Time:2.7168\n","Step:2659/100000, Loss:2.7085, Time:2.7422\n","Step:2660/100000, Loss:2.5767, Time:2.8798\n","Step:2661/100000, Loss:2.6210, Time:2.8296\n"]}]}]}